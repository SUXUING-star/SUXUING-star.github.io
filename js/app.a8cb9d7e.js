(function(){var n={8266:function(n){n.exports={attributes:{title:"深度学习的统计学入门笔记",date:"2024-12-10T00:00:00.000Z",summary:"深度学习怎么可能不学统计学",coverImage:"12-9-1.jpg",pinned:!0},html:"<h1>统计学基础知识入门笔记</h1>\n<h2>1. 基本概念与定义</h2>\n<h3>1.1 统计量的概念</h3>\n<p>统计量是从样本中计算得到的数值，用于描述总体的某些特征。常见的统计量包括：</p>\n<ol>\n<li>\n<p><strong>样本均值 (Sample Mean)</strong>：描述数据的集中趋势\n$\\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n} X_i$</p>\n</li>\n<li>\n<p><strong>样本方差 (Sample Variance)</strong>：描述数据的离散程度\n$S^2 = \\frac{1}{n-1}\\sum_{i=1}^{n} (X_i - \\bar{X})^2$</p>\n</li>\n<li>\n<p><strong>样本标准差 (Sample Standard Deviation)</strong>：方差的平方根，更直观地描述数据的离散程度。\n$S = \\sqrt{S^2}$</p>\n</li>\n<li>\n<p><strong>样本偏度 (Sample Skewness)</strong>：描述数据分布的对称性\n$Skewness = \\frac{1}{n}\\sum_{i=1}^{n}\\left(\\frac{X_i - \\bar{X}}{S}\\right)^3$</p>\n<ul>\n<li>正偏度 (Positive Skewness)：尾部向右延伸，也称为右偏。</li>\n<li>负偏度 (Negative Skewness)：尾部向左延伸，也称为左偏。</li>\n</ul>\n</li>\n<li>\n<p><strong>样本峰度 (Sample Kurtosis)</strong>：描述数据分布的尖峭程度\n$Kurtosis = \\frac{1}{n}\\sum_{i=1}^{n}\\left(\\frac{X_i - \\bar{X}}{S}\\right)^4 - 3$  (这里使用的是超额峰度,  正态分布的超额峰度为0)</p>\n<ul>\n<li>正峰度 (Leptokurtic)：分布比正态分布更尖峭，尾部更厚。</li>\n<li>负峰度 (Platykurtic)：分布比正态分布更平坦，尾部更薄。</li>\n</ul>\n</li>\n</ol>\n<h3>1.2 参数与统计量的区别</h3>\n<ul>\n<li><strong>参数 (Parameter)</strong>：描述<strong>总体</strong>的数值特征，通常未知，用希腊字母表示（如 $\\mu$ 表示总体均值, $\\sigma$ 表示总体标准差）。</li>\n<li><strong>统计量 (Statistic)</strong>：由<strong>样本</strong>计算得到，用于估计总体参数，用拉丁字母表示（如 $\\bar{X}$ 表示样本均值, $S$ 表示样本标准差）。</li>\n</ul>\n<h2>2. 数据特征与分布</h2>\n<h3>2.1 数据平稳性分析</h3>\n<h4>时间序列平稳性</h4>\n<p>平稳性是时间序列分析中的关键概念，一个平稳的时间序列的统计特性不随时间变化。主要包括：</p>\n<ol>\n<li>\n<p><strong>严平稳 (Strict Stationarity)</strong>：时间序列的联合概率分布不随时间平移而改变。\n$F(X_{t_1}, ..., X_{t_k}) = F(X_{t_1+\\tau}, ..., X_{t_k+\\tau}), \\forall \\tau, k, t_1, ..., t_k$</p>\n</li>\n<li>\n<p><strong>弱平稳 (Weak Stationarity, Wide-Sense Stationarity)</strong>：也称宽平稳或协方差平稳，是严平稳的必要非充分条件。</p>\n<ul>\n<li>均值不随时间变化：$E(X_t) = \\mu, \\forall t$</li>\n<li>方差不随时间变化：$Var(X_t) = \\sigma^2, \\forall t$</li>\n<li>协方差只依赖于时间间隔：$Cov(X_t, X_{t+\\tau}) = \\gamma(\\tau), \\forall t, \\tau$</li>\n</ul>\n</li>\n</ol>\n<h4>平稳性检验方法</h4>\n<ol>\n<li><strong>图形检验</strong>：\n<ul>\n<li><strong>时间序列图:</strong>  观察是否存在明显的趋势或季节性。</li>\n<li><strong>自相关图 (ACF) 和偏自相关图 (PACF):</strong>  平稳序列的ACF和PACF会相对快速衰减。</li>\n</ul>\n</li>\n<li><strong>统计检验</strong>：\n<ul>\n<li><strong>ADF 检验 (Augmented Dickey-Fuller Test):</strong>  检验是否存在单位根，原假设是序列<strong>不平稳</strong>。</li>\n<li><strong>KPSS 检验 (Kwiatkowski-Phillips-Schmidt-Shin Test):</strong> 原假设是序列<strong>平稳</strong>。</li>\n</ul>\n</li>\n</ol>\n<h3>2.2 概率分布</h3>\n<h4>正态分布 (Normal Distribution)</h4>\n<p>正态分布，也称高斯分布，是概率论中最常用的分布之一。</p>\n<ul>\n<li><strong>概率密度函数 (PDF):</strong>\n$f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$\n其中 $\\mu$ 是均值, $\\sigma$ 是标准差.</li>\n<li><strong>标准正态分布:</strong> 均值为 0，标准差为 1 的正态分布.</li>\n</ul>\n<h4>其他重要分布</h4>\n<ol>\n<li><strong>t 分布 (Student's t-distribution)</strong>：小样本下，当总体标准差未知时，用于假设检验和置信区间估计。</li>\n<li><strong>卡方分布 ($\\chi^2$ Distribution)</strong>：用于方差分析、拟合优度检验和独立性检验。</li>\n<li><strong>F 分布 (F-distribution)</strong>：方差分析中用于比较两个总体的方差。</li>\n<li><strong>泊松分布 (Poisson Distribution):</strong> 描述单位时间或空间内随机事件发生次数的概率分布.</li>\n<li><strong>指数分布 (Exponential Distribution):</strong> 描述随机事件发生的时间间隔的概率分布.</li>\n</ol>\n<h2>3. 相似度与距离度量</h2>\n<h3>3.1 常见相似度/距离度量</h3>\n<h4>1. 欧氏距离 (Euclidean Distance)</h4>\n<p>$d_{Euclidean}(x, y) = \\sqrt{\\sum_{i=1}^{n}(x_i - y_i)^2}$</p>\n<h4>2. 曼哈顿距离 (Manhattan Distance, City Block Distance, L1 Distance)</h4>\n<p>$d_{Manhattan}(x, y) = \\sum_{i=1}^{n}|x_i - y_i|$</p>\n<h4>3. 余弦相似度 (Cosine Similarity)</h4>\n<p>$\\cos(\\theta) = \\frac{x \\cdot y}{|x| |y|} = \\frac{\\sum_{i=1}^{n} x_i y_i}{\\sqrt{\\sum_{i=1}^{n} x_i^2} \\sqrt{\\sum_{i=1}^{n} y_i^2}}$</p>\n<h4>4. 皮尔逊相关系数 (Pearson Correlation Coefficient)</h4>\n<p>$r = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n}(x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}}$  衡量两个变量之间的线性相关性.</p>\n<h4>5. 汉明距离 (Hamming Distance)</h4>\n<p>用于衡量两个等长字符串的差异，计算对应位置不同的字符数量。</p>\n<h4>6. Jaccard 相似系数 (Jaccard Similarity Coefficient)</h4>\n<p>用于比较两个集合的相似度，定义为两个集合交集的大小除以并集的大小.  $J(A, B) = \\frac{|A \\cap B|}{|A \\cup B|}$</p>\n<h3>3.2 相似度/距离应用场景</h3>\n<ul>\n<li>聚类分析 (Clustering)</li>\n<li>推荐系统 (Recommender Systems)</li>\n<li>模式识别 (Pattern Recognition)</li>\n<li>数据降维 (Dimensionality Reduction)</li>\n<li>文本分析 (Text Analysis)</li>\n<li>图像处理 (Image Processing)</li>\n</ul>\n<h2>4. 假设检验</h2>\n<h3>4.1 假设检验的基本步骤</h3>\n<ol>\n<li>提出原假设 ($H_0$, Null Hypothesis) 和对立假设 ($H_1$，Alternative Hypothesis)。</li>\n<li>选择显著性水平 ($\\alpha$, Significance Level)（常用 0.05 或 0.01）。</li>\n<li>选择检验统计量 (Test Statistic)。</li>\n<li>计算 p 值 (p-value)。</li>\n<li>根据 p 值与显著性水平 $\\alpha$ 的比较作出决策：\n<ul>\n<li>如果 p-value ≤ $\\alpha$，拒绝原假设。</li>\n<li>如果 p-value &gt; $\\alpha$，不能拒绝原假设。</li>\n</ul>\n</li>\n</ol>\n<h3>4.2 常见假设检验</h3>\n<h4>t 检验 (t-test)</h4>\n<p>用于比较两组数据的均值是否存在显著差异。</p>\n<ul>\n<li><strong>单样本 t 检验:</strong>  比较样本均值与已知总体均值的差异.\n$t = \\frac{\\bar{X} - \\mu_0}{S/\\sqrt{n}}$</li>\n<li><strong>双样本 t 检验:</strong> 比较两个独立样本的均值差异.</li>\n<li><strong>配对 t 检验:</strong> 比较两个相关样本的均值差异.</li>\n</ul>\n<h4>方差分析 (ANOVA, Analysis of Variance)</h4>\n<p>用于比较多个总体均值是否存在显著差异。\n$F = \\frac{组间方差 (Between-group Variance)}{组内方差 (Within-group Variance)}$</p>\n<h4>卡方检验 ($\\chi^2$ test)</h4>\n<p>用于检验分类变量之间的关系，例如拟合优度检验和独立性检验。\n$\\chi^2 = \\sum_{i=1}^{r}\\sum_{j=1}^{c} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}$\n其中 $O_{ij}$ 是观测频数，$E_{ij}$ 是期望频数.</p>\n<h2>5. 统计推断与模型</h2>\n<h3>5.1 参数估计方法</h3>\n<ol>\n<li><strong>点估计 (Point Estimation)</strong>：用单个数值估计未知参数，例如用样本均值估计总体均值。</li>\n<li><strong>区间估计 (Interval Estimation)</strong>：给出参数可能的取值范围，即置信区间。\n例如总体均值的置信区间： $\\bar{X} \\pm t_{\\alpha/2, n-1} \\cdot \\frac{S}{\\sqrt{n}}$\n其中 $t_{\\alpha/2, n-1}$ 是 t 分布的临界值.</li>\n</ol>\n<h3>5.2 统计模型</h3>\n<ul>\n<li><strong>线性回归模型 (Linear Regression Model):</strong>  用于建立自变量和因变量之间的线性关系.</li>\n<li><strong>逻辑回归模型 (Logistic Regression Model):</strong> 用于预测二元分类结果的概率.</li>\n<li><strong>时间序列模型 (Time Series Model):</strong> 用于分析和预测时间序列数据，例如 ARIMA 模型.</li>\n<li><strong>贝叶斯模型 (Bayesian Model):</strong> 基于贝叶斯定理进行统计推断.</li>\n</ul>\n<h2>6. 高级统计概念</h2>\n<h3>6.1 Bootstrap 方法</h3>\n<ul>\n<li>用于估计统计量的抽样分布，特别适用于样本量较小或总体分布未知的情况。</li>\n<li>通过重复从原始样本中有放回地抽样，构建多个自助样本，计算每个自助样本的统计量，从而得到统计量的近似分布。</li>\n</ul>\n<h3>6.2 交叉验证 (Cross-validation)</h3>\n<ul>\n<li>用于评估模型的泛化能力，防止过拟合。</li>\n<li><strong>K 折交叉验证 (K-fold Cross-validation):</strong> 将数据集分成 K 份，每次用 K-1 份数据训练模型，用剩余 1 份数据进行测试，重复 K 次，取平均测试结果作为模型的性能评估。</li>\n<li><strong>留一交叉验证 (Leave-One-Out Cross-validation, LOOCV):</strong>  K=n 的特殊情况，每次只留一个样本作为测试集.</li>\n</ul>\n<h2>7. 统计软件与工具</h2>\n<ul>\n<li>R 语言:  强大的统计计算和绘图语言.</li>\n<li>Python:  通用的编程语言，具有丰富的统计和机器学习库，例如 NumPy, SciPy, Pandas, Statsmodels, Scikit-learn.</li>\n<li>SPSS (Statistical Package for the Social Sciences):  常用的统计分析软件，用户界面友好.</li>\n<li>MATLAB:  主要用于数值计算和科学计算，也有一些统计分析工具箱.</li>\n<li>Stata:  用于数据分析和统计建模的软件，尤其在经济学和社会科学领域应用广泛.</li>\n</ul>\n"}},4377:function(n){n.exports={attributes:{title:"深度学习的运筹学知识--反向传播优化问题",date:"2024-12-10T00:00:00.000Z",summary:"深度学习怎么运筹学都学？",coverImage:"12-8-2.jpg",pinned:!0},html:"<h2>深度学习中的运筹优化：梯度下降与损失函数优化</h2>\n<p>在深度学习中，训练模型的目标是找到一组最优的参数，使得模型在给定任务上的性能最佳。这个过程可以看作是一个运筹优化问题，其中目标函数是模型的损失函数，而我们需要找到损失函数的最小值。梯度下降是深度学习中最常用的优化算法，它利用损失函数的梯度信息来迭代地更新模型参数，从而逼近最优解。</p>\n<p><strong>1. 损失函数 (Loss Function):</strong></p>\n<p>损失函数用于衡量模型预测值与真实值之间的差异。不同的任务需要使用不同的损失函数。一些常见的损失函数包括：</p>\n<ul>\n<li>\n<p><strong>均方误差 (MSE, Mean Squared Error):</strong>  常用于回归任务。\n$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$</p>\n</li>\n<li>\n<p><strong>交叉熵损失 (Cross-Entropy Loss):</strong> 常用于分类任务。\n$CE = -\\frac{1}{n} \\sum_{i=1}^{n} \\sum_{c=1}^{C} y_{ic} \\log(\\hat{y}_{ic})$</p>\n</li>\n<li>\n<p><strong>Hinge Loss:</strong> 常用于支持向量机 (SVM)。\n$Hinge = \\frac{1}{n} \\sum_{i=1}^{n} \\max(0, 1 - y_i \\hat{y}_i)$</p>\n</li>\n</ul>\n<p><strong>2. 梯度下降 (Gradient Descent):</strong></p>\n<p>梯度下降的核心思想是沿着损失函数的负梯度方向更新模型参数。参数更新公式如下：</p>\n<p>$\\theta_{t+1} = \\theta_t - \\eta \\nabla_{\\theta} L(\\theta_t)$</p>\n<p>其中：</p>\n<ul>\n<li>$\\theta_t$:  t 时刻的参数值</li>\n<li>$\\eta$: 学习率 (Learning Rate)，控制参数更新的步长</li>\n<li>$\\nabla_{\\theta} L(\\theta_t)$:  损失函数 $L$ 在 $\\theta_t$ 处的梯度</li>\n</ul>\n<p><strong>3. 梯度下降的变体:</strong></p>\n<p>为了提高梯度下降的效率和稳定性，人们提出了许多变体，包括：</p>\n<p><strong>1）批量梯度下降 (Batch Gradient Descent, BGD):</strong></p>\n<ul>\n<li><strong>原理:</strong>  每次迭代使用<strong>所有</strong>训练数据计算损失函数的梯度，然后沿着负梯度方向更新参数。</li>\n<li><strong>公式:</strong>\n<ul>\n<li>计算梯度:  $\\nabla_{\\theta} L(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} \\nabla_{\\theta} L_i(\\theta)$，其中 $N$ 是训练样本总数，$L_i(\\theta)$ 是第 $i$ 个样本的损失。</li>\n<li>更新参数: $\\theta_{t+1} = \\theta_t - \\eta \\nabla_{\\theta} L(\\theta_t)$</li>\n</ul>\n</li>\n<li><strong>优点:</strong>\n<ul>\n<li>收敛稳定，可以保证收敛到凸函数的全局最优解或非凸函数的局部最优解。</li>\n</ul>\n</li>\n<li><strong>缺点:</strong>\n<ul>\n<li>计算量大，每次迭代都需要遍历所有训练数据，对于大规模数据集来说效率很低。</li>\n<li>容易陷入局部最优解（尤其对于非凸函数）。</li>\n</ul>\n</li>\n</ul>\n<p><strong>2） 随机梯度下降 (Stochastic Gradient Descent, SGD):</strong></p>\n<ul>\n<li><strong>原理:</strong> 每次迭代<strong>随机</strong>选择<strong>一个</strong>训练样本计算损失函数的梯度，然后沿着负梯度方向更新参数。</li>\n<li><strong>公式:</strong>\n<ul>\n<li>计算梯度: $\\nabla_{\\theta} L(\\theta) \\approx \\nabla_{\\theta} L_i(\\theta)$，其中 $i$ 是随机选择的样本索引。</li>\n<li>更新参数: $\\theta_{t+1} = \\theta_t - \\eta \\nabla_{\\theta} L_i(\\theta_t)$</li>\n</ul>\n</li>\n<li><strong>优点:</strong>\n<ul>\n<li>计算速度快，每次迭代只处理一个样本。</li>\n<li>能够逃离一些局部最优解，因为随机性引入的噪声可以帮助跳出局部极小值。</li>\n</ul>\n</li>\n<li><strong>缺点:</strong>\n<ul>\n<li>收敛波动较大，参数更新方向不稳定。</li>\n<li>收敛速度较慢，需要更多的迭代次数才能达到较好的效果。</li>\n</ul>\n</li>\n</ul>\n<p><strong>3） 小批量梯度下降 (Mini-Batch Gradient Descent, MBGD):</strong></p>\n<ul>\n<li><strong>原理:</strong> 每次迭代使用一小批 (mini-batch) 训练样本计算损失函数的梯度，然后沿着负梯度方向更新参数。这是 BGD 和 SGD 的折衷方案。</li>\n<li><strong>公式:</strong>\n<ul>\n<li>计算梯度: $\\nabla_{\\theta} L(\\theta) \\approx \\frac{1}{m} \\sum_{i=1}^{m} \\nabla_{\\theta} L_i(\\theta)$，其中 $m$ 是 mini-batch 的大小。</li>\n<li>更新参数: $\\theta_{t+1} = \\theta_t - \\eta \\nabla_{\\theta} L(\\theta_t)$</li>\n</ul>\n</li>\n<li><strong>优点:</strong>\n<ul>\n<li>平衡了计算效率和收敛稳定性，既不像 BGD 那样计算量过大，也不像 SGD 那样收敛波动过大。</li>\n<li>可以利用矩阵运算加速计算，提高效率。</li>\n</ul>\n</li>\n<li><strong>缺点:</strong>\n<ul>\n<li>mini-batch 的大小需要调整，过大或过小都会影响性能。</li>\n</ul>\n</li>\n</ul>\n<p><strong>4） 动量梯度下降 (Momentum Gradient Descent):</strong></p>\n<ul>\n<li><strong>原理:</strong> 动量梯度下降的核心思想是累积之前的梯度信息，并用它来影响当前的参数更新方向。这就像给参数更新添加了一个“惯性项”，使其能够更快地收敛，并减少震荡。</li>\n<li><strong>公式:</strong>\n<ul>\n<li>$v_t = \\gamma v_{t-1} + \\eta \\nabla_{\\theta} L(\\theta_t)$</li>\n<li>$\\theta_{t+1} = \\theta_t - v_t$</li>\n<li>其中 $v_t$ 是动量项，$\\gamma$ 是动量系数 (通常设置为 0.9 左右)。</li>\n</ul>\n</li>\n<li><strong>优点:</strong>\n<ul>\n<li>加速收敛，尤其在峡谷型区域或高曲率区域。</li>\n<li>减少震荡，使参数更新更加平滑。</li>\n</ul>\n</li>\n</ul>\n<p><strong>5） RMSprop (Root Mean Square Propagation):</strong></p>\n<ul>\n<li><strong>原理:</strong>  自适应地调整学习率，对梯度的平方进行指数加权平均，从而更好地处理梯度变化较大的情况。</li>\n<li><strong>公式:</strong>\n<ul>\n<li>$E[g^2]<em>t = \\beta E[g^2]</em>{t-1} + (1-\\beta) g_t^2$</li>\n<li>$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{E[g^2]_t + \\epsilon}} g_t$</li>\n<li>其中 $g_t = \\nabla_{\\theta} L(\\theta_t)$，$\\beta$ 通常设置为 0.9，$\\epsilon$ 是一个很小的常数，防止除零。</li>\n</ul>\n</li>\n</ul>\n<p><strong>6） Adam (Adaptive Moment Estimation):</strong></p>\n<ul>\n<li><strong>原理:</strong> 结合了动量和 RMSprop 的优点，同时对梯度的一阶矩估计（均值）和二阶矩估计（未中心化的方差）进行指数加权平均。</li>\n</ul>\n<p><strong>Adam 算法步骤:</strong></p>\n<ol>\n<li>\n<p><strong>初始化:</strong>  将参数 $\\theta$、一阶矩估计 $m$、二阶矩估计 $v$ 初始化为零向量。设置学习率 $\\eta$、一阶矩衰减率 $\\beta_1$ (通常为 0.9)、二阶矩衰减率 $\\beta_2$ (通常为 0.999) 和一个很小的常数 $\\epsilon$ (通常为 $10^{-8}$) 以防止除零错误。</p>\n</li>\n<li>\n<p><strong>迭代更新:</strong>  对于每个时间步 $t$:</p>\n<ul>\n<li>\n<p>计算梯度:  $g_t = \\nabla_{\\theta} L(\\theta_t)$  (计算损失函数关于参数的梯度)</p>\n</li>\n<li>\n<p>更新一阶矩估计 (类似动量):  $m_t = \\beta_1 m_{t-1} + (1-\\beta_1)g_t$</p>\n</li>\n<li>\n<p>更新二阶矩估计 (类似 RMSprop):  $v_t = \\beta_2 v_{t-1} + (1-\\beta_2)g_t^2$</p>\n</li>\n<li>\n<p>修正一阶矩偏差: $\\hat{m}_t = \\frac{m_t}{1-\\beta_1^t}$</p>\n</li>\n<li>\n<p>修正二阶矩偏差: $\\hat{v}_t = \\frac{v_t}{1-\\beta_2^t}$</p>\n</li>\n<li>\n<p>更新参数: $\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t$</p>\n</li>\n</ul>\n</li>\n</ol>\n<p><strong>解释</strong></p>\n<ul>\n<li><strong>一阶矩估计 $m_t$:</strong>  相当于动量，累积了历史梯度信息，可以帮助算法更快地收敛，并穿越局部极小值或鞍点。</li>\n<li><strong>二阶矩估计 $v_t$:</strong> 类似 RMSprop，记录了历史梯度的平方，用于自适应地调整学习率。梯度变化较大的维度学习率会减小，梯度变化较小的维度学习率会增大。</li>\n<li><strong>偏差修正:</strong>  由于 $m_t$ 和 $v_t$ 初始值为 0，在训练初期它们的值会偏小。偏差修正通过除以 $(1-\\beta_1^t)$ 和 $(1-\\beta_2^t)$ 来弥补这个偏差，确保在早期迭代中 $\\hat{m}_t$ 和 $\\hat{v}_t$  是梯度的不偏估计。</li>\n</ul>\n<p><strong>补充 解释经常用到的AdamW 优化算法</strong></p>\n<p>AdamW 是 Adam 的一个变体，它对权重衰减的应用方式进行了改进。</p>\n<p><strong>Adam 中的权重衰减:</strong></p>\n<p>在标准的 Adam 算法中，权重衰减 (Weight Decay) 通常是通过在损失函数中添加 L2 正则化项来实现的。  这相当于在每次参数更新后，将参数乘以一个略小于 1 的因子。  然而，这种方式与 L2 正则化的理论推导并不完全一致，并且在某些情况下会导致次优解。</p>\n<p><strong>AdamW 的改进:</strong></p>\n<p>AdamW 将权重衰减与参数更新解耦，直接在参数更新步骤中应用权重衰减。  具体来说，AdamW 的参数更新公式如下：</p>\n<p>$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t - \\eta \\lambda \\theta_t$</p>\n<p>其中 $\\lambda$ 是权重衰减系数。</p>\n<p><strong>7） 牛顿法:</strong></p>\n<ul>\n<li><strong>原理:</strong> 使用二阶导数（Hessian 矩阵）的信息来指导参数更新，理论上可以更快地收敛。</li>\n<li><strong>公式:</strong> $\\theta_{t+1} = \\theta_t - H^{-1}(\\theta_t) \\nabla_{\\theta} L(\\theta_t)$，其中 $H(\\theta_t)$ 是 Hessian 矩阵。</li>\n<li><strong>优点:</strong>  收敛速度快。</li>\n<li><strong>缺点:</strong>\n<ul>\n<li>计算 Hessian 矩阵的逆矩阵计算量非常大，尤其对于高维参数空间。</li>\n<li>Hessian 矩阵可能不是正定的，导致算法不稳定。</li>\n<li>对初始值敏感。</li>\n</ul>\n</li>\n</ul>\n<p><strong>4. 损失函数优化的挑战:</strong></p>\n<p>在深度学习中，损失函数的优化通常面临以下挑战：</p>\n<ul>\n<li><strong>局部极小值 (Local Minima):</strong> 梯度下降可能陷入局部极小值，导致模型无法达到全局最优解。</li>\n<li><strong>鞍点 (Saddle Points):</strong>  鞍点处的梯度为零，但不是极值点，梯度下降可能会在鞍点附近停滞。</li>\n<li><strong>梯度消失/爆炸 (Vanishing/Exploding Gradients):</strong>  在深度神经网络中，梯度在反向传播过程中可能变得非常小或非常大，导致训练困难。</li>\n<li><strong>非凸性 (Non-convexity):</strong>  深度学习的损失函数通常是非凸的，这意味着存在多个局部极小值，找到全局最优解非常困难。</li>\n</ul>\n"}},3937:function(n){n.exports={attributes:{title:"亚马逊评论文本简要的分析",date:"2024-11-17T00:00:00.000Z",summary:"这是数据分析部分的代码的描述和一些注释",coverImage:"12-8-2.jpg",pinned:!1},html:"<p>我做的数据分析主要分为两个部分，其实这个第一个部分是后面补充的。</p>\n<h1>自己简单爬取数据然后自己分析</h1>\n<p>这是油猴脚本写的js脚本，直接丢进油猴里边就完事，代码编写耗时可能20分钟以内</p>\n<pre><code class=\"language-javascript\">// ==UserScript==\n// @name         amazon-scraper1\n// @namespace    http://tampermonkey.net/\n// @version      2024-11-06\n// @description  try to take over the world!\n// @author       suxing\n// @match        https://www.amazon.com/*\n// @icon         https://www.google.com/s2/favicons?sz=64&amp;domain=amazon.com\n// @grant        none\n// ==/UserScript==\n\n\n\nfunction main(){\n    new Promise((resolve)=&gt;{\n        console.log(&quot;amazonbutton&quot;);\n        setTimeout(()=&gt;{\n            resolve();\n        },2000)\n    }).then(()=&gt;{\n        let pageMain = document.querySelector(&quot;.sg-col-inner&quot;);\n        console.log(pageMain)\n        if(pageMain){\n            let button = document.createElement(&quot;button&quot;);\n            button.className=&quot;button-test&quot;\n            button.innerHTML = &quot;点击爬取json&quot;;\n            button.style.padding = &quot;10px 20px&quot;;\n            button.style.fontSize = &quot;16px&quot;;\n            button.style.backgroundColor = &quot;#4CAF50&quot;;\n            button.style.color = &quot;white&quot;;\n            button.style.border = &quot;none&quot;;\n            button.style.borderRadius = &quot;5px&quot;;\n            button.style.cursor = &quot;pointer&quot;;\n            button.style.boxShadow = &quot;0px 4px 6px rgba(0, 0, 0, 0.1)&quot;;\n            button.style.transition = &quot;background-color 0.3s&quot;;\n            button.onmouseover = function() {\n                button.style.backgroundColor = &quot;#45a049&quot;;\n            };\n            button.onmouseout = function() {\n                button.style.backgroundColor = &quot;#4CAF50&quot;;\n            };\n            button.onclick=()=&gt;{scrapefunc();}\n            var buttonContainer = document.createElement(&quot;div&quot;);\n            buttonContainer.style.display = &quot;flex&quot;;\n            buttonContainer.style.justifyContent = &quot;center&quot;;\n            buttonContainer.style.alignItems = &quot;center&quot;;\n            buttonContainer.style.height = &quot;100px&quot;; // 调整高度以便更好地居中\n            buttonContainer.appendChild(button);\n\n            // 在 pageMain 元素的上方插入按钮\n            pageMain.parentNode.insertBefore(buttonContainer, pageMain);\n        }\n    })\n}\n\nfunction exportjson(data){\n    const blob = new Blob([data], { type: 'application/json' });\n    const url = URL.createObjectURL(blob);\n    const a = document.createElement('a');\n    a.href = url;\n    const today = new Date();\n    const year = today.getFullYear();\n    const month = String(today.getMonth() + 1).padStart(2, '0');\n    const day = String(today.getDate()).padStart(2, '0');\n    const formattedDate = `${year}-${month}-${day}`;\n    a.download = `amazon-Products${formattedDate}.json`;\n    document.body.appendChild(a);\n    a.click();\n    document.body.removeChild(a);\n    URL.revokeObjectURL(url);\n}\nfunction scrapefunc(){\n    new Promise((resolve)=&gt;{\n        console.log(&quot;amazon-scraper test1&quot;);\n        setTimeout(()=&gt;{\n            resolve();\n        },700)\n    }).then(()=&gt;{\n        new Promise((resolve)=&gt;{\n            window.scrollTo({\n                top: 1000,\n                behavior: &quot;smooth&quot;\n            });\n            setTimeout(()=&gt;{\n                resolve();\n            },1000)\n        }).then(()=&gt;{\n            new Promise((resolve)=&gt;{\n                window.scrollTo({\n                    top: 4000,\n                    behavior: &quot;smooth&quot;\n                });\n                setTimeout(()=&gt;{\n                    resolve();\n                },1000)\n            }).then(()=&gt;{\n                new Promise((resolve)=&gt;{\n                    window.scrollTo({\n                        top: 8000,\n                        behavior: &quot;smooth&quot;\n                    });\n                    setTimeout(()=&gt;{\n                        resolve();\n                    },1000)\n                }).then(()=&gt;{\n                    new Promise((resolve)=&gt;{\n                        window.scrollTo({\n                            top: document.body.scrollHeight,\n                            behavior: &quot;smooth&quot;\n                        });\n                        setTimeout(()=&gt;{\n                            resolve();\n                        },700)\n                    }).then(()=&gt;{\n                        let productlist = [];\n                        document.querySelectorAll('div.a-section.a-spacing-small.puis-padding-left-small.puis-padding-right-small').forEach(container =&gt; {\n                            let product = {};\n\n                            // 标题和URL: 从商品标题容器获取\n                            try {\n                                const titleContainer = container.querySelector('[data-cy=&quot;title-recipe&quot;]');\n                                product.title = titleContainer.querySelector('.a-size-base-plus.a-color-base').textContent.trim();\n                                product.url = titleContainer.querySelector('a.a-link-normal').getAttribute('href');\n                            } catch (e) {\n                                product.title = '';\n                                product.url = '';\n                            }\n\n                            // 价格: 从价格容器获取\n                            try {\n                                const priceContainer = container.querySelector('[data-cy=&quot;price-recipe&quot;]');\n                                const priceElement = priceContainer.querySelector('.a-price .a-offscreen');\n                                product.price = priceElement ? priceElement.textContent.trim() : '';\n                            } catch (e) {\n                                product.price = '';\n                            }\n\n                            // 评分和评分数: 从评论容器获取\n                            try {\n                                const reviewsContainer = container.querySelector('[data-cy=&quot;reviews-block&quot;]');\n                                const ratingElement = reviewsContainer.querySelector('.a-icon-alt');\n                                product.rating = ratingElement ? ratingElement.textContent.trim() : '';\n\n                                const reviewsElement = reviewsContainer.querySelector('.rush-component .s-underline-text');\n                                product.ratingnum = reviewsElement ? reviewsElement.textContent.trim() : '';\n                            } catch (e) {\n                                product.rating = '';\n                                product.ratingnum = '';\n                            }\n\n                            if (product.title) {  // 只添加有标题的商品\n                                productlist.push(product);\n                            }\n                        });\n                        const productListJson = JSON.stringify(productlist, null, 2);\n                        console.log(productListJson);\n                        exportjson(productListJson);\n                        const nexturl=document.querySelector(&quot;.s-pagination-next&quot;).getAttribute(&quot;href&quot;)\n                        window.scrollTo({\n                            top: 0,\n                            behavior: &quot;smooth&quot;\n                        });\n                        new Promise((resolve)=&gt;{\n                            setTimeout(()=&gt;{\n                                resolve();\n                            },500)\n                        }).then(()=&gt;{\n                            location.href=nexturl\n                        })\n\n                    })\n                })\n            })\n        })\n    })\n}\n\n\n\n\n\nwindow.addEventListener(&quot;load&quot;,()=&gt;{\n    main();\n\n},false)\n</code></pre>\n<h2>python分析代码</h2>\n<pre><code class=\"language-python\"></code></pre>\n<h1>深度学习模型构建部分</h1>\n<h2>简要数据分析</h2>\n<pre><code class=\"language-python\"># 导入所需库\nfrom datasets import load_dataset\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertTokenizer\n\n# 加载数据集，并取前2000条数据\ndataset = load_dataset(&quot;McAuley-Lab/Amazon-Reviews-2023&quot;, &quot;raw_review_All_Beauty&quot;, trust_remote_code=True)\ndata = pd.DataFrame(dataset[&quot;full&quot;][:10000])  # 仅取2000条数据\nprint(data.head())\n\n# 1. 词云生成\nall_text = &quot; &quot;.join(data[&quot;text&quot;].fillna(&quot;&quot;))\nwordcloud = WordCloud(width=800, height=400, background_color=&quot;white&quot;).generate(all_text)\n\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation=&quot;bilinear&quot;)\nplt.axis(&quot;off&quot;)\nplt.title(&quot;Word Cloud of Amazon Reviews&quot;)\nplt.show()\n\n# 2. 用户画像分析\n# 评分分布\nplt.figure(figsize=(8, 5))\nsns.histplot(data[&quot;rating&quot;], bins=5, kde=True)\nplt.xlabel(&quot;Rating&quot;)\nplt.title(&quot;Distribution of Ratings&quot;)\nplt.show()\n\n# 验证购买分析\nverified_purchase_counts = data[&quot;verified_purchase&quot;].value_counts()\nplt.figure(figsize=(8, 5))\nsns.barplot(x=verified_purchase_counts.index, y=verified_purchase_counts.values)\nplt.xlabel(&quot;Verified Purchase&quot;)\nplt.ylabel(&quot;Count&quot;)\nplt.title(&quot;Distribution of Verified Purchases&quot;)\nplt.show()\n\n# 3. 时间序列分析：评论随时间的变化\ndata[&quot;timestamp&quot;] = pd.to_datetime(data[&quot;timestamp&quot;], unit=&quot;ms&quot;)  # 转换时间戳为日期格式\ndata.set_index(&quot;timestamp&quot;, inplace=True)\ndata[&quot;rating&quot;].resample(&quot;M&quot;).mean().plot(figsize=(12, 6))\nplt.title(&quot;Average Rating Over Time (Monthly)&quot;)\nplt.xlabel(&quot;Time&quot;)\nplt.xlim(pd.Timestamp(&quot;2012-01-01&quot;), pd.Timestamp(&quot;2023-12-31&quot;))\nplt.ylabel(&quot;Average Rating&quot;)\nplt.show()\n\n# 4. 评论字数分析\ndata[&quot;review_length&quot;] = data[&quot;text&quot;].apply(lambda x: len(str(x).split()))  # 计算每条评论的词数\ndata[&quot;review_length&quot;].resample(&quot;M&quot;).mean().plot(figsize=(12, 6))\nplt.title(&quot;Average Review Length Over Time (Monthly)&quot;)\nplt.xlabel(&quot;Time&quot;)\nplt.xlim(pd.Timestamp(&quot;2012-01-01&quot;), pd.Timestamp(&quot;2023-12-31&quot;))\nplt.ylabel(&quot;Average Review Length&quot;)\nplt.show()\n\n\n\n\n\n</code></pre>\n"}},9317:function(n){n.exports={attributes:{title:"（考研待开坑）YOLO计算机视觉&目标检测模型",date:"2024-11-01T00:00:00.000Z",summary:"在尝试的学习CV技术",coverImage:"12-8-2.jpg",pinned:!1},html:"<h1>学点CV</h1>\n<p>（CV太烧内存了，6G不够用。。。所以还没开始跑代码）</p>\n<p>你以为的YOLO ：<strong>you only look once</strong></p>\n<p>我以为的YOLO： <strong>YOU ONLY LIVE ONCE</strong></p>\n<p><strong>珍爱生命，远离深度学习啊！！</strong></p>\n<h1>常见的视觉任务</h1>\n<ol>\n<li>最简单的任务：图片分类</li>\n<li>进阶：语义分割</li>\n<li>再进阶：目标检测（锚框选定）</li>\n<li>更加高端：3维预测（如路面检测无人车自动驾驶）</li>\n<li>运动监测（肢体检测，嘴型）</li>\n</ol>\n<h1>研究一下YOLO的模型结构</h1>\n<p>以YOLOv3为例</p>\n<ol>\n<li>\n<p>输入:  模型的输入是一张图片。</p>\n</li>\n<li>\n<p>骨干网络 (Backbone Network):  用于提取图像特征。YOLOv3 使用 Darknet-53 作为骨干网络，它是一个 53 层的卷积神经网络，具有残差连接，可以有效地提取图像特征。</p>\n</li>\n<li>\n<p>特征金字塔网络 (Feature Pyramid Network, FPN):  用于在不同尺度上检测目标。FPN 将骨干网络提取的不同层级的特征图进行融合，生成多个尺度的特征图，从而可以检测不同大小的目标。</p>\n</li>\n<li>\n<p>检测头 (Detection Head):  用于预测目标的类别和位置。YOLOv3 的检测头包含三个分支，分别对应三个不同的尺度。每个分支都包含一系列卷积层，最终输出一个三维张量，其中包含每个网格单元的预测信息。</p>\n</li>\n</ol>\n<p>将输入图像分成 S x S 个网格单元。\n每个网格单元负责预测 B 个边界框和 C 个类别概率。\n每个边界框包含 5 个预测值：x，y，w，h 和置信度。\n(x, y) 是边界框中心相对于网格单元的坐标。\n(w, h) 是边界框的宽度和高度相对于整张图片的比例。\n置信度表示边界框包含目标的概率以及边界框的准确度。\n每个网格单元还会预测 C 个类别概率，表示该网格单元包含某个类别的目标的概率。</p>\n"}},2879:function(n){n.exports={attributes:{title:"用亚马逊评论数据，玩一下生成式模型",date:"2024-11-01T00:00:00.000Z",summary:"学习一下生成式模型",coverImage:"12-8-2.jpg",pinned:!1},html:"<h1>T5预训练模型上做微调</h1>\n<pre><code class=\"language-python\"># 导入所需库\nfrom datasets import load_dataset\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nfrom transformers import (\n    T5ForConditionalGeneration, T5Tokenizer,\n    get_linear_schedule_with_warmup\n)\nimport gc\nfrom torch.utils.data import DataLoader, Dataset\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport pandas as pd\nimport copy\nimport os\nimport random\nfrom torch.nn.utils.rnn import pad_sequence\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom collections import Counter\nimport re\n\n# 下载必要的NLTK数据\nnltk.download('punkt')\nnltk.download('wordnet')\nfrom nltk.corpus import wordnet\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nset_seed()\n# 数据增强方法\nclass TextAugmenter:\n    @staticmethod\n    def synonym_replacement(text, n=1):\n        words = word_tokenize(text)\n        new_words = words.copy()\n        random_word_list = list(set([word for word in words if word.isalnum()]))\n        n = min(n, len(random_word_list))\n        \n        for _ in range(n):\n            random_word = random.choice(random_word_list)\n            synonyms = []\n            for syn in wordnet.synsets(random_word):\n                for lemma in syn.lemmas():\n                    synonyms.append(lemma.name())\n            if len(synonyms) &gt; 0:\n                synonym = random.choice(list(set(synonyms)))\n                random_idx = random.randint(0, len(words) - 1)\n                new_words[random_idx] = synonym\n        \n        return ' '.join(new_words)\n\n    @staticmethod\n    def random_deletion(text, p=0.1):\n        words = word_tokenize(text)\n        if len(words) == 1:\n            return text\n        \n        new_words = []\n        for word in words:\n            if random.random() &gt; p:\n                new_words.append(word)\n        \n        if len(new_words) == 0:\n            rand_int = random.randint(0, len(words)-1)\n            new_words.append(words[rand_int])\n            \n        return ' '.join(new_words)\n\n    @staticmethod\n    def random_swap(text, n=1):\n        words = word_tokenize(text)\n        new_words = words.copy()\n        for _ in range(n):\n            if len(new_words) &gt;= 2:\n                idx1, idx2 = random.sample(range(len(new_words)), 2)\n                new_words[idx1], new_words[idx2] = new_words[idx2], new_words[idx1]\n        return ' '.join(new_words)\n\nclass ReviewGenerationDataset(Dataset):\n    def __init__(self, texts, ratings, tokenizer, max_len=128, augment=False):\n        # 将Series转换为list以避免索引问题\n        self.texts = texts.tolist()\n        self.ratings = ratings.tolist()\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.augment = augment\n        self.augmenter = TextAugmenter()\n\n    def __len__(self):\n        return len(self.texts)\n\n    def augment_text(self, text):\n        augmentation_ops = [\n            (self.augmenter.synonym_replacement, {'n': 1}),\n            (self.augmenter.random_deletion, {'p': 0.1}),\n            (self.augmenter.random_swap, {'n': 1})\n        ]\n        op, params = random.choice(augmentation_ops)\n        return op(text, **params)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        rating = self.ratings[idx]\n        \n        if self.augment and random.random() &lt; 0.3:\n            text = self.augment_text(text)\n        \n        prompt = f&quot;Generate a {rating}-star review:&quot;\n        \n        prompt_encoding = self.tokenizer(\n            prompt,\n            max_length=32,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        target_encoding = self.tokenizer(\n            text,\n            max_length=self.max_len,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n\n        return {\n            'input_ids': prompt_encoding['input_ids'].squeeze(),\n            'attention_mask': prompt_encoding['attention_mask'].squeeze(),\n            'labels': target_encoding['input_ids'].squeeze(),\n            'decoder_attention_mask': target_encoding['attention_mask'].squeeze()\n        }\n\n\nclass ReviewGenerator(nn.Module):\n    def __init__(self, model_name=&quot;t5-base&quot;):\n        super().__init__()\n        self.model = T5ForConditionalGeneration.from_pretrained(model_name)\n        # 启用梯度检查点以减少内存使用\n        self.model.gradient_checkpointing_enable()\n        \n    def forward(self, input_ids, attention_mask, labels=None, decoder_attention_mask=None):\n        outputs = self.model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels,\n            decoder_attention_mask=decoder_attention_mask\n        )\n        return outputs\n\n\ndef prepare_data(batch_size=8):  # 减小batch size以降低内存使用\n    # 加载数据集\n    dataset = load_dataset(&quot;McAuley-Lab/Amazon-Reviews-2023&quot;, &quot;raw_review_All_Beauty&quot;, trust_remote_code=True)\n    data = pd.DataFrame(dataset[&quot;full&quot;][:200000])\n    \n    # 数据清洗\n    data['text'] = data['text'].fillna(&quot;&quot;).astype(str)\n    data = data[data['text'].str.len() &gt; 10]\n    data = data.reset_index(drop=True)\n    \n    # 划分训练集和验证集\n    train_texts, val_texts, train_ratings, val_ratings = train_test_split(\n        data['text'], data['rating'],\n        test_size=0.1,\n        random_state=42\n    )\n    \n    tokenizer = T5Tokenizer.from_pretrained('t5-base', model_max_length=512)  # 减小max_length\n    \n    train_dataset = ReviewGenerationDataset(train_texts, train_ratings, tokenizer, augment=True)\n    val_dataset = ReviewGenerationDataset(val_texts, val_ratings, tokenizer, augment=False)\n    \n    train_loader = DataLoader(\n        train_dataset, \n        batch_size=batch_size, \n        shuffle=True,\n        drop_last=True,\n        pin_memory=True  # 启用pin_memory加速数据传输\n    )\n    val_loader = DataLoader(\n        val_dataset, \n        batch_size=batch_size,\n        drop_last=True,\n        pin_memory=True\n    )\n    \n    return train_loader, val_loader, tokenizer\n\n\ndef train_generator(model, train_loader, val_loader, epochs=5, save_dir=&quot;generator_checkpoints&quot;, \n                   gradient_accumulation_steps=4):\n    # 创建输出目录\n    os.makedirs(save_dir, exist_ok=True)\n    os.makedirs(&quot;generative-output&quot;, exist_ok=True)\n    \n    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n    num_training_steps = (len(train_loader) // gradient_accumulation_steps) * epochs\n    num_warmup_steps = num_training_steps // 10\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=num_warmup_steps,\n        num_training_steps=num_training_steps\n    )\n    \n    best_val_loss = float('inf')\n    train_losses = []\n    val_losses = []\n    \n    for epoch in range(epochs):\n        model.train()\n        total_train_loss = 0\n        optimizer.zero_grad()\n        \n        with tqdm(total=len(train_loader), desc=f&quot;Epoch {epoch+1}/{epochs}&quot;) as pbar:\n            for batch_idx, batch in enumerate(train_loader):\n                # 将数据移动到GPU\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['labels'].to(device)\n                decoder_attention_mask = batch['decoder_attention_mask'].to(device)\n                \n                outputs = model(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    labels=labels,\n                    decoder_attention_mask=decoder_attention_mask\n                )\n                \n                loss = outputs.loss / gradient_accumulation_steps\n                total_train_loss += loss.item() * gradient_accumulation_steps\n                \n                loss.backward()\n                \n                if (batch_idx + 1) % gradient_accumulation_steps == 0:\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n                    optimizer.step()\n                    scheduler.step()\n                    optimizer.zero_grad()\n                    \n                    # 清理缓存\n                    if torch.cuda.is_available():\n                        torch.cuda.empty_cache()\n                \n                pbar.update(1)\n                pbar.set_postfix({\n                    'train_loss': f'{loss.item() * gradient_accumulation_steps:.4f}'\n                })\n        \n        # 处理最后一个不完整的累积步\n        if len(train_loader) % gradient_accumulation_steps != 0:\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n            scheduler.step()\n            optimizer.zero_grad()\n        \n        # 评估阶段\n        model.eval()\n        total_val_loss = 0\n        \n        with torch.no_grad():\n            for batch in val_loader:\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['labels'].to(device)\n                decoder_attention_mask = batch['decoder_attention_mask'].to(device)\n                \n                outputs = model(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    labels=labels,\n                    decoder_attention_mask=decoder_attention_mask\n                )\n                \n                total_val_loss += outputs.loss.item()\n        \n        avg_train_loss = total_train_loss / len(train_loader)\n        avg_val_loss = total_val_loss / len(val_loader)\n        \n        train_losses.append(avg_train_loss)\n        val_losses.append(avg_val_loss)\n        \n        print(f&quot;\\nEpoch {epoch+1}&quot;)\n        print(f&quot;Average training loss: {avg_train_loss:.4f}&quot;)\n        print(f&quot;Average validation loss: {avg_val_loss:.4f}&quot;)\n        \n        if avg_val_loss &lt; best_val_loss:\n            best_val_loss = avg_val_loss\n            torch.save(model.state_dict(), f&quot;{save_dir}/best_model.pth&quot;)\n            print(&quot;Saved new best model!&quot;)\n        \n        # 绘制并保存loss曲线\n        plt.figure(figsize=(10, 6))\n        plt.plot(range(1, epoch + 2), train_losses, label='Training Loss')\n        plt.plot(range(1, epoch + 2), val_losses, label='Validation Loss')\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.title('Training and Validation Loss')\n        plt.legend()\n        plt.grid(True)\n        plt.savefig('generative-output/loss_curve.png')\n        plt.close()\n        \n        # 强制进行垃圾回收\n        gc.collect()\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n\n\ndef generate_review(model, tokenizer, rating, max_length=150):\n    model.eval()\n    prompt = f&quot;Generate a {rating}-star review:&quot;\n    \n    inputs = tokenizer(\n        prompt,\n        return_tensors=&quot;pt&quot;,\n        max_length=32,\n        padding=True,\n        truncation=True\n    ).to(device)\n    \n    with torch.no_grad():\n        outputs = model.model.generate(\n            input_ids=inputs[&quot;input_ids&quot;],\n            attention_mask=inputs[&quot;attention_mask&quot;],\n            max_length=max_length,\n            num_beams=5,\n            no_repeat_ngram_size=2,\n            top_k=50,\n            top_p=0.95,\n            temperature=0.7,\n            do_sample=True\n        )\n    \n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return generated_text\n\n\ndef main():\n    # 清理GPU内存\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        \n    train_loader, val_loader, tokenizer = prepare_data()\n    model = ReviewGenerator().to(device)\n    train_generator(model, train_loader, val_loader)\n    \n    # 生成示例评论\n    model.load_state_dict(torch.load(&quot;generator_checkpoints/best_model.pth&quot;))\n    \n    for rating in [1, 3, 5]:\n        print(f&quot;\\nGenerated {rating}-star review:&quot;)\n        review = generate_review(model, tokenizer, rating)\n        print(review)\n\nif __name__ == &quot;__main__&quot;:\n    main()\n</code></pre>\n"}},3352:function(n){n.exports={attributes:{title:"亚马逊评论数据做文本情感分类模型",date:"2024-12-08T00:00:00.000Z",summary:"在尝试的学习NLP技术",coverImage:"12-8-2.jpg",pinned:!0},html:'<h1>亚马逊评论数据分析</h1>\n<h2>跨境电商背景</h2>\n<p>目前跨境电商蓬勃发展，为了抓住这一风口，深入了解外国电商平台至关重要。亚马逊作为全球最大、流量最高的国际电商平台，是跨境电商入门研究的首选。</p>\n<p>本文首先对亚马逊商品数据和评论数据进行简要分析，然后基于评论数据构建深度学习模型进行情感分类，以预测评论的情感倾向（正面、中性、负面）。</p>\n<h2>数据获取</h2>\n<p>使用 Tampermonkey 脚本进行网页数据采集，优势在于快速简便，几分钟即可完成脚本编写，并利用 JS 操作 DOM。然而，多页面采集较为繁琐，因为网页访问是手动进行的。</p>\n<p><strong>脚本逻辑:</strong></p>\n<ol>\n<li>加载亚马逊网站时，在导航栏等区域添加一个按钮，点击即可爬取当前页面商品信息。</li>\n<li>点击按钮后，刷新页面模拟真人操作，滚动至底部等待刷新完成。</li>\n<li>使用 JS CSS 选择器定位商品框，遍历提取标题、价格等信息。</li>\n</ol>\n<p><strong>(附带数据获取的图片)</strong></p>\n<p><strong>问题:</strong>  网站使用哈希法或不写类名，需要调整定位策略，从单用类名/ID 定位到结合层级定位。</p>\n<h2>数据处理</h2>\n<p>使用 Python 脚本处理数据：</p>\n<ol>\n<li>合并 JSON 文件，清理数据。</li>\n<li>将价格、评分转换为浮点数，评论数量转换为整数。</li>\n<li>删除重复项。</li>\n</ol>\n<h2>数据可视化</h2>\n<p>使用 Python 脚本对处理后的数据进行可视化：</p>\n<p><strong>(附带词云图，价格分布曲线图，价格与评分关系图，评分分布图)</strong></p>\n<h2>在 PySpark 上运行 Python 脚本</h2>\n<p>在已配置 Spark 和 PySpark 的环境下：</p>\n<ol>\n<li>创建并激活 Python 虚拟环境。</li>\n<li>使用 pip 安装依赖库。</li>\n<li>运行脚本并保存可视化图片。</li>\n</ol>\n<h2>进阶分析：开源数据</h2>\n<h3>问题背景分析</h3>\n<p>在前述商品数据分析基础上，本文利用开源大型数据集构建深度学习模型，进行文本情感分析。通过不断调整模型和参数，验证集准确率从 0.6 提升至 0.9 以上。</p>\n<h3>数据分析步骤</h3>\n<ol>\n<li>\n<p><strong>数据选择:</strong> Hugging Face 平台上的 Amazon_reviews-2023 数据集。选择开源数据集的优势在于：</p>\n<ul>\n<li>数据量庞大，无需担心数据缺失。</li>\n<li>数据经过预处理，可直接进行分析。</li>\n<li>数据开源维护，具有较高的鲁棒性和泛化性。</li>\n</ul>\n</li>\n<li>\n<p><strong>数据描述:</strong> (数据集大小，格式示例)</p>\n</li>\n<li>\n<p><strong>具体分析步骤:</strong></p>\n<ul>\n<li>数据分析和可视化：词云分析、用户画像分析、时间序列分析。</li>\n<li>机器学习模型：构建神经网络模型进行文本情感分析。</li>\n</ul>\n</li>\n</ol>\n<h3>数据简要分析和可视化</h3>\n<p><strong>(附带词云图，评分分布图，验证购买分析图，用户相似度热力图，时间序列分析图)</strong></p>\n<h3>文本情感分析模型</h3>\n<h4>模型初步构建</h4>\n<p><strong>模型 1-1 (回归):</strong></p>\n<ul>\n<li>结构: BERT 分词 + Embedding + LSTM + 全连接层(tanh)</li>\n<li>问题: 拟合效果异常，验证集损失很高。</li>\n</ul>\n<p><strong>模型 1-2 (分类):</strong></p>\n<ul>\n<li>结构: Embedding + LSTM + 全连接层 + Softmax</li>\n<li>损失函数: 交叉熵</li>\n<li>问题: 验证集准确度低，模型过于简单。</li>\n</ul>\n<p><strong>模型 1-3 (双层 LSTM):</strong></p>\n<ul>\n<li>结构: 双层 LSTM</li>\n<li>问题: 准确率仍低，主要预测五星评论，收敛过快。</li>\n</ul>\n<p><strong>模型 1-4 (双向 LSTM + 注意力):</strong></p>\n<ul>\n<li>结构: 双向 LSTM + 注意力机制 + 多层全连接 + Dropout</li>\n<li>优化器: AdamW + 权重衰减 + 梯度裁剪</li>\n<li>其他: 分层学习率，模型保存，RMSE 评估</li>\n<li>结果: 性能显著提升，能预测其他星级评论。</li>\n<li>问题: 1-4 星评论预测效果仍需改进。</li>\n</ul>\n<p><strong>(附带模型结构图、公式、训练曲线图、混淆矩阵)</strong></p>\n<h4>在 BERT 预训练模型上做微调 (Fine-tune)</h4>\n<p><strong>模型 1-5 (BERT 微调):</strong></p>\n<ul>\n<li>结构: BERT + 分类头 (全连接 + ReLU + Dropout) + Softmax</li>\n<li>优化: 差异化学习率，权重衰减</li>\n<li>结果: 性能进一步提升。</li>\n</ul>\n<p><strong>模型 1-6 (数据增强 &amp; 训练策略优化):</strong></p>\n<ul>\n<li>模型: Dropout 调整为 0.5, 添加 BatchNorm, 冻结 BERT 底层</li>\n<li>训练: 分层采样, warmup 学习率</li>\n<li>数据: 动态文本裁剪, 增大批量大小</li>\n<li>结果: 缓解过拟合，性能略有提升。</li>\n</ul>\n<p><strong>模型 1-7 (数据平衡):</strong></p>\n<ul>\n<li>数据: 3-4 星过采样和文本增强，加权采样</li>\n<li>损失函数: 加权交叉熵</li>\n<li>结果: 3-4 星评论预测提升，但 5 星误判率增加。</li>\n</ul>\n<p><strong>模型 1-8 (模型结构优化):</strong></p>\n<ul>\n<li>模型: 多头注意力 + 特征增强层 (LayerNorm + Dropout)</li>\n<li>训练: warmup 学习率，分层学习率，早停</li>\n<li>结果: 准确率大幅提升，但出现过拟合。</li>\n</ul>\n<p><strong>模型 1-9 (更复杂的分类头 &amp; 训练策略优化):</strong></p>\n<ul>\n<li>模型: 更复杂的分类头</li>\n<li>训练: 余弦退火学习率 + warmup，更高初始学习率，断点续训，注意力可视化</li>\n<li>结果: 准确率达到 0.92，仍有少量过拟合。</li>\n</ul>\n<p><strong>(附带模型结构图，训练曲线图，混淆矩阵，注意力可视化结果)</strong></p>\n<h4>其他可实现模型</h4>\n<ul>\n<li>\n<p><strong>MAMBA 模型:</strong> 优势明显，但目前仅支持 Linux 系统。</p>\n</li>\n<li>\n<p><strong>其他预训练模型:</strong> RoBERTa, XLNet, ELECTRA, FinBERT, DeBERTa, ERNIE 等。</p>\n</li>\n<li>\n<p><strong>多语言文本情感分析模型:</strong>  使用 XLM-RoBERTa-base 构建，中英文测试结果良好，但在中性评论预测方面置信度较低。</p>\n</li>\n<li>\n<p><strong>生成式预训练模型:</strong> 使用 T5 模型进行初步实验，未来可使用更大数据集和更合适的模型 (如 GPT 系列) 提升性能。</p>\n</li>\n</ul>\n<h3>模型解释及不足</h3>\n<ul>\n<li>模型假设文本情绪与评分绑定，可能存在不符合此假设的数据，导致假中性和假正向性。</li>\n<li>数据量相对较小，限制了模型的泛化能力。</li>\n<li>未划分测试集，仅使用验证集评估模型性能。</li>\n<li>未使用 AllBeauty 全部数据集，因为数据量增加后性能反而下降，表明需要更复杂的模型和更多数据。</li>\n</ul>\n<h3>其他补充</h3>\n<ul>\n<li>配置说明: 初期使用 TensorFlow，后期使用 PyTorch + CUDA。</li>\n<li>训练补充:  记录了模型调试过程中遇到的问题和解决方法.</li>\n</ul>\n<h3>源码附录和参考文献</h3>\n<ul>\n<li>在线链接\n<a href="/posts/etc/dl.rar">所有源码压缩包</a></li>\n<li>博客: https://suxing.online/#/</li>\n<li>参考文献:  列出了 LSTM、双向 RNN、注意力机制、Transformer、BERT、T5、Mamba 等模型的相关论文。</li>\n</ul>\n'}},277:function(n){n.exports={attributes:{title:"记录一下写过的爬虫脚本",date:"2024-11-16T00:00:00.000Z",summary:"写的都是js脚本",coverImage:"post2-1.png",pinned:!1},html:"<p><s>不会有人还在写python脚本吧？</s>  <br>\n无论是什么语言写的脚本，都必须要操作DOM  <br>\n既然都操作都操作DOM了，我何不用JS来写呢？ \\</p>\n<p>下文记录一下自己写过的爬虫脚本，数据整理代码写在另一篇了。</p>\n<h1>pipiads的爬虫脚本</h1>\n<p>pipiads上面主要有tiktok小店的数据，和一些广告的数据。</p>\n<h2>主要是爬取商品数据的信息</h2>\n<pre><code class=\"language-javascript\">\n// ==UserScript==\n// @name         皮皮一键爬取\n// @namespace    http://tampermonkey.net/\n// @version      2024-09-14\n// @description  try to take over the world!\n// @author       suxing\n// @match        https://www.pipiads.com/*\n// @icon         https://www.google.com/s2/favicons?sz=64&amp;domain=pipiads.com\n// @grant        none\n// ==/UserScript==\n\n\nfunction main(){\n    new Promise((resolve)=&gt;{\n        console.log(&quot;pipiads-button1&quot;);\n        setTimeout(()=&gt;{\n            resolve();\n        },4000)\n    }).then(()=&gt;{\n        let pageMain = document.querySelector(&quot;.main-container&quot;);\n        console.log(pageMain)\n        if(pageMain){\n            const task1Button = document.createElement(&quot;button&quot;);\n            task1Button.className = &quot;button-test&quot;;\n            task1Button.innerHTML = &quot;任务1 小店爬取&quot;;\n            styleButton(task1Button);\n            task1Button.onclick=()=&gt;{task1();}\n\n            const task2Button = document.createElement(&quot;button&quot;);\n            task2Button.className = &quot;button-test&quot;;\n            task2Button.innerHTML = &quot;任务2 产品爬取&quot;;\n            styleButton(task2Button);\n            task2Button.onclick=()=&gt;{task2();}\n            \n\n            var buttonContainer = document.createElement(&quot;div&quot;);\n            buttonContainer.style.display = &quot;flex&quot;;\n            buttonContainer.style.justifyContent = &quot;center&quot;;\n            buttonContainer.style.alignItems = &quot;center&quot;;\n            buttonContainer.style.height = &quot;100px&quot;;\n            buttonContainer.appendChild(task1Button);\n            buttonContainer.appendChild(task2Button);\n            pageMain.parentNode.insertBefore(buttonContainer, pageMain);\n\n\n        }\n    })\n}\n\nfunction exportjson(data,taskname){\n    const blob = new Blob([data], { type: 'application/json' });\n    const url = URL.createObjectURL(blob);\n    const a = document.createElement('a');\n    a.href = url;\n    const today = new Date();\n    const year = today.getFullYear();\n    const month = String(today.getMonth() + 1).padStart(2, '0');\n    const day = String(today.getDate()).padStart(2, '0');\n    const formattedDate = `${year}-${month}-${day}`;\n    a.download = `${taskname}-${formattedDate}.json`;\n    document.body.appendChild(a);\n    a.click();\n    document.body.removeChild(a);\n    URL.revokeObjectURL(url);\n}\nfunction task2(){\n    new Promise((resolve)=&gt;{\n        console.log(&quot;pipiads-scraper test1&quot;);\n        setTimeout(()=&gt;{\n            resolve();\n        },700)\n    }).then(()=&gt;{\n        new Promise((resolve)=&gt;{\n            window.scrollTo({\n                top: 7000,\n                behavior: &quot;smooth&quot;\n            });\n            setTimeout(()=&gt;{\n                resolve();\n            },1000)\n        }).then(()=&gt;{\n            new Promise((resolve)=&gt;{\n                window.scrollTo({\n                    top: 14000,\n                    behavior: &quot;smooth&quot;\n                });\n                setTimeout(()=&gt;{\n                    resolve();\n                },1000)\n            }).then(()=&gt;{\n                new Promise((resolve)=&gt;{\n                    window.scrollTo({\n                        top: 21000,\n                        behavior: &quot;smooth&quot;\n                    });\n                    setTimeout(()=&gt;{\n                        resolve();\n                    },1000)\n                }).then(()=&gt;{\n                    new Promise((resolve)=&gt;{\n                        window.scrollTo({\n                            top: document.body.scrollHeight,\n                            behavior: &quot;smooth&quot;\n                        });\n                        setTimeout(()=&gt;{\n                            resolve();\n                        },700)\n                    }).then(()=&gt;{\n                        let productlist=[];\n                        document.querySelectorAll(&quot;ul.wt-block-grid&gt;li.wt-block-grid__item&quot;).forEach(li=&gt;{\n                            let title=li.querySelector(&quot;a.title.a-link&quot;).innerText;\n                            let url=li.querySelector(&quot;a.title.a-link&quot;).getAttribute(&quot;href&quot;);\n                            let price=&quot;&quot;\n                            try{\n                                price=li.querySelector(&quot;.price-box&quot;).innerText.replace(/[()]/g, &quot;&quot;);\n                            }catch{\n                                price=&quot;&quot;;\n                            }\n                            let datablock=li.querySelector(&quot;.data-count&quot;);\n                            var i=0;\n                            let temp=[];\n                            datablock.querySelectorAll(&quot;.item&quot;).forEach(item=&gt;{\n                                if(i==0){let thumb=item.querySelector(&quot;.value&quot;).innerText;temp.push(thumb)}\n                                if(i==1){let ads=item.querySelector(&quot;.value&quot;).innerText;temp.push(ads)}\n                                if(i==2){let increase=item.querySelector(&quot;.value&quot;).innerText;temp.push(increase)}\n                                i++;\n                            })\n                            let products={\n                                &quot;title&quot;:title,\n                                &quot;url&quot;:url,\n                                &quot;price&quot;:price,\n                                &quot;thumb&quot;:temp[0],\n                                &quot;ads&quot;:temp[1],\n                                &quot;increase&quot;:temp[2],\n                            }\n                            productlist.push(products);\n\n                        })\n                        const productListJson = JSON.stringify(productlist, null, 2);\n                        console.log(productListJson);\n                        exportjson(productListJson,&quot;task2&quot;);\n                        window.scrollTo({\n                            top: 0,\n                            behavior: &quot;smooth&quot;\n                        });\n                    })\n                })\n            })\n        })\n    })\n}\n\nfunction task1(){\n    new Promise((resolve)=&gt;{\n        console.log(&quot;pipiads-scraper test1&quot;);\n        setTimeout(()=&gt;{\n            resolve();\n        },700)\n    }).then(()=&gt;{\n        new Promise((resolve)=&gt;{\n            window.scrollTo({\n                top: 7000,\n                behavior: &quot;smooth&quot;\n            });\n            setTimeout(()=&gt;{\n                resolve();\n            },1000)\n        }).then(()=&gt;{\n            new Promise((resolve)=&gt;{\n                window.scrollTo({\n                    top: 14000,\n                    behavior: &quot;smooth&quot;\n                });\n                setTimeout(()=&gt;{\n                    resolve();\n                },1000)\n            }).then(()=&gt;{\n                new Promise((resolve)=&gt;{\n                    window.scrollTo({\n                        top: 21000,\n                        behavior: &quot;smooth&quot;\n                    });\n                    setTimeout(()=&gt;{\n                        resolve();\n                    },1000)\n                }).then(()=&gt;{\n                    new Promise((resolve)=&gt;{\n                        window.scrollTo({\n                            top: document.body.scrollHeight,\n                            behavior: &quot;smooth&quot;\n                        });\n                        setTimeout(()=&gt;{\n                            resolve();\n                        },700)\n                    }).then(()=&gt;{\n                        let productlist=[];\n                        document.querySelectorAll(&quot;ul.wt-block-grid&gt;li.wt-block-grid__item&quot;).forEach(li=&gt;{\n                            let title=li.querySelector(&quot;a.title.a-link&quot;).innerText;\n                            let url=li.querySelector(&quot;a.title.a-link&quot;).getAttribute(&quot;href&quot;);\n                            let price=&quot;&quot;\n                            try{\n                                price=li.querySelector(&quot;span.usdPrice&quot;).innerText.replace(/[()]/g, &quot;&quot;);\n                            }catch{\n                                price=li.querySelector(&quot;strong.price&quot;).innerText;\n                            }\n                            let quantity=li.querySelector(&quot;.sales-value&quot;).innerText;\n                            let datablock=li.querySelector(&quot;.data-count&quot;);\n                            let adsblock=li.querySelector(&quot;.time-data-box&quot;);\n                            var i=0;\n                            let temp=[];\n                            datablock.querySelectorAll(&quot;.item&quot;).forEach(item=&gt;{\n                                if(i==0){let ads=item.querySelector(&quot;.value&quot;).innerText;temp.push(ads)}\n                                if(i==1){let thumb=item.querySelector(&quot;.value&quot;).innerText;temp.push(thumb)}\n                                if(i==2){let thumbrate=item.querySelector(&quot;.value&quot;).innerText;temp.push(thumbrate)}\n                                i++;\n                            })\n                            let temp1=[]\n                            var i1=0\n                            adsblock.querySelectorAll(&quot;.time-item&quot;).forEach(item=&gt;{\n                                if(i1==0){let starttime=item.querySelector(&quot;._value&quot;).innerText;temp1.push(starttime)}\n                                if(i1==1){let endtime=item.querySelector(&quot;._value&quot;).innerText;temp1.push(endtime)}\n                                if(i1==2){let nums=item.querySelector(&quot;._value&quot;).innerText;temp1.push(nums)}\n                                i1++;\n\n                            })\n                            let products={\n                                &quot;title&quot;:title,\n                                &quot;url&quot;:url,\n                                &quot;price&quot;:price,\n                                &quot;quantity&quot;:quantity,\n                                &quot;ads&quot;:temp[0],\n                                &quot;thumb&quot;:temp[1],\n                                &quot;thumbrate&quot;:temp[2],\n                                &quot;starttime&quot;:temp1[0],\n                                &quot;endtime&quot;:temp1[1],\n                                &quot;adsnums&quot;:temp1[2]\n                            }\n                            productlist.push(products);\n\n                        })\n                        const productListJson = JSON.stringify(productlist, null, 2);\n                        console.log(productListJson);\n                        exportjson(productListJson,&quot;task1&quot;);\n                        window.scrollTo({\n                            top: 0,\n                            behavior: &quot;smooth&quot;\n                        });\n                    })\n                })\n            })\n        })\n    })\n}\nfunction styleButton(button) {\n    button.style.padding = &quot;7px 15px&quot;;\n    button.style.margin = &quot;5px&quot;;\n    button.style.fontSize = &quot;16px&quot;;\n    button.style.backgroundColor = &quot;#4CAF50&quot;;\n    button.style.color = &quot;white&quot;;\n    button.style.border = &quot;none&quot;;\n    button.style.borderRadius = &quot;5px&quot;;\n    button.style.cursor = &quot;pointer&quot;;\n    button.style.boxShadow = &quot;0px 4px 6px rgba(0, 0, 0, 0.1)&quot;;\n    button.style.transition = &quot;background-color 0.3s&quot;;\n    button.onmouseover = function() {\n        button.style.backgroundColor = &quot;#45a049&quot;;\n    };\n    button.onmouseout = function() {\n        button.style.backgroundColor = &quot;#4CAF50&quot;;\n    };\n}\n\n\n\n\nwindow.addEventListener(&quot;load&quot;,()=&gt;{\n    main();\n},false)\n</code></pre>\n<h1>sellercenter爬虫</h1>\n<p>当时随便找到的网站，上面不少数据是可以免费查看的，很爽。\n随手就搞了一个爬虫，虽然没怎么用。</p>\n<pre><code class=\"language-javascript\">// ==UserScript==\n// @name         ebayscraper1\n// @namespace    http://tampermonkey.net/\n// @version      2024-10-14\n// @description  try to take over the world!\n// @author       suxing\n// @match        https://sellercenter.io/*\n// @icon         https://www.google.com/s2/favicons?sz=64&amp;domain=ebay.com\n// @grant        none\n// ==/UserScript==\n\n\nfunction main(){\n    new Promise((resolve)=&gt;{\n        console.log(&quot;sc-test!&quot;);\n        setTimeout(()=&gt;{\n            resolve();\n        },2000)\n    }).then(()=&gt;{\n        let pageMain = document.querySelector(&quot;.el-table__header-wrapper&quot;);\n        console.log(pageMain)\n        if(pageMain){\n            let button = document.createElement(&quot;button&quot;);\n            button.className=&quot;button-test&quot;\n            button.innerHTML = &quot;点击爬取json&quot;;\n            button.style.padding = &quot;10px 20px&quot;;\n            button.style.fontSize = &quot;16px&quot;;\n            button.style.backgroundColor = &quot;#4CAF50&quot;;\n            button.style.color = &quot;white&quot;;\n            button.style.border = &quot;none&quot;;\n            button.style.borderRadius = &quot;5px&quot;;\n            button.style.cursor = &quot;pointer&quot;;\n            button.style.boxShadow = &quot;0px 4px 6px rgba(0, 0, 0, 0.1)&quot;;\n            button.style.transition = &quot;background-color 0.3s&quot;;\n            button.onmouseover = function() {\n                button.style.backgroundColor = &quot;#45a049&quot;;\n            };\n            button.onmouseout = function() {\n                button.style.backgroundColor = &quot;#4CAF50&quot;;\n            };\n            button.onclick=()=&gt;{scrapefunc();}\n            var buttonContainer = document.createElement(&quot;div&quot;);\n            buttonContainer.style.display = &quot;flex&quot;;\n            buttonContainer.style.justifyContent = &quot;center&quot;;\n            buttonContainer.style.alignItems = &quot;center&quot;;\n            buttonContainer.style.height = &quot;100px&quot;; // 调整高度以便更好地居中\n            buttonContainer.appendChild(button);\n\n            // 在 pageMain 元素的上方插入按钮\n            pageMain.parentNode.insertBefore(buttonContainer, pageMain);\n        }\n    })\n}\n\nfunction exportjson(data){\n    const blob = new Blob([data], { type: 'application/json' });\n    const url = URL.createObjectURL(blob);\n    const a = document.createElement('a');\n    a.href = url;\n    const today = new Date();\n    const year = today.getFullYear();\n    const month = String(today.getMonth() + 1).padStart(2, '0');  \n    const day = String(today.getDate()).padStart(2, '0');  \n    const formattedDate = `${year}-${month}-${day}`;\n    a.download = `ebay${formattedDate}.json`;\n    document.body.appendChild(a);\n    a.click();\n    document.body.removeChild(a);\n    URL.revokeObjectURL(url);\n}\nfunction scrapefunc(){\n    new Promise((resolve)=&gt;{\n        console.log(&quot;ebay-scraper test1&quot;);\n        setTimeout(()=&gt;{\n            resolve();\n        },1000)\n    }).then(()=&gt;{\n        new Promise((resolve)=&gt;{\n            window.scrollTo({\n                top: 2000,\n                behavior: &quot;smooth&quot;\n            });\n            setTimeout(()=&gt;{\n                resolve();\n            },1000)\n        }).then(()=&gt;{\n            let productlist=[];\n            document.querySelectorAll(&quot;.el-table__row &quot;).forEach(li=&gt;{\n                let title=li.querySelector(&quot;.productNameNew&quot;).innerText;\n                \n                let price=li.querySelector(&quot;.priceShow&quot;).innerText  \n                let cate=li.querySelector(&quot;.el-tooltip__trigger&quot;).innerText\n                let quantity=&quot;&quot;   \n                try{\n                    quantity=li.querySelector(&quot;.cell&gt;span&quot;).innerText;\n                }catch{\n                    quantity=&quot;不显示&quot;\n                }                   \n                let info =&quot;&quot;\n                try{\n                    info=li.querySelector(&quot;.viewLabel&quot;).innerText; \n        \n                }\n                catch{\n                    shipping=&quot;不显示&quot;\n                }\n\n                \n                let products={\n                    &quot;title&quot;:title,\n                    &quot;cate&quot;:cate,\n                    &quot;price&quot;:price,\n                    &quot;quantity&quot;:quantity,\n                    &quot;info&quot;:info,\n\n                }                                                                      \n                productlist.push(products);\n                })\n                const productListJson = JSON.stringify(productlist, null, 2);\n                console.log(productListJson);\n                exportjson(productListJson);\n                window.scrollTo({\n                    top: 0,\n                    behavior: &quot;smooth&quot;\n                });\n            })        \n\n        })\n}\n\n\n\n\n\nwindow.addEventListener(&quot;load&quot;,()=&gt;{ \n    main();\n\n},false)\n</code></pre>\n<h1>ebay爬虫</h1>\n<p>当时做客户需求搞的脚本，爬了二手服务器，内存条，硬盘数据</p>\n<pre><code class=\"language-javascipt\">// ==UserScript==\n// @name         ebayscraper1\n// @namespace    http://tampermonkey.net/\n// @version      2024-10-14\n// @description  try to take over the world!\n// @author       suxing\n// @match        https://www.ebay.com/*\n// @icon         https://www.google.com/s2/favicons?sz=64&amp;domain=ebay.com\n// @grant        none\n// ==/UserScript==\n\n\nfunction main(){\n    new Promise((resolve)=&gt;{\n        console.log(&quot;pipiads-button1&quot;);\n        setTimeout(()=&gt;{\n            resolve();\n        },2000)\n    }).then(()=&gt;{\n        let pageMain = document.querySelector(&quot;.s-answer-region&quot;);\n        console.log(pageMain)\n        if(pageMain){\n            let button = document.createElement(&quot;button&quot;);\n            button.className=&quot;button-test&quot;\n            button.innerHTML = &quot;点击爬取json&quot;;\n            button.style.padding = &quot;10px 20px&quot;;\n            button.style.fontSize = &quot;16px&quot;;\n            button.style.backgroundColor = &quot;#4CAF50&quot;;\n            button.style.color = &quot;white&quot;;\n            button.style.border = &quot;none&quot;;\n            button.style.borderRadius = &quot;5px&quot;;\n            button.style.cursor = &quot;pointer&quot;;\n            button.style.boxShadow = &quot;0px 4px 6px rgba(0, 0, 0, 0.1)&quot;;\n            button.style.transition = &quot;background-color 0.3s&quot;;\n            button.onmouseover = function() {\n                button.style.backgroundColor = &quot;#45a049&quot;;\n            };\n            button.onmouseout = function() {\n                button.style.backgroundColor = &quot;#4CAF50&quot;;\n            };\n            button.onclick=()=&gt;{scrapefunc();}\n            var buttonContainer = document.createElement(&quot;div&quot;);\n            buttonContainer.style.display = &quot;flex&quot;;\n            buttonContainer.style.justifyContent = &quot;center&quot;;\n            buttonContainer.style.alignItems = &quot;center&quot;;\n            buttonContainer.style.height = &quot;100px&quot;; // 调整高度以便更好地居中\n            buttonContainer.appendChild(button);\n\n            // 在 pageMain 元素的上方插入按钮\n            pageMain.parentNode.insertBefore(buttonContainer, pageMain);\n        }\n    })\n}\n\nfunction exportjson(data){\n    const blob = new Blob([data], { type: 'application/json' });\n    const url = URL.createObjectURL(blob);\n    const a = document.createElement('a');\n    a.href = url;\n    const today = new Date();\n    const year = today.getFullYear();\n    const month = String(today.getMonth() + 1).padStart(2, '0');  \n    const day = String(today.getDate()).padStart(2, '0');  \n    const formattedDate = `${year}-${month}-${day}`;\n    a.download = `ebay${formattedDate}.json`;\n    document.body.appendChild(a);\n    a.click();\n    document.body.removeChild(a);\n    URL.revokeObjectURL(url);\n}\nfunction scrapefunc(){\n    new Promise((resolve)=&gt;{\n        console.log(&quot;ebay-scraper test1&quot;);\n        setTimeout(()=&gt;{\n            resolve();\n        },1000)\n    }).then(()=&gt;{\n        new Promise((resolve)=&gt;{\n            window.scrollTo({\n                top: 2000,\n                behavior: &quot;smooth&quot;\n            });\n            setTimeout(()=&gt;{\n                resolve();\n            },1000)\n        }).then(()=&gt;{\n            new Promise((resolve)=&gt;{\n                window.scrollTo({\n                    top: 5000,\n                    behavior: &quot;smooth&quot;\n                });\n                setTimeout(()=&gt;{\n                    resolve();\n                },1000)\n            }).then(()=&gt;{\n                new Promise((resolve)=&gt;{\n                    window.scrollTo({\n                        top: 8000,\n                        behavior: &quot;smooth&quot;\n                    });\n                    setTimeout(()=&gt;{\n                        resolve();\n                    },1000)\n                }).then(()=&gt;{\n                    new Promise((resolve)=&gt;{\n                        window.scrollTo({\n                            top: 12000,\n                            behavior: &quot;smooth&quot;\n                        });\n                        setTimeout(()=&gt;{\n                            resolve();\n                        },700)\n                    }).then(()=&gt;{    \n                        new Promise((resolve)=&gt;{\n                            window.scrollTo({\n                                top: 14000,\n                                behavior: &quot;smooth&quot;\n                            });\n                            setTimeout(()=&gt;{\n                                resolve();\n                            },700)\n    \n                        }).then(()=&gt;{\n                            let productlist=[];\n                            document.querySelectorAll(&quot;.s-item__info &quot;).forEach(li=&gt;{\n                                let title=li.querySelector(&quot;.s-item__title&gt;span&quot;).innerText;\n                                let secondtitle=&quot;&quot;\n                                try{\n                                    secondtitle=li.querySelector(&quot;.s-item__subtitle&gt;span&quot;).innerText;\n\n                                }\n                                catch{\n                                    secondtitle=&quot;不显示&quot;\n\n                                }\n                                \n                                let price=li.querySelector(&quot;span.s-item__price&quot;).innerText    \n                                let quantity=&quot;&quot;   \n                                try{\n                                    quantity=li.querySelector(&quot;span.s-item__quantitySold&quot;).innerText;\n                                }catch{\n                                    quantity=&quot;不显示&quot;\n                                }                   \n                                let loc=&quot;&quot;\n                                try{\n                                    loc=li.querySelector(&quot;span.s-item__location&quot;).innerText;\n\n                                }\n                                catch{\n                                    loc=&quot;不显示&quot;\n                                }\n                                let shipping =&quot;&quot;\n                                try{\n                                    shipping=li.querySelector(&quot;span.s-item__shipping&quot;).innerText; \n                      \n                                }\n                                catch{\n                                    shipping=&quot;不显示&quot;\n                                }\n    \n                                \n                                let products={\n                                    &quot;title&quot;:title,\n                                    &quot;secondtitle&quot;:secondtitle,\n                                    &quot;location&quot;:loc,\n                                    &quot;price&quot;:price,\n                                    &quot;quantity&quot;:quantity,\n                                    &quot;shipping&quot;:shipping,\n    \n                                }\n                                if (products.title!=&quot;Shop on eBay&quot;){\n                                    productlist.push(products);\n\n                                }\n                                \n                \n                            })\n                            const productListJson = JSON.stringify(productlist, null, 2);\n                            console.log(productListJson);\n                            exportjson(productListJson);\n                            let nextpage=document.querySelector(&quot;.pagination__next&quot;).href\n                            window.scrollTo({\n                                top: 0,\n                                behavior: &quot;smooth&quot;\n                            });\n                            location.href=nextpage\n                        })                              \n    \n                           \n                        \n                    })\n                })        \n\n            })\n               \n        })\n    })\n}\n\n\n\n\n\nwindow.addEventListener(&quot;load&quot;,()=&gt;{ \n    main();\n\n},false)\n</code></pre>\n<h1>tiktok爬虫</h1>\n<p>这个没什么卵用的脚本，做到一半我差不多就弃掉了。</p>\n<p>主要出发点就是，自己手点太慢了想搞个脚本一键保存tiktok后台数据不多好。</p>\n<p>结果发现还不如手点。。。所以全自动脚本等于全自己手动脚本。</p>\n<pre><code class=\"language-javascript\">// ==UserScript==\n// @name         tkshop test\n// @namespace    http://tampermonkey.net/\n// @version      2024-10-28\n// @description  字节跳动被我踩在脚下。\n// @author       suxing\n// @match        https://seller.tiktokglobalshop.com/*\n// @icon         https://www.google.com/s2/favicons?sz=64&amp;domain=tiktokglobalshop.com\n// @grant        none\n// ==/UserScript==\n\nfunction simulateClick(selector) {\n    const element = document.querySelector(selector);\n    \n    if (element) {\n        const rect = element.getBoundingClientRect();\n        const centerX = rect.left + rect.width / 2;\n        const centerY = rect.top + rect.height / 2;\n\n        // 创建鼠标移动事件\n        const mouseMoveEvent = new MouseEvent('mousemove', {\n            bubbles: true,\n            cancelable: true,\n            view: window,\n            clientX: centerX,\n            clientY: centerY\n        });\n\n        // 创建点击事件\n        const mouseDownEvent = new MouseEvent('mousedown', {\n            bubbles: true,\n            cancelable: true,\n            view: window,\n            clientX: centerX,\n            clientY: centerY\n        });\n\n        const mouseUpEvent = new MouseEvent('mouseup', {\n            bubbles: true,\n            cancelable: true,\n            view: window,\n            clientX: centerX,\n            clientY: centerY\n        });\n\n        const clickEvent = new MouseEvent('click', {\n            bubbles: true,\n            cancelable: true,\n            view: window,\n            clientX: centerX,\n            clientY: centerY\n        });\n\n        // 模拟鼠标移动\n        document.dispatchEvent(mouseMoveEvent);\n        // 模拟鼠标按下和松开\n        element.dispatchEvent(mouseDownEvent);\n        element.dispatchEvent(mouseUpEvent);\n        // 模拟点击\n        element.dispatchEvent(clickEvent);\n    } else {\n        console.error('Element not found for selector:', selector);\n    }\n}\n\nfunction delay(ms) {\n    return new Promise(resolve =&gt; setTimeout(resolve, ms));\n}\n\nasync function waitForModalToClose() {\n    // 等待打开的框消失\n    while (document.querySelector('div[role=&quot;dialog&quot;]')) {\n        await delay(500); // 每500毫秒检查一次\n    }\n}\n\nfunction main() {\n    new Promise((resolve) =&gt; {\n        console.log(&quot;tktest&quot;);\n        setTimeout(() =&gt; {\n            resolve();\n        }, 10000); // 等待 10 秒\n    }).then(() =&gt; {\n        const pageMain = document.querySelector(&quot;#compass-header&quot;);\n        console.log(pageMain);\n        if (pageMain) {\n            // 创建第一个按钮，用于第一个任务\n            const task1Button = document.createElement(&quot;button&quot;);\n            task1Button.className = &quot;button-test&quot;;\n            task1Button.innerHTML = &quot;任务 1 总览数据导出）&quot;;\n            styleButton(task1Button);\n            task1Button.onclick = async () =&gt; {\n                task1Button.disabled = true; // 禁用按钮以防重复点击\n                console.log(&quot;任务 1: 点击按钮&quot;);\n                // 执行任务 1 的操作\n                await simulateClick('button[data-tid=&quot;m4b_button&quot;]'); // 假设是导出按钮\n                task1Button.disabled = false; // 点击完成后启用按钮\n            };\n\n            // 创建第二个按钮，用于第二个任务\n            const task2Button = document.createElement(&quot;button&quot;);\n            task2Button.className = &quot;button-test&quot;;\n            task2Button.innerHTML = &quot;任务 2: 商品数据导出）&quot;;\n            styleButton(task2Button);\n            task2Button.onclick = async () =&gt; {\n                task2Button.disabled = true; // 禁用按钮以防重复点击\n                console.log(&quot;任务 2: 商品数据导出&quot;);\n\n                // 点击配置指标按钮\n                const configButtonSelector = 'div.mx-12 button';\n                simulateClick(configButtonSelector);\n\n                // 等待框关闭\n                await waitForModalToClose();\n\n                // 点击导出按钮\n                const exportButtonSelector = 'div.flex.gap-8 button';\n                simulateClick(exportButtonSelector);\n\n                task2Button.disabled = false; // 点击完成后启用按钮\n            };\n\n            // 创建按钮容器并插入按钮\n            const buttonContainer = document.createElement(&quot;div&quot;);\n            buttonContainer.style.display = &quot;flex&quot;;\n            buttonContainer.style.justifyContent = &quot;center&quot;;\n            buttonContainer.style.alignItems = &quot;center&quot;;\n            buttonContainer.style.height = &quot;50px&quot;; // 调整高度以便更好地居中\n            buttonContainer.appendChild(task1Button);\n            buttonContainer.appendChild(task2Button);\n\n            // 在 pageMain 元素的上方插入按钮容器\n            pageMain.parentNode.insertBefore(buttonContainer, pageMain);\n        }\n    });\n}\n\nfunction styleButton(button) {\n    button.style.padding = &quot;10px 20px&quot;;\n    button.style.margin = &quot;5px&quot;;\n    button.style.fontSize = &quot;16px&quot;;\n    button.style.backgroundColor = &quot;#4CAF50&quot;;\n    button.style.color = &quot;white&quot;;\n    button.style.border = &quot;none&quot;;\n    button.style.borderRadius = &quot;5px&quot;;\n    button.style.cursor = &quot;pointer&quot;;\n    button.style.boxShadow = &quot;0px 4px 6px rgba(0, 0, 0, 0.1)&quot;;\n    button.style.transition = &quot;background-color 0.3s&quot;;\n    button.onmouseover = function() {\n        button.style.backgroundColor = &quot;#45a049&quot;;\n    };\n    button.onmouseout = function() {\n        button.style.backgroundColor = &quot;#4CAF50&quot;;\n    };\n}\n\n// 调用 main 函数以执行代码\nmain();\n\n</code></pre>\n"}},8774:function(n){n.exports={attributes:{title:"（考研待开坑）前端网页小项目",date:"2024-12-08T00:00:00.000Z",summary:"在尝试的学习NLP技术",coverImage:"12-8-2.jpg"},html:"<h1>还是学一下前端了</h1>\n<p>在尝试vue3前端项目（这个网站就是vue做的）</p>\n<p>并且也在尝试react技术栈</p>\n<p>（待开坑）</p>\n"}},4307:function(n){n.exports={attributes:{title:"如何成为一个初级的炼丹术士",date:"2024-12-09T00:00:00.000Z",summary:"深度学习调参就是炼丹~",coverImage:"12-8-2.jpg",pinned:!0},html:"<h1>调参手段笔记</h1>\n<h2>1. 数据维度：</h2>\n<ul>\n<li><strong>数据增强</strong>: 通过对训练数据进行随机变换（旋转、裁剪、翻转、颜色抖动等）来增加数据量，提高模型的泛化能力。</li>\n<li>数据清洗: 去除数据中的噪声、异常值和重复值，提高数据质量。</li>\n<li>特征工程: 选择或创建更有效的特征，例如，使用词嵌入表示文本数据。</li>\n<li>数据平衡: 如果数据集存在类别不平衡问题，可以使用过采样、欠采样或类别权重等技术来平衡类别分布。</li>\n</ul>\n<h2>2. 调度策略：</h2>\n<ul>\n<li>学习率调度: 学习率是影响模型训练最重要的超参数之一。常用的学习率调度策略包括：\n<ul>\n<li>固定学习率: 在整个训练过程中使用相同的学习率。</li>\n<li>学习率衰减: 随着训练的进行，逐渐减小学习率。常用的衰减方法包括：\n<ul>\n<li>阶梯衰减 (Step Decay): 每经过一定的 epoch 数，将学习率降低一个固定的比例。</li>\n<li>线性衰减 (Linear Decay): 线性地减小学习率。</li>\n<li>余弦衰减 (Cosine Annealing): 按照余弦函数的曲线降低学习率。</li>\n</ul>\n</li>\n<li><strong>warmup + 余弦衰减</strong>: 在训练初期使用较小的学习率 (warmup)，然后按照余弦函数进行衰减。</li>\n<li>循环学习率 (Cyclic Learning Rates): 在一定的范围内循环调整学习率。</li>\n<li>自适应学习率调整: 根据模型的训练状态自动调整学习率，例如 Adam, RAdam 等优化器。</li>\n</ul>\n</li>\n<li><strong>早停 (Early Stopping)</strong>: 当模型在验证集上的性能停止提升时，停止训练，避免过拟合。</li>\n</ul>\n<h2>3. 模型结构：</h2>\n<ul>\n<li>采用预训练模型</li>\n<li>网络深度: 增加网络深度可以提高模型的表达能力，但同时也增加了过拟合的风险。</li>\n<li>网络宽度: 增加网络宽度也可以提高模型的表达能力，但会增加计算量和参数数量。</li>\n<li>层类型: 选择合适的层类型对于模型的性能至关重要。 例如，卷积层适用于图像数据，循环层适用于序列数据。</li>\n<li><strong>激活函数</strong>: 选择合适的激活函数可以提高模型的训练效率和性能。 常用的激活函数包括 ReLU, LeakyReLU, GELU, Sigmoid, Tanh 等。\n$$ReLU(x) = \\max(0, x)$$\n$$LeakyReLU(x) = \\begin{cases} x, &amp; \\text{if } x &gt; 0 \\ \\alpha x, &amp; \\text{otherwise} \\end{cases}$$\n$$GELU(x) = x \\cdot \\Phi(x)$$\n$$GELU(x) \\approx 0.5x\\left( 1 + \\tanh\\left( \\sqrt{\\frac{2}{\\pi}}\\left( x + 0.044715x^3 \\right) \\right) \\right)$$\n$$\\text{Sigmoid}(x) = \\frac{1}{1 + e^{-x}}$$\n$$\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} = \\frac{\\sinh(x)}{\\cosh(x)}$$</li>\n<li><strong>最后一层激活函数</strong>\n<ul>\n<li>分类任务\n<ul>\n<li>二元分类: 使用 Sigmoid 激活函数。\n$$\\sigma(x) = \\frac{1}{1 + e^{-x}}$$</li>\n<li>多类别分类: 使用 Softmax 激活函数。\n$$\\text{Softmax}(x_i) = \\frac{e^{x_i}}{\\sum_{j=1}^{n} e^{x_j}}$$</li>\n</ul>\n</li>\n<li>回归任务\n<ul>\n<li>无约束的回归: 使用线性激活函数。\n$$f(x) = x$$</li>\n<li>非负的回归: 使用 ReLU 或 Exponential 激活函数。\n$$ReLU(x) = \\max(0, x)$$</li>\n<li>有界回归: 使用 Sigmoid 或 Tanh 激活函数。\n$$f(x) = e^x$$</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>残差连接 (Residual Connections)</strong>: 残差连接可以帮助训练更深的网络，避免梯度消失问题。</li>\n<li><strong>注意力机制 (Attention Mechanism)</strong>: 注意力机制可以帮助模型关注输入中的重要部分，提高模型的性能。</li>\n</ul>\n<h2>4. 正则化技术：</h2>\n<ul>\n<li><strong>Dropout</strong>: 在训练过程中随机丢弃一些神经元，降低过拟合的风险。</li>\n<li>权重衰减 (Weight Decay/L2 正则化): 对模型的权重施加 L2 正则化，限制权重的大小，避免过拟合。</li>\n<li>批量归一化 (Batch Normalization): 对每层的输入进行归一化，加速模型训练，并提高模型的泛化能力。</li>\n<li>层归一化 (Layer Normalization): 类似于批量归一化，但对每个样本进行归一化，而不是对每个批量进行归一化。</li>\n</ul>\n<h2>5. 计算优化算法：</h2>\n<ul>\n<li>SGD: 随机梯度下降，简单但容易陷入局部最优。</li>\n<li>SGD with Momentum: 带动量的 SGD，可以加速收敛，并逃离局部最优。</li>\n<li>Adagrad: 自适应学习率优化器，根据参数的历史梯度调整学习率。</li>\n<li>RMSprop: 改进的 Adagrad，可以解决 Adagrad 学习率下降过快的问题。</li>\n<li><strong>Adam</strong>: 结合了 Momentum 和 RMSprop 的优点，通常是深度学习的首选优化器。</li>\n<li>RAdam: 改进的 Adam，可以解决 Adam 在训练初期不稳定的问题。</li>\n</ul>\n<h2>6. 损失函数：</h2>\n<p>损失函数的选择取决于具体的机器学习任务。以下是一些常见的损失函数及其公式：</p>\n<p><strong>1. 分类任务：</strong></p>\n<ul>\n<li>\n<p><strong>二元交叉熵损失 (Binary Cross-Entropy Loss):</strong> 用于二元分类问题。</p>\n<p>$$\nL = -\\frac{1}{N} \\sum_{i=1}^{N} [y_i \\log(\\hat{y}_i) + (1-y_i) \\log(1-\\hat{y}_i)]\n$$\n其中，$N$ 是样本数量，$y_i$ 是真实标签 (0 或 1)，$\\hat{y}_i$ 是预测概率。</p>\n</li>\n<li>\n<p><strong>类别交叉熵损失 (Categorical Cross-Entropy Loss):</strong> 用于多类别分类问题（互斥类别）。</p>\n<p>$$\nL = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{c=1}^{C} y_{ic} \\log(\\hat{y}<em>{ic})\n$$\n其中，$N$ 是样本数量，$C$ 是类别数量，$y</em>{ic}$ 是真实标签 (one-hot 编码)，$\\hat{y}_{ic}$ 是类别 $c$ 的预测概率。</p>\n</li>\n<li>\n<p><strong>多标签二元交叉熵损失:</strong> 用于多标签分类问题(非互斥类别).  它对每个类别独立地应用二元交叉熵损失.</p>\n</li>\n</ul>\n<p><strong>2. 回归任务：</strong></p>\n<ul>\n<li>\n<p><strong>均方误差 (Mean Squared Error, MSE):</strong></p>\n<p>$$\nL = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2\n$$</p>\n</li>\n<li>\n<p><strong>平均绝对误差 (Mean Absolute Error, MAE):</strong></p>\n<p>$$\nL = \\frac{1}{N} \\sum_{i=1}^{N} |y_i - \\hat{y}_i|\n$$</p>\n</li>\n<li>\n<p><strong>Huber 损失 (Huber Loss):</strong>  结合了 MSE 和 MAE 的优点，对异常值更鲁棒。</p>\n<p>$$\nL_\\delta(y, \\hat{y}) = \\frac{1}{N} \\sum_{i=1}^{N}\n\\begin{cases}\n\\frac{1}{2}(y_i - \\hat{y}_i)^2, &amp; \\text{if } |y_i - \\hat{y}_i| \\le \\delta \\\n\\delta(|y_i - \\hat{y}_i| - \\frac{1}{2}\\delta), &amp; \\text{otherwise}\n\\end{cases}\n$$\n其中，$\\delta$ 是一个控制参数。</p>\n</li>\n</ul>\n<p><strong>其他损失函数：</strong></p>\n<ul>\n<li>\n<p><strong>铰链损失 (Hinge Loss):</strong>  用于支持向量机 (SVM)。</p>\n<p>$$\nL = \\frac{1}{N}\\sum_{i=1}^N \\max(0, 1 - y_i \\cdot \\hat{y}_i)\n$$\n其中,  $y_i$ 为真实标签 (-1 或 1)，$\\hat{y}_i$ 是预测值.</p>\n</li>\n<li>\n<p><strong>KL 散度 (Kullback-Leibler Divergence):</strong>  用于衡量两个概率分布之间的差异，通常用于生成模型和概率建模.</p>\n<p>$$\nD_{KL}(P || Q) = \\sum_{x} P(x) \\log \\frac{P(x)}{Q(x)}\n$$</p>\n</li>\n</ul>\n<p><strong>选择损失函数的技巧:</strong></p>\n<ul>\n<li><strong>根据任务类型选择：</strong>  分类任务通常使用交叉熵损失，回归任务通常使用 MSE、MAE 或 Huber 损失.</li>\n<li><strong>考虑数据特点：</strong>  如果数据中存在异常值，可以使用 Huber 损失或 MAE 等对异常值更鲁棒的损失函数.</li>\n<li><strong>根据模型输出选择:</strong>  模型的输出类型也影响损失函数的选择.  例如，如果模型输出概率分布，可以使用交叉熵损失。</li>\n<li><strong>实验和比较：</strong>  可以尝试不同的损失函数，并比较它们的性能。</li>\n</ul>\n<p>没有万能的损失函数，最佳选择取决于你的具体任务和数据。</p>\n<h2>7. 优化显存占用</h2>\n<ul>\n<li>减少批次大小 (Batch Size)</li>\n<li>梯度累积 (Gradient Accumulation)</li>\n<li>混合精度训练 (Mixed Precision Training)</li>\n<li>梯度检查点 (Gradient Checkpointing)</li>\n<li>分布式训练 (Distributed Training)</li>\n<li>模型并行 (Model Parallelism)</li>\n<li>释放不必要的显存</li>\n</ul>\n"}},2044:function(n){n.exports={attributes:{title:"深度学习入门笔记",date:"2024-12-09T00:00:00.000Z",summary:"深度学习和机器学习差别越来越大了",coverImage:"12-9-1.jpg",pinned:!0},html:"<h1>I. 机器学习模型</h1>\n<h2><strong>1. 线性回归 (Linear Regression):</strong></h2>\n<ul>\n<li><strong>描述:</strong>  预测连续目标变量，假设目标变量与特征之间存在线性关系。</li>\n<li><strong>公式:</strong>  $y = \\mathbf{w}^T\\mathbf{x} + b$\n<ul>\n<li>$y$:  预测值 (标量)</li>\n<li>$\\mathbf{w}$:  权重向量</li>\n<li>$\\mathbf{x}$:  特征向量</li>\n<li>$b$:  偏置项 (标量)</li>\n</ul>\n</li>\n<li><strong>损失函数:</strong> 均方误差 (MSE) $MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$</li>\n<li><strong>可学习超参数:</strong>  无 (所有参数通过训练直接学习)</li>\n</ul>\n<h2><strong>2. 逻辑回归 (Logistic Regression):</strong></h2>\n<ul>\n<li><strong>描述:</strong>  预测二元分类问题，使用 sigmoid 函数将线性回归的输出转换为概率。</li>\n<li><strong>公式:</strong>  $p = \\frac{1}{1 + \\exp(-(\\mathbf{w}^T\\mathbf{x} + b))}$\n<ul>\n<li>$p$:  属于正类的概率</li>\n</ul>\n</li>\n<li><strong>损失函数:</strong> 二元交叉熵损失 (BCE) $BCE = -\\frac{1}{n}\\sum_{i=1}^{n}[y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i)]$</li>\n<li><strong>可学习超参数:</strong> 正则化强度 (L1 或 L2)</li>\n</ul>\n<h2><strong>3. 支持向量机 (Support Vector Machine - SVM):</strong></h2>\n<ul>\n<li><strong>描述:</strong>  寻找一个最优超平面来划分不同类别的数据。</li>\n<li><strong>公式 (线性可分):</strong>  最大化间隔 $\\frac{2}{|\\mathbf{w}|}$，并满足 $y_i(\\mathbf{w}^T\\mathbf{x}_i + b) \\ge 1$</li>\n<li><strong>损失函数 (软间隔):</strong>  $Hinge Loss + \\lambda|\\mathbf{w}|^2$  其中 $Hinge Loss = \\sum_{i=1}^{n} \\max(0, 1 - y_i(\\mathbf{w}^T\\mathbf{x}_i + b))$</li>\n<li><strong>可学习超参数:</strong> 正则化参数 $\\lambda$ (C), 核函数类型及参数 (例如：高斯核的 $\\gamma$)</li>\n</ul>\n<h2><strong>4. 决策树 (Decision Tree):</strong></h2>\n<ul>\n<li><strong>描述:</strong>  基于一系列条件判断进行分类或回归。</li>\n<li><strong>公式:</strong>  无单一公式</li>\n<li><strong>可学习超参数:</strong> 树的最大深度,  每个节点的最小样本数, 叶节点的最小样本数,  分裂准则 (基尼系数, 信息增益)</li>\n</ul>\n<h2><strong>5. 朴素贝叶斯 (Naive Bayes):</strong></h2>\n<ul>\n<li><strong>描述:</strong>  基于贝叶斯定理进行分类，假设特征之间相互独立.</li>\n<li><strong>公式:</strong> $P(y|\\mathbf{x}) = \\frac{P(\\mathbf{x}|y) P(y)}{P(\\mathbf{x})}$\n<ul>\n<li>$P(y|\\mathbf{x})$:  后验概率</li>\n<li>$P(\\mathbf{x}|y)$:  似然度</li>\n<li>$P(y)$:  先验概率</li>\n<li>$P(\\mathbf{x})$:  证据</li>\n</ul>\n</li>\n<li><strong>可学习超参数:</strong>  拉普拉斯平滑参数 (对于离散特征),  高斯分布的参数 (对于连续特征)</li>\n</ul>\n<h2><strong>6. K 近邻 (K-Nearest Neighbors - KNN):</strong></h2>\n<ul>\n<li><strong>描述:</strong> 基于距离度量找到训练集中与待预测样本最近的 k 个邻居，然后根据邻居的标签进行预测。</li>\n<li><strong>公式:</strong> 无单一公式</li>\n<li><strong>可学习超参数:</strong>  邻居数量 k, 距离度量方法 (欧氏距离、曼哈顿距离等)</li>\n</ul>\n<h2><strong>7. 随机森林 (Random Forest):</strong></h2>\n<ul>\n<li><strong>描述:</strong> 集成学习方法，通过构建多个决策树并结合它们的预测结果来提高模型的泛化能力和鲁棒性。</li>\n<li><strong>公式:</strong> 无单一公式，基于多个决策树的投票或平均预测。</li>\n<li><strong>可学习超参数:</strong>  决策树的数量,  每棵树的最大深度, 每个节点的最小样本数,  特征采样比例, 数据采样比例 (Bagging)</li>\n</ul>\n<h2><strong>8. XGBoost (Extreme Gradient Boosting):</strong></h2>\n<ul>\n<li><strong>描述:</strong> 一种梯度提升树(GBDT)的实现，具有高效、灵活和可扩展性等优点。</li>\n<li><strong>公式:</strong> 基于梯度提升和正则化项的优化目标函数。</li>\n<li><strong>可学习超参数:</strong> 学习率 (eta), 树的数量 (n_estimators), 树的最大深度 (max_depth),  L1正则化参数 (alpha), L2正则化参数 (lambda), 子样本比例 (subsample),  特征子采样比例 (colsample_bytree)</li>\n</ul>\n<h1><strong>I-I. 时间序列模型补充</strong></h1>\n<h2>0.数据平稳性分析</h2>\n<p>1）.<strong>平稳性的类型:</strong></p>\n<ul>\n<li><strong>严格平稳:</strong> 时间序列的所有统计特性都不随时间变化。这是一个非常强的条件，在实际应用中很难满足。</li>\n<li><strong>弱平稳 (宽平稳):</strong>  时间序列的均值、方差和自协方差(和自相关)不随时间变化。这是时间序列分析中常用的平稳性定义。</li>\n</ul>\n<p>2）<strong>判断平稳性的方法:</strong></p>\n<ul>\n<li>\n<p><strong>可视化:</strong> 通过绘制时间序列图、滚动统计量图（例如滚动均值和滚动方差）来观察时间序列的均值和方差是否随时间变化。</p>\n</li>\n<li>\n<p><strong>单位根检验:</strong>  如前所述，ADF 检验和 KPSS 检验是常用的单位根检验方法。它们可以用来检验时间序列是否具有单位根，从而判断序列是否平稳。</p>\n</li>\n<li>\n<p><strong>自相关函数 (ACF) 和偏自相关函数 (PACF):</strong>  平稳时间序列的 ACF 和 PACF 会快速衰减到零，而非平稳时间序列的 ACF 会缓慢衰减。</p>\n</li>\n</ul>\n<p>3）<strong>非平稳数据的处理方法:</strong></p>\n<p>如果时间序列是非平稳的，需要进行一些变换使其平稳，然后再应用时间序列模型。常用的变换方法包括：</p>\n<ul>\n<li>\n<p><strong>差分:</strong>  对时间序列进行一阶或更高阶差分，可以去除趋势和季节性。一阶差分定义为：\n$\\Delta y_t = y_t - y_{t-1}$</p>\n</li>\n<li>\n<p><strong>对数变换:</strong>  对时间序列取对数可以稳定方差，尤其适用于方差随时间增大的情况。</p>\n</li>\n<li>\n<p><strong>季节性分解:</strong>  将时间序列分解为趋势、季节性和残差项，然后对各个分量分别进行建模。</p>\n</li>\n<li>\n<p><strong>Box-Cox 变换:</strong>  一种更通用的变换方法，可以根据数据的特点选择合适的变换参数。</p>\n</li>\n</ul>\n<h2><strong>1. ARIMA (Autoregressive Integrated Moving Average):</strong></h2>\n<ul>\n<li><strong>描述:</strong>  一种经典的时间序列预测模型，通过对时间序列的自回归 (AR)、差分 (I) 和移动平均 (MA) 部分进行建模来捕捉时间序列中的模式。</li>\n<li><strong>公式:</strong>  $y_t = c + \\phi_1 y_{t-1} + ... + \\phi_p y_{t-p} + \\theta_1 \\epsilon_{t-1} + ... + \\theta_q \\epsilon_{t-q} + \\epsilon_t$ (ARIMA(p,d,q)模型)\n<ul>\n<li>$p$: 自回归阶数</li>\n<li>$d$: 差分阶数</li>\n<li>$q$: 移动平均阶数</li>\n<li>$\\phi$: 自回归系数</li>\n<li>$\\theta$: 移动平均系数</li>\n<li>$\\epsilon$: 白噪声</li>\n</ul>\n</li>\n<li><strong>可学习超参数:</strong>  p, d, q</li>\n</ul>\n<h3>如何确定pdq参数？</h3>\n<p><strong>1）. ACF 和 PACF 图:</strong></p>\n<ul>\n<li><strong>自相关函数 (ACF):</strong> 描述时间序列与自身滞后值之间的相关性。</li>\n<li><strong>偏自相关函数 (PACF):</strong> 描述时间序列与自身滞后值之间的直接相关性，排除了中间滞后值的影响。</li>\n</ul>\n<p>通过观察 ACF 和 PACF 图，可以初步判断 p 和 q 的值：</p>\n<ul>\n<li><strong>AR(p) 模型:</strong> ACF 呈指数衰减或拖尾，PACF 在 p 阶后截尾。</li>\n<li><strong>MA(q) 模型:</strong> ACF 在 q 阶后截尾，PACF 呈指数衰减或拖尾。</li>\n<li><strong>ARMA(p,q) 模型:</strong> ACF 和 PACF 都呈拖尾。</li>\n</ul>\n<p><strong>2）. 单位根检验:</strong></p>\n<p>用于确定差分阶数 d。常用的单位根检验方法包括：</p>\n<ul>\n<li><strong>ADF 检验 (Augmented Dickey-Fuller Test):</strong>  如果序列存在单位根，则需要进行差分。重复进行 ADF 检验， 直到序列平稳。</li>\n<li><strong>KPSS 检验 (Kwiatkowski-Phillips-Schmidt-Shin Test):</strong>  与 ADF 检验相反，KPSS 检验的原假设是序列平   稳。</li>\n</ul>\n<p><strong>3）. 信息准则:</strong></p>\n<p>用于比较不同 p、d、q 组合的模型拟合效果。常用的信息准则包括：</p>\n<ul>\n<li><strong>AIC (Akaike Information Criterion):</strong>  AIC 值越小，模型越好。</li>\n<li><strong>BIC (Bayesian Information Criterion):</strong>  BIC 值越小，模型越好，BIC 比 AIC 对模型复杂度惩罚更大。</li>\n</ul>\n<p><strong>4）. 自动化工具:</strong></p>\n<p>一些 Python 库提供了自动确定 ARIMA 参数的功能，例如 <code>pmdarima</code> 库中的 <code>auto_arima</code> 函数。该函数会根据信 息准则自动搜索最佳的 p、d、q 组合。</p>\n<p><strong>迭代流程示例:</strong></p>\n<ul>\n<li><strong>数据预处理:</strong>  处理缺失值，进行数据变换（例如对数变换）以稳定方差。</li>\n<li><strong>判断 d:</strong>  使用 ADF 或 KPSS 检验确定差分阶数 d。</li>\n<li><strong>初步判断 p 和 q:</strong>  观察差分后序列的 ACF 和 PACF 图，初步估计 p 和 q 的值。</li>\n<li><strong>模型选择:</strong>  使用不同的 p、d、q 组合训练 ARIMA 模型，并使用 AIC 或 BIC 比较模型的拟合效果。</li>\n<li><strong>模型评估:</strong>  使用残差分析、预测性能等指标评估模型的优劣。</li>\n<li><strong>参数调整:</strong>  根据模型评估结果，调整 p、d、q 的值，重复步骤 4 和 5，直到找到最佳的模型。</li>\n</ul>\n<h2><strong>2. 灰色预测模型 (GM):</strong></h2>\n<ul>\n<li><strong>描述:</strong>  一种用于处理少量数据的预测模型，通过对原始数据进行累加生成，建立微分方程模型进行预测。</li>\n<li><strong>公式:</strong>\n<ul>\n<li>累加生成: $x^{(1)}(k) = \\sum_{i=1}^{k} x^{(0)}(i)$，其中 $x^{(0)}$ 为原始序列, $x^{(1)}$ 为一次累加生成序列。</li>\n<li>一阶微分方程: $x^{(0)}(k) + az^{(1)}(k) = b$，其中 $z^{(1)}(k) = 0.5[x^{(1)}(k) + x^{(1)}(k-1)]$ 是背景值,  $a$ 为发展系数, $b$ 为灰色作用量。</li>\n<li>参数估计: 通过最小二乘法估计 $a$ 和 $b$。</li>\n<li>时间响应函数:  用于预测未来值。</li>\n</ul>\n</li>\n<li><strong>可学习超参数:</strong> 无，a和b通过数据学习得到。</li>\n</ul>\n<h2><strong>3. Prophet:</strong></h2>\n<ul>\n<li><strong>描述:</strong>  Facebook 开发的时间序列预测模型，特别适用于具有季节性和趋势性数据的预测。</li>\n<li><strong>公式:</strong>  基于加性模型，将时间序列分解为趋势、季节性、节假日效应和残差项.</li>\n<li><strong>可学习超参数:</strong>  趋势模型参数, 季节性模型参数, 节假日效应参数</li>\n</ul>\n<h2><strong>4. 其他时间序列模型:</strong></h2>\n<ul>\n<li><strong>指数平滑:</strong>  简单且有效的时间序列预测方法，适用于短期预测。</li>\n<li><strong>状态空间模型:</strong>  一种更通用的时间序列建模框架，可以包含 ARIMA、指数平滑等模型作为特例。</li>\n</ul>\n<h2><strong>5. 状态空间模型 (State Space Models):</strong></h2>\n<ul>\n<li><strong>描述:</strong> 一种灵活的通用时间序列建模框架，通过状态方程描述时间序列的演变，观测方程描述观测值与状态之间的关系。可以涵盖 ARIMA、指数平滑等模型作为特例。</li>\n<li><strong>公式:</strong>\n<ul>\n<li>状态方程: $\\mathbf{x}_{t+1} = F_t\\mathbf{x}_t + G_t\\mathbf{w}_t$</li>\n<li>观测方程: $\\mathbf{y}_t = H_t\\mathbf{x}_t + \\mathbf{v}_t$</li>\n<li>其中 $\\mathbf{x}_t$ 为状态向量，$\\mathbf{y}_t$ 为观测向量，$F_t$, $G_t$, $H_t$ 为系数矩阵，$\\mathbf{w}_t$ 和 $\\mathbf{v}_t$ 为噪声向量。</li>\n</ul>\n</li>\n<li><strong>可学习超参数:</strong>  根据具体模型而定，例如卡尔曼滤波中的噪声协方差矩阵。</li>\n</ul>\n<h1><strong>II. 深度学习模型</strong></h1>\n<h2><strong>1. 多层感知机 (Multilayer Perceptron - MLP):</strong></h2>\n<ul>\n<li><strong>描述:</strong>  包含多个全连接层的神经网络.</li>\n<li><strong>公式:</strong>  $\\mathbf{a}^{(l)} = \\sigma(\\mathbf{W}^{(l)}\\mathbf{a}^{(l-1)} + \\mathbf{b}^{(l)})$\n<ul>\n<li>$\\mathbf{a}^{(l)}$: 第 l 层的激活值</li>\n<li>$\\sigma$: 激活函数 (例如 sigmoid, ReLU)</li>\n<li>$\\mathbf{W}^{(l)}$: 第 l 层的权重矩阵</li>\n<li>$\\mathbf{b}^{(l)}$: 第 l 层的偏置向量</li>\n</ul>\n</li>\n<li><strong>可学习超参数:</strong> 隐藏层数量, 每层神经元数量, 激活函数, 学习率, batch size, 优化器, 正则化方法及强度 (dropout, L1/L2)</li>\n</ul>\n<h2><strong>2. 卷积神经网络 (Convolutional Neural Network - CNN):</strong></h2>\n<ul>\n<li><strong>描述:</strong>  使用卷积层提取特征的深度学习模型，主要用于图像和序列数据.</li>\n<li><strong>公式 (卷积操作):</strong>  $(f * g)(t) =  \\int f(\\tau)g(t - \\tau)d\\tau$  (连续) 或  $(f * g)(i) = \\sum_j f(j)g(i-j)$ (离散)\n<ul>\n<li>$f$: 输入信号</li>\n<li>$g$: 卷积核</li>\n</ul>\n</li>\n<li><strong>可学习超参数:</strong>  卷积核大小, 卷积核数量, 步长, 填充,  池化类型及大小,  学习率, batch size, 优化器, 正则化方法及强度</li>\n</ul>\n<h2><strong>3. 循环神经网络 (Recurrent Neural Network - RNN):</strong></h2>\n<ul>\n<li>\n<p><strong>描述:</strong> 处理序列数据的深度学习模型，能够捕捉时间依赖关系。</p>\n</li>\n<li>\n<p><strong>公式:</strong>  $\\ h_t = \\sigma(W_{xh} \\cdot x_t + W_{hh} \\cdot h_{t-1} + b_h)$</p>\n<ul>\n<li>$\\mathbf{h}_t$: t 时刻的隐藏状态</li>\n<li>$\\mathbf{x}_t$: t 时刻的输入</li>\n<li>$\\mathbf{W}_{xh}$: 输入到隐藏状态的权重矩阵</li>\n<li>$\\mathbf{W}_{hh}$: 隐藏状态到隐藏状态的权重矩阵</li>\n<li>$\\mathbf{b}_h$: 隐藏状态的偏置向量</li>\n<li>$\\sigma$: 激活函数 (例如 tanh, sigmoid)</li>\n</ul>\n</li>\n<li>\n<p><strong>可学习超参数:</strong> 隐藏单元数量, 学习率, 优化器, 序列长度</p>\n</li>\n</ul>\n<h2><strong>4. 长短期记忆网络 (Long Short-Term Memory - LSTM):</strong></h2>\n<ul>\n<li><strong>描述:</strong> 一种特殊的 RNN，能够更好地处理长期依赖关系。</li>\n<li><strong>公式:</strong>\n<ul>\n<li><strong>遗忘门:</strong> $\\ f_t = \\sigma(W_{xf} \\cdot x_t + W_{hf} \\cdot h_{t-1} + b_f)$</li>\n<li><strong>输入门:</strong> $\\ i_t = \\sigma(W_{xi} \\cdot x_t + W_{hi} \\cdot h_{t-1} + b_i)$</li>\n<li><strong>候选细胞状态:</strong> $ \\ \\tilde{c_t} = \\tanh(W_{xc} \\cdot x_t + W_{hc} \\cdot h_{t-1} + b_c) \\ $</li>\n<li><strong>细胞状态:</strong> $\\ c_t = f_t \\cdot c_{t-1} + i_t \\cdot \\tilde{c}_t$</li>\n<li><strong>输出门:</strong> $\\ o_t = \\sigma(W_{xo} \\cdot x_t + W_{ho} \\cdot h_{t-1} + b_o)$</li>\n<li><strong>隐藏状态:</strong> $\\ h_t = o_t \\cdot \\tanh(c_t)$</li>\n<li>$\\mathbf{W}_{x*}$: 输入到各个门的权重矩阵 (* 代表 f, i, c, o)</li>\n<li>$\\mathbf{W}_{h*}$: 隐藏状态到各个门的权重矩阵</li>\n<li>$\\mathbf{b}_*$: 各个门的偏置向量</li>\n<li>$\\sigma$: sigmoid 激活函数</li>\n<li>$\\tanh$: hyperbolic tangent 激活函数</li>\n<li>$*$:  元素乘法</li>\n</ul>\n</li>\n<li><strong>可学习超参数:</strong> LSTM 单元数量, 学习率, 优化器, 序列长度</li>\n</ul>\n<h2><strong>5. 门控循环单元 (Gated Recurrent Unit - GRU):</strong></h2>\n<ul>\n<li><strong>描述:</strong> GRU 是 LSTM 的一种简化版本，它合并了遗忘门和输入门为一个更新门，并去除了细胞状态。</li>\n<li><strong>公式:</strong>\n<ul>\n<li><strong>更新门:</strong> $\\ z_t = \\sigma(W_{xz} \\cdot x_t + W_{hz} \\cdot h_{t-1} + b_z)$</li>\n<li><strong>重置门:</strong> $\\ r_t = \\sigma(W_{xr} \\cdot x_t + W_{hr} \\cdot h_{t-1} + b_r)$</li>\n<li><strong>候选隐藏状态:</strong> $\\tilde{h_t} = \\tanh(W_{xh} \\cdot x_t + W_{hh} \\cdot (r_t \\cdot h_{t-1}) + b_h)$</li>\n<li><strong>隐藏状态:</strong> $\\ h_t = (1 - z_t) \\cdot h_{t-1} + z_t \\cdot \\tilde{h}_t$</li>\n<li>$\\mathbf{W}_{x*}$: 输入到各个门的权重矩阵 (* 代表 z, r, h)</li>\n<li>$\\mathbf{W}_{h*}$: 隐藏状态到各个门的权重矩阵</li>\n<li>$\\mathbf{b}_*$: 各个门的偏置向量</li>\n<li>$\\sigma$: sigmoid 激活函数</li>\n<li>$\\tanh$: hyperbolic tangent 激活函数</li>\n<li>$*$: 元素乘法</li>\n</ul>\n</li>\n<li><strong>可学习超参数:</strong> GRU 单元数量, 学习率, 优化器, 序列长度</li>\n</ul>\n<h2>6. Transformer:</h2>\n<ul>\n<li><strong>描述:</strong> 基于注意力机制的深度学习模型，广泛应用于自然语言处理领域.</li>\n<li><strong>公式 (Scaled Dot-Product Attention):</strong>  $Attention(\\mathbf{Q}, \\mathbf{K}, \\mathbf{V}) = \\text{softmax}(\\frac{\\mathbf{Q}\\mathbf{K}^T}{\\sqrt{d_k}})\\mathbf{V}$\n<ul>\n<li>$\\mathbf{Q}$: 查询矩阵</li>\n<li>$\\mathbf{K}$:  键矩阵</li>\n<li>$\\mathbf{V}$: 值矩阵</li>\n<li>$d_k$:  键向量的维度</li>\n</ul>\n</li>\n<li><strong>可学习超参数:</strong>  注意力头数, 隐藏层维度,  前馈网络维度, 学习率, batch size, 优化器, dropout 率.</li>\n</ul>\n<h3>补充</h3>\n<p><strong>1） 点积相似度:</strong></p>\n<p>在 Scaled Dot-Product Attention 中，点积相似度用于衡量查询向量 (query) 和键向量 (key) 之间的相关性。  对于查询矩阵 $\\mathbf{Q}$ 中的每个向量 $q_i$ 和键矩阵 $\\mathbf{K}$ 中的每个向量 $k_j$，它们的点积相似度计算如下：</p>\n<p>$similarity(q_i, k_j) = q_i \\cdot k_j$</p>\n<p>点积的结果越大，表示 $q_i$ 和 $k_j$ 的相关性越高。</p>\n<p><strong>2） QKV 计算方式:</strong></p>\n<p>查询矩阵 $\\mathbf{Q}$、键矩阵 $\\mathbf{K}$ 和值矩阵 $\\mathbf{V}$ 都是通过将输入矩阵 $\\mathbf{X}$ 分别乘以三个可学习的权重矩阵 $\\mathbf{W}_Q$、$\\mathbf{W}_K$ 和 $\\mathbf{W}_V$ 得到的：</p>\n<ul>\n<li>$\\mathbf{Q} = \\mathbf{X} \\mathbf{W}_Q$</li>\n<li>$\\mathbf{K} = \\mathbf{X} \\mathbf{W}_K$</li>\n<li>$\\mathbf{V} = \\mathbf{X} \\mathbf{W}_V$</li>\n</ul>\n<p>其中，$\\mathbf{X}$ 的形状为 <code>(batch_size, sequence_length, embedding_dim)</code>，$\\mathbf{W}_Q$、$\\mathbf{W}_K$ 和 $\\mathbf{W}_V$ 的形状为 <code>(embedding_dim, d_k)</code> 或 <code>(embedding_dim, d_v)</code>，$d_k$ 通常等于 $d_v$。</p>\n<p><strong>3） Scaled Dot-Product Attention:</strong></p>\n<p>Scaled Dot-Product Attention 的公式如下：</p>\n<p>$Attention(\\mathbf{Q}, \\mathbf{K}, \\mathbf{V}) = \\text{softmax}(\\frac{\\mathbf{Q}\\mathbf{K}^T}{\\sqrt{d_k}})\\mathbf{V}$</p>\n<ul>\n<li>$\\frac{\\mathbf{Q}\\mathbf{K}^T}{\\sqrt{d_k}}$ 计算了所有查询向量和键向量之间的缩放点积相似度。缩放因子 $\\frac{1}{\\sqrt{d_k}}$ 用于防止点积结果过大，导致 softmax 函数的梯度消失。</li>\n<li>$\\text{softmax}$ 函数将相似度分数转换为概率分布，使得每个查询向量都关注所有键向量，但关注程度不同。</li>\n<li>将概率分布与值矩阵 $\\mathbf{V}$ 相乘，得到加权平均后的值，作为 Attention 的输出。</li>\n</ul>\n<p><strong>4） 多头注意力机制 (Multi-Head Attention):</strong></p>\n<p>多头注意力机制通过将 $d_k$ 和 $d_v$ 分成多个头，并在每个头上分别进行 Scaled Dot-Product Attention，然后将多个头的输出拼接在一起，最后再乘以一个权重矩阵 $\\mathbf{W}_O$，得到最终的输出。  这使得模型可以从不同的子空间学习不同的表示。</p>\n<p><strong>公式:</strong></p>\n<p>$MultiHead(\\mathbf{Q}, \\mathbf{K}, \\mathbf{V}) = Concat(head_1,...,head_h)\\mathbf{W}_O$</p>\n<p>其中，$head_i = Attention(\\mathbf{Q}\\mathbf{W}_i^Q, \\mathbf{K}\\mathbf{W}_i^K, \\mathbf{V}\\mathbf{W}_i^V)$,  $\\mathbf{W}_i^Q$, $\\mathbf{W}_i^K$, $\\mathbf{W}_i^V$ 是第i个头的投影矩阵。</p>\n<h1><strong>II-I. 深度学习重要方法补充</strong></h1>\n<h2><strong>1. 卷积层:</strong></h2>\n<ul>\n<li><strong>普通卷积:</strong>  如前所述，$(f * g)(t) =  \\int f(\\tau)g(t - \\tau)d\\tau$ (连续) 或  $(f * g)(i) = \\sum_j f(j)g(i-j)$ (离散)</li>\n<li><strong>转置卷积 (反卷积):</strong> 用于上采样，增大特征图尺寸.</li>\n<li><strong>空洞卷积 (膨胀卷积):</strong> 通过在卷积核中插入“空洞”来扩大感受野，而不增加参数量.</li>\n<li><strong>深度可分离卷积:</strong> 将标准卷积分解为深度卷积和逐点卷积，减少参数量和计算量.</li>\n</ul>\n<h2><strong>2. 池化层:</strong></h2>\n<ul>\n<li><strong>最大池化:</strong> 选择池化区域内的最大值.</li>\n<li><strong>平均池化:</strong> 计算池化区域内值的平均值.</li>\n</ul>\n<h2><strong>3. 门控单元:</strong></h2>\n<ul>\n<li><strong>LSTM (长短期记忆网络):</strong>  包含输入门、遗忘门、输出门和细胞状态，用于控制信息的流动和记忆.\n<ul>\n<li><strong>输入门:</strong>  决定哪些新信息会被添加到细胞状态.</li>\n<li><strong>遗忘门:</strong> 决定哪些信息会被从细胞状态中移除.</li>\n<li><strong>输出门:</strong> 决定哪些信息会被输出.</li>\n</ul>\n</li>\n<li><strong>GRU (门控循环单元):</strong>  简化版的 LSTM，只有更新门和重置门.</li>\n</ul>\n<h2><strong>4. 残差连接 (Residual Connection):</strong></h2>\n<ul>\n<li><strong>描述:</strong>  将输入添加到后续层的输出中，有助于缓解梯度消失问题，使训练更深层次的网络成为可能.</li>\n<li><strong>公式:</strong>  $y = F(x) + x$，其中 $F(x)$ 是残差块的输出.</li>\n</ul>\n<h2><strong>5. 其他重要方法:</strong></h2>\n<ul>\n<li><strong>Batch Normalization:</strong>  对每层的输入进行归一化，加速训练并提高模型稳定性.</li>\n<li><strong>Dropout:</strong>  在训练过程中随机丢弃一部分神经元，防止过拟合.</li>\n<li><strong>正则化 (L1/L2):</strong>  向损失函数添加惩罚项，限制权重的大小，防止过拟合.</li>\n</ul>\n<h1><strong>II-II. 卷积 VS Transformer补充</strong></h1>\n<h2><strong>1. 卷积的感受野:</strong></h2>\n<ul>\n<li><strong>定义:</strong> 卷积神经网络中，特征图上的一个点对应输入图像上的区域大小。</li>\n<li><strong>计算:</strong> 感受野的大小与卷积核大小、网络深度、步长等因素有关。  感受野越大，意味着该点能够捕捉到更大范围的上下文信息.  每一层的感受野大小可以通过公式递推计算：\n$RF_i = RF_{i-1} + (kernel_size - 1) * stride_{i-1} * stride_{i-2} * ... * stride_1$\n其中 $RF_i$ 是第 i 层的感受野, $kernel_size$ 是卷积核大小, $stride$ 是步长.</li>\n<li><strong>影响:</strong> 感受野的大小对模型的性能有重要影响。例如，在图像识别任务中，更大的感受野可以帮助模型捕捉到更全局的特征。</li>\n</ul>\n<h2><strong>2. Transformer 的感受野:</strong></h2>\n<ul>\n<li><strong>全局感受野:</strong>  理论上，由于自注意力机制，Transformer 可以捕捉到全局的上下文信息，即具有全局感受野。</li>\n<li><strong>实际感受野:</strong>  在实践中，Transformer 的注意力机制会偏向于局部区域，因此实际感受野可能小于全局感受野。  这与注意力权重的分布有关.  研究表明，Transformer 的有效感受野随着网络深度的增加而扩大，但增长速度比卷积网络慢.</li>\n<li><strong>影响:</strong>  Transformer 的感受野特性使其在自然语言处理任务中表现出色，因为它可以捕捉到长距离的依赖关系。</li>\n</ul>\n"}},8277:function(n){n.exports={attributes:{title:"测试文章",date:"2024-11-1",summary:"这是我的第一篇博客文章",coverImage:"2.png",pinned:!1},html:'<h1>欢迎来到我的博客</h1>\n<p>这是一篇测试博客，如果它能正常显示成功就代表它运行正常了。</p>\n<h2>数学公式示例</h2>\n<p>$\nE = mc^2\n$</p>\n<h2>代码块示例</h2>\n<pre><code class="language-python">def hello_world():\n    print(&quot;Hello, World!&quot;)\n</code></pre>\n<h2>图片示例</h2>\n<p><img src="posts/images/1.png" alt="本地图片"></p>\n'}},1137:function(n,t,o){"use strict";var e=o(5130),i=o(6768);const r={class:"app"};function l(n,t,o,e,l,s){const a=(0,i.g2)("blog-header"),u=(0,i.g2)("router-view"),p=(0,i.g2)("blog-footer");return(0,i.uX)(),(0,i.CE)("div",r,[(0,i.bF)(a),(0,i.bF)(u),(0,i.bF)(p)])}var s=o(4232);const a={class:"header-content"},u={class:"header-main"},p={class:"site-nav"};function c(n,t,o,e,r,l){const c=(0,i.g2)("router-link");return(0,i.uX)(),(0,i.CE)("header",{class:(0,s.C4)(["header",{"header-scrolled":r.isScrolled}])},[(0,i.Lk)("div",a,[(0,i.Lk)("div",u,[t[3]||(t[3]=(0,i.Lk)("h1",{class:"site-title"},"星云茶聚",-1)),(0,i.Lk)("nav",p,[(0,i.bF)(c,{to:"/",class:"nav-link"},{default:(0,i.k6)((()=>t[0]||(t[0]=[(0,i.eW)("首页")]))),_:1}),(0,i.bF)(c,{to:"/archive",class:"nav-link"},{default:(0,i.k6)((()=>t[1]||(t[1]=[(0,i.eW)("归档")]))),_:1}),(0,i.bF)(c,{to:"/about",class:"nav-link"},{default:(0,i.k6)((()=>t[2]||(t[2]=[(0,i.eW)("关于")]))),_:1})])])])],2)}var g={name:"BlogHeader",data(){return{isScrolled:!1,lastScrollTop:0,headerHeight:0,scrollThreshold:50,scrollTimer:null}},mounted(){this.headerHeight=this.$el.offsetHeight,window.addEventListener("scroll",this.handleScroll,{passive:!0}),document.body.style.paddingTop=`${this.headerHeight+40}px`},beforeUnmount(){window.removeEventListener("scroll",this.handleScroll),document.body.style.paddingTop="0",this.scrollTimer&&clearTimeout(this.scrollTimer)},methods:{handleScroll(){this.scrollTimer&&cancelAnimationFrame(this.scrollTimer),this.scrollTimer=requestAnimationFrame((()=>{const n=window.scrollY;if(n<=this.scrollThreshold)return void(this.isScrolled=!1);const t=n-this.lastScrollTop;Math.abs(t)>this.scrollThreshold&&(this.isScrolled=!(t>0),this.lastScrollTop=n)}))}}},d=o(1241);const m=(0,d.A)(g,[["render",c],["__scopeId","data-v-1e9d4ba0"]]);var h=m;const _={class:"footer"};function q(n,t,o,e,r,l){return(0,i.uX)(),(0,i.CE)("footer",_,[(0,i.Lk)("p",null,"© "+(0,s.v_)(l.currentYear)+" 星云茶聚. All rights reserved.",1),t[0]||(t[0]=(0,i.Lk)("div",{class:"social-links"},[(0,i.Lk)("a",{href:"#"},"微博"),(0,i.eW)(" | "),(0,i.Lk)("a",{href:"https://github.com/SUXUING-star/SUXUING-star.github.io"},"GitHub"),(0,i.eW)(" | "),(0,i.Lk)("a",{href:"#"},"LinkedIn")],-1))])}var b={name:"BlogFooter",computed:{currentYear(){return(new Date).getFullYear()}}};const f=(0,d.A)(b,[["render",q]]);var $=f,y={name:"App",components:{BlogHeader:h,BlogFooter:$}};const v=(0,d.A)(y,[["render",l]]);var w=v,x=o(1387);const k={class:"home-page"},S={key:0,class:"pinned-posts"},T={class:"posts-grid"},C={class:"regular-posts"},L={key:0,class:"section-title"},A={class:"posts-grid"},E={key:1,class:"pagination"},P=["disabled"],M={class:"pagination-numbers"},B=["onClick"],D=["disabled"];function R(n,t,o,e,r,l){const a=(0,i.g2)("blog-post");return(0,i.uX)(),(0,i.CE)("div",k,[t[3]||(t[3]=(0,i.Lk)("section",{class:"banner"},[(0,i.Lk)("div",{class:"banner-content"},[(0,i.Lk)("h2",null,"欢迎来到这个神奇的地方！"),(0,i.Lk)("p",null,"记录成长，探索未知的世界。")])],-1)),e.pinnedPosts.length?((0,i.uX)(),(0,i.CE)("section",S,[t[2]||(t[2]=(0,i.Lk)("h3",{class:"section-title"},"📌 置顶文章",-1)),(0,i.Lk)("div",T,[((0,i.uX)(!0),(0,i.CE)(i.FK,null,(0,i.pI)(e.pinnedPosts,(n=>((0,i.uX)(),(0,i.Wv)(a,{key:n.id,post:n,onClick:t=>e.viewPost(n.id)},null,8,["post","onClick"])))),128))])])):(0,i.Q3)("",!0),(0,i.Lk)("section",C,[e.pinnedPosts.length?((0,i.uX)(),(0,i.CE)("h3",L,"最新文章")):(0,i.Q3)("",!0),(0,i.Lk)("div",A,[((0,i.uX)(!0),(0,i.CE)(i.FK,null,(0,i.pI)(e.paginatedRegularPosts,(n=>((0,i.uX)(),(0,i.Wv)(a,{key:n.id,post:n,onClick:t=>e.viewPost(n.id)},null,8,["post","onClick"])))),128))])]),e.totalPages>1?((0,i.uX)(),(0,i.CE)("div",E,[(0,i.Lk)("button",{class:"pagination-btn",disabled:1===e.currentPage,onClick:t[0]||(t[0]=n=>e.changePage(e.currentPage-1))}," ← 上一页 ",8,P),(0,i.Lk)("div",M,[((0,i.uX)(!0),(0,i.CE)(i.FK,null,(0,i.pI)(e.displayedPages,(n=>((0,i.uX)(),(0,i.CE)("button",{key:n,class:(0,s.C4)(["page-number",{active:n===e.currentPage}]),onClick:t=>e.changePage(n)},(0,s.v_)(n),11,B)))),128))]),(0,i.Lk)("button",{class:"pagination-btn",disabled:e.currentPage===e.totalPages,onClick:t[1]||(t[1]=n=>e.changePage(e.currentPage+1))}," 下一页 → ",8,D)])):(0,i.Q3)("",!0)])}o(4114),o(8992),o(4520);var F=o(4249),j=o(144);const N={key:0,class:"pin-badge"},z={class:"post-image"},I=["src","alt"],W={key:1,src:"/placeholder-image.gif",alt:"Placeholder Image",loading:"lazy"},O={class:"post-content"},U={class:"post-title"},X={class:"post-meta"},G={class:"post-date"},H={class:"post-summary"};function K(n,t,o,e,r,l){return(0,i.uX)(),(0,i.CE)("article",{class:(0,s.C4)(["blog-post-card",{"blog-post-pinned":o.post.pinned}]),onClick:t[1]||(t[1]=t=>n.$emit("click"))},[o.post.pinned?((0,i.uX)(),(0,i.CE)("div",N,t[2]||(t[2]=[(0,i.Lk)("svg",{xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",viewBox:"0 0 24 24",fill:"none",stroke:"currentColor","stroke-width":"2","stroke-linecap":"round","stroke-linejoin":"round"},[(0,i.Lk)("line",{x1:"12",y1:"17",x2:"12",y2:"22"}),(0,i.Lk)("path",{d:"M5 17h14v-1.76a2 2 0 0 0-1.11-1.79l-1.78-.9A2 2 0 0 1 15 10.76V6h1a2 2 0 0 0 0-4H8a2 2 0 0 0 0 4h1v4.76a2 2 0 0 1-1.11 1.79l-1.78.9A2 2 0 0 0 5 15.24Z"})],-1),(0,i.Lk)("span",null,"置顶",-1)]))):(0,i.Q3)("",!0),(0,i.Lk)("div",z,[o.post.coverImage?((0,i.uX)(),(0,i.CE)("img",{key:0,src:o.post.coverImage,alt:o.post.title,onError:t[0]||(t[0]=(...n)=>l.handleImageError&&l.handleImageError(...n)),loading:"lazy"},null,40,I)):((0,i.uX)(),(0,i.CE)("img",W))]),(0,i.Lk)("div",O,[(0,i.Lk)("h2",U,(0,s.v_)(o.post.title),1),(0,i.Lk)("div",X,[(0,i.Lk)("span",G,(0,s.v_)(o.post.date),1)]),(0,i.Lk)("p",H,(0,s.v_)(o.post.summary),1),t[3]||(t[3]=(0,i.Lk)("div",{class:"post-footer"},[(0,i.Lk)("span",{class:"read-more"},"阅读全文 →")],-1))])],2)}var V={name:"BlogPostItem",props:{post:{type:Object,required:!0,default:()=>({coverImage:"",summary:""}),validator:function(n){return n&&"string"===typeof n.title&&"string"===typeof n.date&&(!("pinned"in n)||"boolean"===typeof n.pinned)&&("string"===typeof n.coverImage||void 0===n.coverImage)&&"string"===typeof n.summary}}},methods:{handleImageError(n){n.target.src="/placeholder-image.gif"}}};const J=(0,d.A)(V,[["render",K],["__scopeId","data-v-0abe35df"]]);var Y=J,Q={name:"HomePage",components:{BlogPost:Y},setup(){const n=(0,F.Pj)(),t=(0,x.rd)(),o=6,e=(0,j.KR)(1),r=(0,i.EW)((()=>(console.log("Posts:",n.state.posts),n.state.posts))),l=(0,i.EW)((()=>r.value.filter((n=>!0===n.frontmatter?.pinned||!0===n.pinned)))),s=(0,i.EW)((()=>r.value.filter((n=>!0!==n.pinned)))),a=(0,i.EW)((()=>Math.ceil(s.value.length/o))),u=(0,i.EW)((()=>{const n=(e.value-1)*o,t=n+o;return s.value.slice(n,t)})),p=(0,i.EW)((()=>{const n=a.value,t=e.value,o=[];if(n<=5)for(let e=1;e<=n;e++)o.push(e);else if(t<=3)for(let e=1;e<=5;e++)o.push(e);else if(t>=n-2)for(let e=n-4;e<=n;e++)o.push(e);else for(let e=t-2;e<=t+2;e++)o.push(e);return o})),c=n=>{e.value=n,window.scrollTo({top:0,behavior:"smooth"})},g=n=>{t.push(`/post/${n}`)};return{pinnedPosts:l,paginatedRegularPosts:u,currentPage:e,totalPages:a,displayedPages:p,changePage:c,viewPost:g}}};const Z=(0,d.A)(Q,[["render",R],["__scopeId","data-v-6ccd4249"]]);var nn=Z;const tn=[{path:"/",name:"Home",component:nn,beforeEnter:(n,t,e)=>{const i=[o.e(594).then(o.bind(o,3431)),o.e(503).then(o.bind(o,9294))];Promise.all(i).catch((()=>{})),e()}},{path:"/about",name:"About",component:()=>o.e(594).then(o.bind(o,3431)),meta:{keepAlive:!0}},{path:"/post/:id",name:"PostDetail",component:()=>Promise.all([o.e(137),o.e(205)]).then(o.bind(o,1989)),props:!0},{path:"/archive",name:"Archive",component:()=>o.e(503).then(o.bind(o,9294)),meta:{keepAlive:!0}}],on=(0,x.aE)({history:(0,x.Bt)(),routes:tn,scrollBehavior(n,t,o){return o||{top:0}}});on.beforeEach(((n,t,o)=>{o()}));var en=on;o(2577),o(1454);const rn=o(5344);function ln(n){const t=new Date(n);return t.toLocaleDateString("zh-CN",{year:"numeric",month:"long",day:"numeric"})}function sn(n){if(!n)return"";if(n.startsWith("http"))return n;try{const t=o(1979),e=n.startsWith("/")?n.slice(1):n,i=t.keys().find((n=>{const t=n.replace(/^\.\//,"");return t===e}));if(i)return t(i);throw new Error(`Image not found: ${n}`)}catch(t){return console.warn(`Image loading error for ${n}:`,t),""}}function an(n){return n.replace(/!\[(.*?)\]\((.*?)\)/g,((n,t,o)=>{if(o.startsWith("http"))return n;try{const e=sn(o);return e?`![${t}](${e})`:n}catch(e){return console.warn(`Failed to process image in markdown: ${o}`),n}}))}function un(){return rn.keys().map(((n,t)=>{const o=n.replace(/^\.\//,"").replace(/\.md$/,""),{attributes:e,html:i}=rn(n);return{id:t+1,slug:o,title:e.title,date:ln(e.date),summary:e.summary,coverImage:sn(e.coverImage),pinned:e.pinned||!1,content:an(i)}}))}const pn=(0,F.y$)({state(){return{posts:un()}},getters:{getPostById:n=>t=>n.posts.find((n=>n.id===parseInt(t))),getPostBySlug:n=>t=>n.posts.find((n=>n.slug===t)),getAllPosts:n=>n.posts},mutations:{UPDATE_POST(n,{id:t,post:o}){const e=n.posts.findIndex((n=>n.id===t));-1!==e&&(n.posts[e]={...n.posts[e],...o})}},actions:{updatePost({commit:n},t){n("UPDATE_POST",t)}}});var cn=pn;o(9351);const gn=(0,e.Ef)(w);gn.use(cn),gn.use(en),gn.mount("#app")},1979:function(n,t,o){var e={"./12-8-1.png":514,"./12-8-2.jpg":6830,"./12-9-1.jpg":9783,"./2.png":7478,"./3.png":4415,"./post2-1.png":1342};function i(n){var t=r(n);return o(t)}function r(n){if(!o.o(e,n)){var t=new Error("Cannot find module '"+n+"'");throw t.code="MODULE_NOT_FOUND",t}return e[n]}i.keys=function(){return Object.keys(e)},i.resolve=r,n.exports=i,i.id=1979},5344:function(n,t,o){var e={"./post10.md":8266,"./post11.md":4377,"./post2.md":3937,"./post3.md":9317,"./post4.md":2879,"./post5.md":3352,"./post6.md":277,"./post7.md":8774,"./post8.md":4307,"./post9.md":2044,"./welcome.md":8277};function i(n){var t=r(n);return o(t)}function r(n){if(!o.o(e,n)){var t=new Error("Cannot find module '"+n+"'");throw t.code="MODULE_NOT_FOUND",t}return e[n]}i.keys=function(){return Object.keys(e)},i.resolve=r,n.exports=i,i.id=5344},514:function(n,t,o){"use strict";n.exports=o.p+"img/12-8-1.36a8b19c.png"},6830:function(n,t,o){"use strict";n.exports=o.p+"img/12-8-2.65a28134.jpg"},9783:function(n,t,o){"use strict";n.exports=o.p+"img/12-9-1.f102fa8e.jpg"},7478:function(n,t,o){"use strict";n.exports=o.p+"img/2.82a2bed7.png"},4415:function(n,t,o){"use strict";n.exports=o.p+"img/3.1cf9cafa.png"},1342:function(n,t,o){"use strict";n.exports=o.p+"img/post2-1.e41820ee.png"}},t={};function o(e){var i=t[e];if(void 0!==i)return i.exports;var r=t[e]={exports:{}};return n[e].call(r.exports,r,r.exports,o),r.exports}o.m=n,function(){var n=[];o.O=function(t,e,i,r){if(!e){var l=1/0;for(p=0;p<n.length;p++){e=n[p][0],i=n[p][1],r=n[p][2];for(var s=!0,a=0;a<e.length;a++)(!1&r||l>=r)&&Object.keys(o.O).every((function(n){return o.O[n](e[a])}))?e.splice(a--,1):(s=!1,r<l&&(l=r));if(s){n.splice(p--,1);var u=i();void 0!==u&&(t=u)}}return t}r=r||0;for(var p=n.length;p>0&&n[p-1][2]>r;p--)n[p]=n[p-1];n[p]=[e,i,r]}}(),function(){o.n=function(n){var t=n&&n.__esModule?function(){return n["default"]}:function(){return n};return o.d(t,{a:t}),t}}(),function(){o.d=function(n,t){for(var e in t)o.o(t,e)&&!o.o(n,e)&&Object.defineProperty(n,e,{enumerable:!0,get:t[e]})}}(),function(){o.f={},o.e=function(n){return Promise.all(Object.keys(o.f).reduce((function(t,e){return o.f[e](n,t),t}),[]))}}(),function(){o.u=function(n){return"js/"+({205:"post",503:"archive",594:"about"}[n]||n)+"."+{137:"5b3b94a8",205:"481568f9",503:"29cb7fcf",594:"6f7f4a2a"}[n]+".js"}}(),function(){o.miniCssF=function(n){return"css/post.fb00c5b2.css"}}(),function(){o.g=function(){if("object"===typeof globalThis)return globalThis;try{return this||new Function("return this")()}catch(n){if("object"===typeof window)return window}}()}(),function(){o.o=function(n,t){return Object.prototype.hasOwnProperty.call(n,t)}}(),function(){var n={},t="xingyunchaju:";o.l=function(e,i,r,l){if(n[e])n[e].push(i);else{var s,a;if(void 0!==r)for(var u=document.getElementsByTagName("script"),p=0;p<u.length;p++){var c=u[p];if(c.getAttribute("src")==e||c.getAttribute("data-webpack")==t+r){s=c;break}}s||(a=!0,s=document.createElement("script"),s.charset="utf-8",s.timeout=120,o.nc&&s.setAttribute("nonce",o.nc),s.setAttribute("data-webpack",t+r),s.src=e),n[e]=[i];var g=function(t,o){s.onerror=s.onload=null,clearTimeout(d);var i=n[e];if(delete n[e],s.parentNode&&s.parentNode.removeChild(s),i&&i.forEach((function(n){return n(o)})),t)return t(o)},d=setTimeout(g.bind(null,void 0,{type:"timeout",target:s}),12e4);s.onerror=g.bind(null,s.onerror),s.onload=g.bind(null,s.onload),a&&document.head.appendChild(s)}}}(),function(){o.r=function(n){"undefined"!==typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(n,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(n,"__esModule",{value:!0})}}(),function(){o.p="/SUXUING-star.github.io/"}(),function(){if("undefined"!==typeof document){var n=function(n,t,e,i,r){var l=document.createElement("link");l.rel="stylesheet",l.type="text/css",o.nc&&(l.nonce=o.nc);var s=function(o){if(l.onerror=l.onload=null,"load"===o.type)i();else{var e=o&&o.type,s=o&&o.target&&o.target.href||t,a=new Error("Loading CSS chunk "+n+" failed.\n("+e+": "+s+")");a.name="ChunkLoadError",a.code="CSS_CHUNK_LOAD_FAILED",a.type=e,a.request=s,l.parentNode&&l.parentNode.removeChild(l),r(a)}};return l.onerror=l.onload=s,l.href=t,e?e.parentNode.insertBefore(l,e.nextSibling):document.head.appendChild(l),l},t=function(n,t){for(var o=document.getElementsByTagName("link"),e=0;e<o.length;e++){var i=o[e],r=i.getAttribute("data-href")||i.getAttribute("href");if("stylesheet"===i.rel&&(r===n||r===t))return i}var l=document.getElementsByTagName("style");for(e=0;e<l.length;e++){i=l[e],r=i.getAttribute("data-href");if(r===n||r===t)return i}},e=function(e){return new Promise((function(i,r){var l=o.miniCssF(e),s=o.p+l;if(t(l,s))return i();n(e,s,null,i,r)}))},i={524:0};o.f.miniCss=function(n,t){var o={205:1};i[n]?t.push(i[n]):0!==i[n]&&o[n]&&t.push(i[n]=e(n).then((function(){i[n]=0}),(function(t){throw delete i[n],t})))}}}(),function(){var n={524:0};o.f.j=function(t,e){var i=o.o(n,t)?n[t]:void 0;if(0!==i)if(i)e.push(i[2]);else{var r=new Promise((function(o,e){i=n[t]=[o,e]}));e.push(i[2]=r);var l=o.p+o.u(t),s=new Error,a=function(e){if(o.o(n,t)&&(i=n[t],0!==i&&(n[t]=void 0),i)){var r=e&&("load"===e.type?"missing":e.type),l=e&&e.target&&e.target.src;s.message="Loading chunk "+t+" failed.\n("+r+": "+l+")",s.name="ChunkLoadError",s.type=r,s.request=l,i[1](s)}};o.l(l,a,"chunk-"+t,t)}},o.O.j=function(t){return 0===n[t]};var t=function(t,e){var i,r,l=e[0],s=e[1],a=e[2],u=0;if(l.some((function(t){return 0!==n[t]}))){for(i in s)o.o(s,i)&&(o.m[i]=s[i]);if(a)var p=a(o)}for(t&&t(e);u<l.length;u++)r=l[u],o.o(n,r)&&n[r]&&n[r][0](),n[r]=0;return o.O(p)},e=self["webpackChunkxingyunchaju"]=self["webpackChunkxingyunchaju"]||[];e.forEach(t.bind(null,0)),e.push=t.bind(null,e.push.bind(e))}();var e=o.O(void 0,[683,501,849,823],(function(){return o(1137)}));e=o.O(e)})();
//# sourceMappingURL=app.a8cb9d7e.js.map