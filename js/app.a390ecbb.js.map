{"version":3,"file":"js/app.a390ecbb.js","mappings":"oCACAA,EAAOC,QAAU,CACXC,WAAY,CAAC,MAAQ,eAAe,KAAO,2BAA2B,QAAU,sBAAsB,WAAa,cAAc,QAAS,GAE1IC,KAAM,82U,mBCHZH,EAAOC,QAAU,CACXC,WAAY,CAAC,MAAQ,mBAAmB,KAAO,2BAA2B,QAAU,aAAa,WAAa,QAAQ,QAAS,GAE/HC,KAAM,s2B,mBCHZH,EAAOC,QAAU,CACXC,WAAY,CAAC,MAAQ,oBAAoB,KAAO,2BAA2B,QAAU,YAAY,WAAa,cAAc,QAAS,GAErIC,KAAM,q3Y,mBCHZH,EAAOC,QAAU,CACXC,WAAY,CAAC,MAAQ,mBAAmB,KAAO,2BAA2B,QAAU,cAAc,WAAa,cAAc,QAAS,GAEtIC,KAAM,8xpC,kBCHZH,EAAOC,QAAU,CACXC,WAAY,CAAC,MAAQ,qBAAqB,KAAO,2BAA2B,QAAU,cAAc,WAAa,cAAc,QAAS,GAExIC,KAAM,+lS,mBCHZH,EAAOC,QAAU,CACXC,WAAY,CAAC,MAAQ,cAAc,KAAO,2BAA2B,QAAU,WAAW,WAAa,cAAc,QAAS,GAE9HC,KAAM,wu+B,mBCHZH,EAAOC,QAAU,CACXC,WAAY,CAAC,MAAQ,2BAA2B,KAAO,2BAA2B,QAAU,aAAa,WAAa,cAAc,QAAS,GAE7IC,KAAM,4P,mBCHZH,EAAOC,QAAU,CACXC,WAAY,CAAC,MAAQ,WAAW,KAAO,2BAA2B,QAAU,YAAY,WAAa,cAAc,QAAS,GAE5HC,KAAM,wB,mBCHZH,EAAOC,QAAU,CACXC,WAAY,CAAC,MAAQ,OAAO,KAAO,YAAY,QAAU,cAAc,WAAa,cAAc,QAAS,GAE3GC,KAAM,iS,qECFLC,MAAM,O,8HAAXC,EAAAA,EAAAA,IAIM,MAJNC,EAIM,EAHJC,EAAAA,EAAAA,IAAeC,IACfD,EAAAA,EAAAA,IAAeE,IACfF,EAAAA,EAAAA,IAAeG,I,wBCFVN,MAAM,kB,GACJA,MAAM,e,GAEJA,MAAM,Y,0EAJjBC,EAAAA,EAAAA,IAWS,UAXDD,OAFVO,EAAAA,EAAAA,IAAA,CAEgB,SAAQ,mBAA8BC,EAAAC,e,EAClDC,EAAAA,EAAAA,IASM,MATNR,EASM,EARJQ,EAAAA,EAAAA,IAOM,MAPNC,EAOM,cANJD,EAAAA,EAAAA,IAAgC,MAA5BV,MAAM,cAAa,QAAI,KAC3BU,EAAAA,EAAAA,IAIM,MAJNE,EAIM,EAHJT,EAAAA,EAAAA,IAAqDU,EAAA,CAAxCC,GAAG,IAAId,MAAM,Y,CAPpCe,SAAAC,EAAAA,EAAAA,KAO+C,IAAEC,EAAA,KAAAA,EAAA,KAPjDC,EAAAA,EAAAA,IAO+C,UAP/CC,EAAA,KAQUhB,EAAAA,EAAAA,IAA4DU,EAAA,CAA/CC,GAAG,WAAWd,MAAM,Y,CAR3Ce,SAAAC,EAAAA,EAAAA,KAQsD,IAAEC,EAAA,KAAAA,EAAA,KARxDC,EAAAA,EAAAA,IAQsD,UARtDC,EAAA,KASUhB,EAAAA,EAAAA,IAA0DU,EAAA,CAA7CC,GAAG,SAASd,MAAM,Y,CATzCe,SAAAC,EAAAA,EAAAA,KASoD,IAAEC,EAAA,KAAAA,EAAA,KATtDC,EAAAA,EAAAA,IASoD,UATpDC,EAAA,W,GAkBA,OACEC,KAAM,aACNC,IAAAA,GACE,MAAO,CACLZ,YAAY,EACZa,cAAe,EACfC,aAAc,EACdC,gBAAiB,GACjBC,YAAa,KAEjB,EACAC,OAAAA,GACEC,KAAKJ,aAAeI,KAAKC,IAAIC,aAC7BC,OAAOC,iBAAiB,SAAUJ,KAAKK,aAAc,CAAEC,SAAS,IAChEC,SAASC,KAAKC,MAAMC,WAAa,GAAGV,KAAKJ,aAAe,MAC1D,EACAe,aAAAA,GACER,OAAOS,oBAAoB,SAAUZ,KAAKK,cAC1CE,SAASC,KAAKC,MAAMC,WAAa,IAC7BV,KAAKF,aACPe,aAAab,KAAKF,YAEtB,EACAgB,QAAS,CACPT,YAAAA,GAEML,KAAKF,aACPiB,qBAAqBf,KAAKF,aAG5BE,KAAKF,YAAckB,uBAAsB,KACvC,MAAMC,EAAKd,OAAOe,QAGlB,GAAID,GAAMjB,KAAKH,gBAEb,YADAG,KAAKlB,YAAa,GAKpB,MAAMqC,EAAcF,EAAKjB,KAAKL,cAG1ByB,KAAKC,IAAIF,GAAenB,KAAKH,kBAG7BG,KAAKlB,aAFHqC,EAAc,GAOlBnB,KAAKL,cAAgBsB,EACvB,GAEJ,I,UCjEJ,MAAMK,GAA2B,OAAgB,EAAQ,CAAC,CAAC,SAAS,GAAQ,CAAC,YAAY,qBAEzF,Q,SCPYjD,MAAM,U,0CAAdC,EAAAA,EAAAA,IAOS,SAPTC,EAOS,EANPQ,EAAAA,EAAAA,IAAqD,SAAlD,MAAEwC,EAAAA,EAAAA,IAAGC,EAAAC,aAAc,8BAA2B,gBACjD1C,EAAAA,EAAAA,IAIM,OAJDV,MAAM,gBAAc,EACvBU,EAAAA,EAAAA,IAAkB,KAAf2C,KAAK,KAAI,OALpBnC,EAAAA,EAAAA,IAK0B,QAClBR,EAAAA,EAAAA,IAA2E,KAAxE2C,KAAK,0DAAyD,WANzEnC,EAAAA,EAAAA,IAMmF,QAC3ER,EAAAA,EAAAA,IAAwB,KAArB2C,KAAK,KAAI,cAAQ,K,CAM1B,OACEjC,KAAM,aACNkC,SAAU,CACRF,WAAAA,GACE,OAAO,IAAIG,MAAOC,aACpB,ICbN,MAAM,GAA2B,OAAgB,EAAQ,CAAC,CAAC,SAAS,KAEpE,QJMA,GACEpC,KAAM,MACNqC,WAAY,CACVC,WAAU,EACVC,WAAUA,IKZd,MAAM,GAA2B,OAAgB,EAAQ,CAAC,CAAC,SAASC,KAEpE,Q,mBCLO5D,MAAM,a,GAFb6D,IAAA,EAYuC7D,MAAM,gB,GAElCA,MAAM,c,GAWJA,MAAM,iB,GAzBnB6D,IAAA,EA0BoC7D,MAAM,iB,GAC/BA,MAAM,c,GA3BjB6D,IAAA,EAsC+B7D,MAAM,c,EAtCrC,a,GA+CWA,MAAM,sB,EA/CjB,Y,EAAA,a,wEAEEC,EAAAA,EAAAA,IAiEM,MAjENC,EAiEM,cAhEJQ,EAAAA,EAAAA,IAKU,WALDV,MAAM,UAAQ,EACrBU,EAAAA,EAAAA,IAGM,OAHDV,MAAM,kBAAgB,EACzBU,EAAAA,EAAAA,IAAqB,UAAjB,iBACJA,EAAAA,EAAAA,IAAoB,SAAjB,qBAAa,IAMLoD,EAAAC,YAAYC,SAAM,WAAjC/D,EAAAA,EAAAA,IAUU,UAVVU,EAUU,cATRD,EAAAA,EAAAA,IAAsC,MAAlCV,MAAM,iBAAgB,WAAO,KACjCU,EAAAA,EAAAA,IAOM,MAPNE,EAOM,gBANJX,EAAAA,EAAAA,IAKEgE,EAAAA,GAAA,MApBVC,EAAAA,EAAAA,IAgByBJ,EAAAC,aAARI,K,WADTC,EAAAA,EAAAA,IAKEC,EAAA,CAHCR,IAAKM,EAAKG,GACVH,KAAMA,EACNI,QAAKC,GAAEV,EAAAW,SAASN,EAAKG,K,0CAnBhCI,EAAAA,EAAAA,IAAA,QAyBIhE,EAAAA,EAAAA,IAUU,UAVViE,EAUU,CATEb,EAAAC,YAAYC,SAAM,WAA5B/D,EAAAA,EAAAA,IAA6D,KAA7D2E,EAAoD,UA1B1DF,EAAAA,EAAAA,IAAA,QA2BMhE,EAAAA,EAAAA,IAOM,MAPNmE,EAOM,gBANJ5E,EAAAA,EAAAA,IAKEgE,EAAAA,GAAA,MAjCVC,EAAAA,EAAAA,IA6ByBJ,EAAAgB,uBAARX,K,WADTC,EAAAA,EAAAA,IAKEC,EAAA,CAHCR,IAAKM,EAAKG,GACVH,KAAMA,EACNI,QAAKC,GAAEV,EAAAW,SAASN,EAAKG,K,wCAMjBR,EAAAiB,WAAa,IAAH,WAArB9E,EAAAA,EAAAA,IA4BM,MA5BN+E,EA4BM,EA3BJtE,EAAAA,EAAAA,IAMS,UALPV,MAAM,iBACLiF,SAA0B,IAAhBnB,EAAAoB,YACVX,QAAKtD,EAAA,KAAAA,EAAA,GAAAuD,GAAEV,EAAAqB,WAAWrB,EAAAoB,YAAc,KAClC,UAED,EA7CNE,IA+CM1E,EAAAA,EAAAA,IAUM,MAVN2E,EAUM,gBATJpF,EAAAA,EAAAA,IAQSgE,EAAAA,GAAA,MAxDjBC,EAAAA,EAAAA,IAiDyBJ,EAAAwB,gBAARC,K,WADTtF,EAAAA,EAAAA,IAQS,UANN4D,IAAK0B,EACNvF,OAnDVO,EAAAA,EAAAA,IAAA,CAmDgB,cAAa,CAAAiF,OACDD,IAASzB,EAAAoB,eAC1BX,QAAKC,GAAEV,EAAAqB,WAAWI,K,QAEhBA,GAAI,GAvDjBE,M,SA2DM/E,EAAAA,EAAAA,IAMS,UALPV,MAAM,iBACLiF,SAAUnB,EAAAoB,cAAgBpB,EAAAiB,WAC1BR,QAAKtD,EAAA,KAAAA,EAAA,GAAAuD,GAAEV,EAAAqB,WAAWrB,EAAAoB,YAAc,KAClC,UAED,EAjENQ,OAAAhB,EAAAA,EAAAA,IAAA,Q,yDCAAb,IAAA,EAIS7D,MAAM,a,GASNA,MAAM,c,EAbf,c,GAAA6D,IAAA,EAuBQ8B,IAAI,yBACJC,IAAI,oBACJC,QAAQ,Q,GAGP7F,MAAM,gB,GACLA,MAAM,c,GACLA,MAAM,a,GACHA,MAAM,a,GAEXA,MAAM,gB,0CA/BbC,EAAAA,EAAAA,IAoCU,WApCDD,OAFXO,EAAAA,EAAAA,IAAA,CAEiB,iBAAgB,oBAA+BuF,EAAA3B,KAAK4B,UAAWxB,QAAKtD,EAAA,KAAAA,EAAA,GAAAuD,GAAEwB,EAAAC,MAAM,W,CAE5DH,EAAA3B,KAAK4B,SAAM,WAAxC9F,EAAAA,EAAAA,IAOM,MAPNC,EAOMe,EAAA,KAAAA,EAAA,KANJP,EAAAA,EAAAA,IAIM,OAJDwF,MAAM,6BAA6BC,MAAM,KAAKC,OAAO,KAAKC,QAAQ,YAAYC,KAAK,OACnFC,OAAO,eAAe,eAAa,IAAI,iBAAe,QAAQ,kBAAgB,S,EACjF7F,EAAAA,EAAAA,IAAuC,QAAjC8F,GAAG,KAAKC,GAAG,KAAKC,GAAG,KAAKC,GAAG,QACjCjG,EAAAA,EAAAA,IAAkK,QAA5JkG,EAAE,6JAAwJ,IAElKlG,EAAAA,EAAAA,IAAe,YAAT,MAAE,QAVdgE,EAAAA,EAAAA,IAAA,QAaIhE,EAAAA,EAAAA,IAcM,MAdNC,EAcM,CAZImF,EAAA3B,KAAK0C,aAAU,WADvB5G,EAAAA,EAAAA,IAMC,OApBP4D,IAAA,EAgBS8B,IAAKG,EAAA3B,KAAK0C,WACVjB,IAAKE,EAAA3B,KAAK2C,MACVC,QAAK9F,EAAA,KAAAA,EAAA,OAAA+F,IAAE7D,EAAA8D,kBAAA9D,EAAA8D,oBAAAD,IACRnB,QAAQ,Q,QAnBhBjF,MAAA,WAqBMX,EAAAA,EAAAA,IAKC,MALD0E,OAOFjE,EAAAA,EAAAA,IASM,MATNkE,EASM,EARJlE,EAAAA,EAAAA,IAA4C,KAA5CmE,GAA4C3B,EAAAA,EAAAA,IAAlB4C,EAAA3B,KAAK2C,OAAK,IACpCpG,EAAAA,EAAAA,IAEM,MAFNsE,EAEM,EADJtE,EAAAA,EAAAA,IAA8C,OAA9C0E,GAA8ClC,EAAAA,EAAAA,IAAnB4C,EAAA3B,KAAK+C,MAAI,MAEtCxG,EAAAA,EAAAA,IAA8C,IAA9C2E,GAA8CnC,EAAAA,EAAAA,IAAnB4C,EAAA3B,KAAKgD,SAAO,gBACvCzG,EAAAA,EAAAA,IAEM,OAFDV,MAAM,eAAa,EACtBU,EAAAA,EAAAA,IAAqC,QAA/BV,MAAM,aAAY,YAAM,S,CAOtC,OACEoB,KAAM,eACNgG,MAAO,CACLjD,KAAM,CACJkD,KAAMC,OACNC,UAAU,EACVxG,QAASA,KAAA,CAEP8F,WAAY,GACZM,QAAS,KAEXK,UAAW,SAASC,GAClB,OAAOA,GAEiB,kBAAdA,EAAIX,OAES,kBAAbW,EAAIP,SAET,WAAYO,IAA8B,mBAAfA,EAAI1B,UAEP,kBAAnB0B,EAAIZ,iBAA8Ca,IAAnBD,EAAIZ,aAEnB,kBAAhBY,EAAIN,OAChB,IAGJ1E,QAAS,CACPwE,gBAAAA,CAAiBU,GACfA,EAAEC,OAAOjC,IAAM,wBACjB,IChEJ,MAAM,GAA2B,OAAgB,EAAQ,CAAC,CAAC,SAAS,GAAQ,CAAC,YAAY,qBAEzF,QFmEA,GACEvE,KAAM,WACNqC,WAAY,CACVoE,SAAQA,GAEVC,KAAAA,GACE,MAAMC,GAAQC,EAAAA,EAAAA,MACRC,GAASC,EAAAA,EAAAA,MAETC,EAAe,EACfjD,GAAckD,EAAAA,EAAAA,IAAI,GAElBC,GAAQ/E,EAAAA,EAAAA,KAAS,KACrBgF,QAAQC,IAAI,SAAUR,EAAMS,MAAMH,OAC3BN,EAAMS,MAAMH,SAIftE,GAAcT,EAAAA,EAAAA,KAAS,IAC3B+E,EAAMI,MAAMC,QAAOvE,IACY,IAA7BA,EAAKwE,aAAa5C,SACF,IAAhB5B,EAAK4B,WAGH6C,GAAetF,EAAAA,EAAAA,KAAS,IAC5B+E,EAAMI,MAAMC,QAAOvE,IAAwB,IAAhBA,EAAK4B,WAI5BhB,GAAazB,EAAAA,EAAAA,KAAS,IAC1BP,KAAK8F,KAAKD,EAAaH,MAAMzE,OAASmE,KAIlCrD,GAAwBxB,EAAAA,EAAAA,KAAS,KACrC,MAAMwF,GAAS5D,EAAYuD,MAAQ,GAAKN,EAClCY,EAAMD,EAAQX,EACpB,OAAOS,EAAaH,MAAMO,MAAMF,EAAOC,EAAI,IAIvCzD,GAAiBhC,EAAAA,EAAAA,KAAS,KAC9B,MAAM2F,EAAQlE,EAAW0D,MACnBS,EAAUhE,EAAYuD,MACtBU,EAAQ,GAEd,GAAIF,GAAS,EACX,IAAK,IAAIG,EAAI,EAAGA,GAAKH,EAAOG,IAC1BD,EAAME,KAAKD,QAGb,GAAIF,GAAW,EACb,IAAK,IAAIE,EAAI,EAAGA,GAAK,EAAGA,IACtBD,EAAME,KAAKD,QAER,GAAIF,GAAWD,EAAQ,EAC5B,IAAK,IAAIG,EAAIH,EAAQ,EAAGG,GAAKH,EAAOG,IAClCD,EAAME,KAAKD,QAGb,IAAK,IAAIA,EAAIF,EAAU,EAAGE,GAAKF,EAAU,EAAGE,IAC1CD,EAAME,KAAKD,GAKjB,OAAOD,CAAI,IAGPhE,EAAcI,IAClBL,EAAYuD,MAAQlD,EACpBzD,OAAOwH,SAAS,CACdC,IAAK,EACLC,SAAU,UACV,EAGE/E,EAAYH,IAChB2D,EAAOoB,KAAK,SAAS/E,IAAK,EAG5B,MAAO,CACLP,cACAe,wBACAI,cACAH,aACAO,iBACAH,aACAV,WAEJ,GG/JF,MAAM,GAA2B,OAAgB,EAAQ,CAAC,CAAC,SAAS,GAAQ,CAAC,YAAY,qBAEzF,SCNA,MAAMgF,GAAS,CACb,CACEC,KAAM,IACNtI,KAAM,OACNuI,UAAWC,GAEXC,YAAaA,CAAC/I,EAAIgJ,EAAMC,KACtB,MAAMtG,EAAa,CACjB,8BACA,+BAEFuG,QAAQC,IAAIxG,GAAYyG,OAAM,SAC9BH,GAAM,GAGV,CACEL,KAAM,SACNtI,KAAM,QACNuI,UAAWA,IAAM,8BAEjBQ,KAAM,CAAEC,WAAW,IAErB,CACEV,KAAM,YACNtI,KAAM,aACNuI,UAAWA,IAAM,sDACjBvC,OAAO,GAET,CACEsC,KAAM,WACNtI,KAAM,UACNuI,UAAWA,IAAM,8BACjBQ,KAAM,CAAEC,WAAW,KAIjBnC,IAASoC,EAAAA,EAAAA,IAAa,CAC1BC,SAASC,EAAAA,EAAAA,MACTd,UAEAe,cAAAA,CAAe1J,EAAIgJ,EAAMW,GACvB,OAAIA,GAGK,CAAElB,IAAK,EAElB,IAIFtB,GAAOyC,YAAW,CAAC5J,EAAIgJ,EAAMC,KAE3BA,GAAM,IAGR,U,gBCvDA,MAAMY,GAAgBC,EAAAA,MAGtB,SAASC,GAAWC,GAClB,MAAM5D,EAAO,IAAI3D,KAAKuH,GACtB,OAAO5D,EAAK6D,mBAAmB,QAAS,CACtCC,KAAM,UACNC,MAAO,OACPC,IAAK,WAET,CAGA,SAASC,GAAYC,GACnB,IAAKA,EAAW,MAAO,GACvB,GAAIA,EAAUC,WAAW,QACvB,OAAOD,EAGT,IACE,OAAOR,EAAAA,KAAAA,CAAQ,KAAmBQ,IACpC,CAAE,MAAOzD,GAEP,OADAW,QAAQgD,KAAK,oBAAoBF,KAC1B,EACT,CACF,CAGA,SAASG,GAAsBC,GAC7B,OAAOA,EAAQC,QACb,wBACA,CAACC,EAAO9F,EAAK8D,KACX,GAAIA,EAAK2B,WAAW,QAClB,OAAOK,EAET,IACE,MAAMC,EAAWf,EAAAA,KAAAA,CAAQ,KAAmBlB,KAC5C,MAAO,KAAK9D,MAAQ+F,IACtB,CAAE,MAAOhE,GAEP,OADAW,QAAQgD,KAAK,gCAAgC5B,KACtCgC,CACT,IAGN,CAGA,SAASE,KACP,OAAOjB,GAAckB,OAAOC,KAAI,CAACpC,EAAMqC,KACrC,MAAMC,EAAOtC,EAAK+B,QAAQ,QAAS,IAAIA,QAAQ,QAAS,KAClD,WAAE3L,EAAU,KAAEC,GAAS4K,GAAcjB,GAE3C,MAAO,CACLpF,GAAIyH,EAAQ,EACZC,OACAlF,MAAOhH,EAAWgH,MAClBI,KAAM2D,GAAW/K,EAAWoH,MAC5BC,QAASrH,EAAWqH,QACpBN,WAAYsE,GAAYrL,EAAW+G,YACnCd,OAAQjG,EAAWiG,SAAU,EAC7ByF,QAASD,GAAsBxL,GAChC,GAEL,CAEA,MAAMgI,IAAQkE,EAAAA,EAAAA,IAAY,CACxBzD,KAAAA,GACE,MAAO,CACLH,MAAOuD,KAEX,EACAM,QAAS,CACPC,YAAc3D,GAAWlE,GAChBkE,EAAMH,MAAM+D,MAAKjI,GAAQA,EAAKG,KAAO+H,SAAS/H,KAEvDgI,cAAgB9D,GAAWwD,GAClBxD,EAAMH,MAAM+D,MAAKjI,GAAQA,EAAK6H,OAASA,IAEhDO,YAAc/D,GACLA,EAAMH,OAGjBmE,UAAW,CACTC,WAAAA,CAAYjE,GAAO,GAAElE,EAAE,KAAEH,IACvB,MAAM4H,EAAQvD,EAAMH,MAAMqE,WAAUC,GAAKA,EAAErI,KAAOA,KACnC,IAAXyH,IACFvD,EAAMH,MAAM0D,GAAS,IAAKvD,EAAMH,MAAM0D,MAAW5H,GAErD,GAEFyI,QAAS,CACPC,UAAAA,EAAW,OAAEC,GAAUC,GACrBD,EAAO,cAAeC,EACxB,KAIJ,U,QCtFA,MAAMC,IAAMC,EAAAA,EAAAA,IAAUC,GAEtBF,GAAIG,IAAIpF,IACRiF,GAAIG,IAAIlF,IAER+E,GAAII,MAAM,O,uBCnBV,IAAItB,EAAM,CACT,gBAAiB,KACjB,gBAAiB,KACjB,gBAAiB,KACjB,gBAAiB,IACjB,gBAAiB,KACjB,gBAAiB,KACjB,gBAAiB,KACjB,gBAAiB,KACjB,gBAAiB,KACjB,UAAW,KACX,gBAAiB,IACjB,sBAAuB,MAIxB,SAASuB,EAAeC,GACvB,IAAIhJ,EAAKiJ,EAAsBD,GAC/B,OAAOE,EAAoBlJ,EAC5B,CACA,SAASiJ,EAAsBD,GAC9B,IAAIE,EAAoBC,EAAE3B,EAAKwB,GAAM,CACpC,IAAI3F,EAAI,IAAI+F,MAAM,uBAAyBJ,EAAM,KAEjD,MADA3F,EAAEgG,KAAO,mBACHhG,CACP,CACA,OAAOmE,EAAIwB,EACZ,CACAD,EAAexB,KAAO,WACrB,OAAOvE,OAAOuE,KAAKC,EACpB,EACAuB,EAAeO,QAAUL,EACzB3N,EAAOC,QAAUwN,EACjBA,EAAe/I,GAAK,I,uBCjCpB,IAAIwH,EAAM,CACT,aAAc,KACd,aAAc,KACd,aAAc,KACd,aAAc,KACd,aAAc,IACd,aAAc,KACd,aAAc,KACd,aAAc,KACd,eAAgB,MAIjB,SAASuB,EAAeC,GACvB,IAAIhJ,EAAKiJ,EAAsBD,GAC/B,OAAOE,EAAoBlJ,EAC5B,CACA,SAASiJ,EAAsBD,GAC9B,IAAIE,EAAoBC,EAAE3B,EAAKwB,GAAM,CACpC,IAAI3F,EAAI,IAAI+F,MAAM,uBAAyBJ,EAAM,KAEjD,MADA3F,EAAEgG,KAAO,mBACHhG,CACP,CACA,OAAOmE,EAAIwB,EACZ,CACAD,EAAexB,KAAO,WACrB,OAAOvE,OAAOuE,KAAKC,EACpB,EACAuB,EAAeO,QAAUL,EACzB3N,EAAOC,QAAUwN,EACjBA,EAAe/I,GAAK,I,q4BC7BhBuJ,EAA2B,CAAC,EAGhC,SAASL,EAAoBM,GAE5B,IAAIC,EAAeF,EAAyBC,GAC5C,QAAqBpG,IAAjBqG,EACH,OAAOA,EAAalO,QAGrB,IAAID,EAASiO,EAAyBC,GAAY,CAGjDjO,QAAS,CAAC,GAOX,OAHAmO,EAAoBF,GAAUG,KAAKrO,EAAOC,QAASD,EAAQA,EAAOC,QAAS2N,GAGpE5N,EAAOC,OACf,CAGA2N,EAAoBU,EAAIF,E,WCzBxB,IAAIG,EAAW,GACfX,EAAoBY,EAAI,SAASC,EAAQC,EAAUC,EAAIC,GACtD,IAAGF,EAAH,CAMA,IAAIG,EAAeC,IACnB,IAAStF,EAAI,EAAGA,EAAI+E,EAASnK,OAAQoF,IAAK,CACrCkF,EAAWH,EAAS/E,GAAG,GACvBmF,EAAKJ,EAAS/E,GAAG,GACjBoF,EAAWL,EAAS/E,GAAG,GAE3B,IAJA,IAGIuF,GAAY,EACPC,EAAI,EAAGA,EAAIN,EAAStK,OAAQ4K,MACpB,EAAXJ,GAAsBC,GAAgBD,IAAalH,OAAOuE,KAAK2B,EAAoBY,GAAGS,OAAM,SAAShL,GAAO,OAAO2J,EAAoBY,EAAEvK,GAAKyK,EAASM,GAAK,IAChKN,EAASQ,OAAOF,IAAK,IAErBD,GAAY,EACTH,EAAWC,IAAcA,EAAeD,IAG7C,GAAGG,EAAW,CACbR,EAASW,OAAO1F,IAAK,GACrB,IAAI2F,EAAIR,SACE7G,IAANqH,IAAiBV,EAASU,EAC/B,CACD,CACA,OAAOV,CArBP,CAJCG,EAAWA,GAAY,EACvB,IAAI,IAAIpF,EAAI+E,EAASnK,OAAQoF,EAAI,GAAK+E,EAAS/E,EAAI,GAAG,GAAKoF,EAAUpF,IAAK+E,EAAS/E,GAAK+E,EAAS/E,EAAI,GACrG+E,EAAS/E,GAAK,CAACkF,EAAUC,EAAIC,EAwB/B,C,eC5BAhB,EAAoBwB,EAAI,SAASpP,GAChC,IAAIqP,EAASrP,GAAUA,EAAOsP,WAC7B,WAAa,OAAOtP,EAAO,UAAY,EACvC,WAAa,OAAOA,CAAQ,EAE7B,OADA4N,EAAoB5G,EAAEqI,EAAQ,CAAEE,EAAGF,IAC5BA,CACR,C,eCNAzB,EAAoB5G,EAAI,SAAS/G,EAASuP,GACzC,IAAI,IAAIvL,KAAOuL,EACX5B,EAAoBC,EAAE2B,EAAYvL,KAAS2J,EAAoBC,EAAE5N,EAASgE,IAC5EyD,OAAO+H,eAAexP,EAASgE,EAAK,CAAEyL,YAAY,EAAMC,IAAKH,EAAWvL,IAG3E,C,eCPA2J,EAAoBgC,EAAI,CAAC,EAGzBhC,EAAoB7F,EAAI,SAAS8H,GAChC,OAAOzF,QAAQC,IAAI3C,OAAOuE,KAAK2B,EAAoBgC,GAAGE,QAAO,SAASC,EAAU9L,GAE/E,OADA2J,EAAoBgC,EAAE3L,GAAK4L,EAASE,GAC7BA,CACR,GAAG,IACJ,C,eCPAnC,EAAoBoC,EAAI,SAASH,GAEhC,MAAO,OAAS,CAAC,IAAM,OAAO,IAAM,UAAU,IAAM,SAASA,IAAYA,GAAW,IAAM,CAAC,IAAM,WAAW,IAAM,WAAW,IAAM,WAAW,IAAM,YAAYA,GAAW,KAC5K,C,eCHAjC,EAAoBqC,SAAW,SAASJ,GAEvC,MAAO,uBACR,C,eCJAjC,EAAoBsC,EAAI,WACvB,GAA0B,kBAAfC,WAAyB,OAAOA,WAC3C,IACC,OAAOpO,MAAQ,IAAIqO,SAAS,cAAb,EAChB,CAAE,MAAOrI,GACR,GAAsB,kBAAX7F,OAAqB,OAAOA,MACxC,CACA,CAPuB,E,eCAxB0L,EAAoBC,EAAI,SAAShG,EAAKwI,GAAQ,OAAO3I,OAAO4I,UAAUC,eAAelC,KAAKxG,EAAKwI,EAAO,C,eCAtG,IAAIG,EAAa,CAAC,EACdC,EAAoB,gBAExB7C,EAAoB8C,EAAI,SAASC,EAAKC,EAAM3M,EAAK4L,GAChD,GAAGW,EAAWG,GAAQH,EAAWG,GAAKlH,KAAKmH,OAA3C,CACA,IAAIC,EAAQC,EACZ,QAAWhJ,IAAR7D,EAEF,IADA,IAAI8M,EAAUzO,SAAS0O,qBAAqB,UACpCxH,EAAI,EAAGA,EAAIuH,EAAQ3M,OAAQoF,IAAK,CACvC,IAAIyH,EAAIF,EAAQvH,GAChB,GAAGyH,EAAEC,aAAa,QAAUP,GAAOM,EAAEC,aAAa,iBAAmBT,EAAoBxM,EAAK,CAAE4M,EAASI,EAAG,KAAO,CACpH,CAEGJ,IACHC,GAAa,EACbD,EAASvO,SAAS6O,cAAc,UAEhCN,EAAOO,QAAU,QACjBP,EAAOQ,QAAU,IACbzD,EAAoB0D,IACvBT,EAAOU,aAAa,QAAS3D,EAAoB0D,IAElDT,EAAOU,aAAa,eAAgBd,EAAoBxM,GAExD4M,EAAO9K,IAAM4K,GAEdH,EAAWG,GAAO,CAACC,GACnB,IAAIY,EAAmB,SAASC,EAAMC,GAErCb,EAAOc,QAAUd,EAAOe,OAAS,KACjChP,aAAayO,GACb,IAAIQ,EAAUrB,EAAWG,GAIzB,UAHOH,EAAWG,GAClBE,EAAOiB,YAAcjB,EAAOiB,WAAWC,YAAYlB,GACnDgB,GAAWA,EAAQG,SAAQ,SAASrD,GAAM,OAAOA,EAAG+C,EAAQ,IACzDD,EAAM,OAAOA,EAAKC,EACtB,EACIL,EAAUY,WAAWT,EAAiBU,KAAK,UAAMpK,EAAW,CAAEL,KAAM,UAAWO,OAAQ6I,IAAW,MACtGA,EAAOc,QAAUH,EAAiBU,KAAK,KAAMrB,EAAOc,SACpDd,EAAOe,OAASJ,EAAiBU,KAAK,KAAMrB,EAAOe,QACnDd,GAAcxO,SAAS6P,KAAKC,YAAYvB,EApCkB,CAqC3D,C,eCxCAjD,EAAoBuB,EAAI,SAASlP,GACX,qBAAXoS,QAA0BA,OAAOC,aAC1C5K,OAAO+H,eAAexP,EAASoS,OAAOC,YAAa,CAAEzJ,MAAO,WAE7DnB,OAAO+H,eAAexP,EAAS,aAAc,CAAE4I,OAAO,GACvD,C,eCNA+E,EAAoBb,EAAI,0B,eCAxB,GAAwB,qBAAbzK,SAAX,CACA,IAAIiQ,EAAmB,SAAS1C,EAAS2C,EAAUC,EAAQzE,EAAS0E,GACnE,IAAIC,EAAUrQ,SAAS6O,cAAc,QAErCwB,EAAQC,IAAM,aACdD,EAAQlL,KAAO,WACXmG,EAAoB0D,KACvBqB,EAAQE,MAAQjF,EAAoB0D,IAErC,IAAIwB,EAAiB,SAASpB,GAG7B,GADAiB,EAAQhB,QAAUgB,EAAQf,OAAS,KAChB,SAAfF,EAAMjK,KACTuG,QACM,CACN,IAAI+E,EAAYrB,GAASA,EAAMjK,KAC3BuL,EAAWtB,GAASA,EAAM1J,QAAU0J,EAAM1J,OAAOvE,MAAQ+O,EACzDS,EAAM,IAAInF,MAAM,qBAAuB+B,EAAU,cAAgBkD,EAAY,KAAOC,EAAW,KACnGC,EAAIzR,KAAO,iBACXyR,EAAIlF,KAAO,wBACXkF,EAAIxL,KAAOsL,EACXE,EAAIC,QAAUF,EACVL,EAAQb,YAAYa,EAAQb,WAAWC,YAAYY,GACvDD,EAAOO,EACR,CACD,EAUA,OATAN,EAAQhB,QAAUgB,EAAQf,OAASkB,EACnCH,EAAQlP,KAAO+O,EAGXC,EACHA,EAAOX,WAAWqB,aAAaR,EAASF,EAAOW,aAE/C9Q,SAAS6P,KAAKC,YAAYO,GAEpBA,CACR,EACIU,EAAiB,SAAS5P,EAAM+O,GAEnC,IADA,IAAIc,EAAmBhR,SAAS0O,qBAAqB,QAC7CxH,EAAI,EAAGA,EAAI8J,EAAiBlP,OAAQoF,IAAK,CAChD,IAAI+J,EAAMD,EAAiB9J,GACvBgK,EAAWD,EAAIrC,aAAa,cAAgBqC,EAAIrC,aAAa,QACjE,GAAe,eAAZqC,EAAIX,MAAyBY,IAAa/P,GAAQ+P,IAAahB,GAAW,OAAOe,CACrF,CACA,IAAIE,EAAoBnR,SAAS0O,qBAAqB,SACtD,IAAQxH,EAAI,EAAGA,EAAIiK,EAAkBrP,OAAQoF,IAAK,CAC7C+J,EAAME,EAAkBjK,GACxBgK,EAAWD,EAAIrC,aAAa,aAChC,GAAGsC,IAAa/P,GAAQ+P,IAAahB,EAAU,OAAOe,CACvD,CACD,EACIG,EAAiB,SAAS7D,GAC7B,OAAO,IAAIzF,SAAQ,SAAS4D,EAAS0E,GACpC,IAAIjP,EAAOmK,EAAoBqC,SAASJ,GACpC2C,EAAW5E,EAAoBb,EAAItJ,EACvC,GAAG4P,EAAe5P,EAAM+O,GAAW,OAAOxE,IAC1CuE,EAAiB1C,EAAS2C,EAAU,KAAMxE,EAAS0E,EACpD,GACD,EAEIiB,EAAqB,CACxB,IAAK,GAGN/F,EAAoBgC,EAAEgE,QAAU,SAAS/D,EAASE,GACjD,IAAI8D,EAAY,CAAC,IAAM,GACpBF,EAAmB9D,GAAUE,EAAStG,KAAKkK,EAAmB9D,IACzB,IAAhC8D,EAAmB9D,IAAkBgE,EAAUhE,IACtDE,EAAStG,KAAKkK,EAAmB9D,GAAW6D,EAAe7D,GAASiE,MAAK,WACxEH,EAAmB9D,GAAW,CAC/B,IAAG,SAAS9H,GAEX,aADO4L,EAAmB9D,GACpB9H,CACP,IAEF,CA3E2C,C,eCK3C,IAAIgM,EAAkB,CACrB,IAAK,GAGNnG,EAAoBgC,EAAEZ,EAAI,SAASa,EAASE,GAE1C,IAAIiE,EAAqBpG,EAAoBC,EAAEkG,EAAiBlE,GAAWkE,EAAgBlE,QAAW/H,EACtG,GAA0B,IAAvBkM,EAGF,GAAGA,EACFjE,EAAStG,KAAKuK,EAAmB,QAC3B,CAGL,IAAIC,EAAU,IAAI7J,SAAQ,SAAS4D,EAAS0E,GAAUsB,EAAqBD,EAAgBlE,GAAW,CAAC7B,EAAS0E,EAAS,IACzH3C,EAAStG,KAAKuK,EAAmB,GAAKC,GAGtC,IAAItD,EAAM/C,EAAoBb,EAAIa,EAAoBoC,EAAEH,GAEpDqE,EAAQ,IAAIpG,MACZqG,EAAe,SAASzC,GAC3B,GAAG9D,EAAoBC,EAAEkG,EAAiBlE,KACzCmE,EAAqBD,EAAgBlE,GACX,IAAvBmE,IAA0BD,EAAgBlE,QAAW/H,GACrDkM,GAAoB,CACtB,IAAIjB,EAAYrB,IAAyB,SAAfA,EAAMjK,KAAkB,UAAYiK,EAAMjK,MAChE2M,EAAU1C,GAASA,EAAM1J,QAAU0J,EAAM1J,OAAOjC,IACpDmO,EAAMG,QAAU,iBAAmBxE,EAAU,cAAgBkD,EAAY,KAAOqB,EAAU,IAC1FF,EAAM1S,KAAO,iBACb0S,EAAMzM,KAAOsL,EACbmB,EAAMhB,QAAUkB,EAChBJ,EAAmB,GAAGE,EACvB,CAEF,EACAtG,EAAoB8C,EAAEC,EAAKwD,EAAc,SAAWtE,EAASA,EAE/D,CAEH,EAUAjC,EAAoBY,EAAEQ,EAAI,SAASa,GAAW,OAAoC,IAA7BkE,EAAgBlE,EAAgB,EAGrF,IAAIyE,EAAuB,SAASC,EAA4B9S,GAC/D,IAKIyM,EAAU2B,EALVnB,EAAWjN,EAAK,GAChB+S,EAAc/S,EAAK,GACnBgT,EAAUhT,EAAK,GAGI+H,EAAI,EAC3B,GAAGkF,EAASgG,MAAK,SAAShQ,GAAM,OAA+B,IAAxBqP,EAAgBrP,EAAW,IAAI,CACrE,IAAIwJ,KAAYsG,EACZ5G,EAAoBC,EAAE2G,EAAatG,KACrCN,EAAoBU,EAAEJ,GAAYsG,EAAYtG,IAGhD,GAAGuG,EAAS,IAAIhG,EAASgG,EAAQ7G,EAClC,CAEA,IADG2G,GAA4BA,EAA2B9S,GACrD+H,EAAIkF,EAAStK,OAAQoF,IACzBqG,EAAUnB,EAASlF,GAChBoE,EAAoBC,EAAEkG,EAAiBlE,IAAYkE,EAAgBlE,IACrEkE,EAAgBlE,GAAS,KAE1BkE,EAAgBlE,GAAW,EAE5B,OAAOjC,EAAoBY,EAAEC,EAC9B,EAEIkG,EAAqBC,KAAK,4BAA8BA,KAAK,6BAA+B,GAChGD,EAAmB3C,QAAQsC,EAAqBpC,KAAK,KAAM,IAC3DyC,EAAmBlL,KAAO6K,EAAqBpC,KAAK,KAAMyC,EAAmBlL,KAAKyI,KAAKyC,G,ICpFvF,IAAIE,EAAsBjH,EAAoBY,OAAE1G,EAAW,CAAC,IAAI,IAAI,IAAI,MAAM,WAAa,OAAO8F,EAAoB,KAAO,IAC7HiH,EAAsBjH,EAAoBY,EAAEqG,E","sources":["webpack://xingyunchaju/./src/posts/post2.md","webpack://xingyunchaju/./src/posts/post3.md","webpack://xingyunchaju/./src/posts/post4.md","webpack://xingyunchaju/./src/posts/post5.md","webpack://xingyunchaju/./src/posts/post6.md","webpack://xingyunchaju/./src/posts/post7.md","webpack://xingyunchaju/./src/posts/post8.md","webpack://xingyunchaju/./src/posts/post9.md","webpack://xingyunchaju/./src/posts/welcome.md","webpack://xingyunchaju/./src/App.vue","webpack://xingyunchaju/./src/components/BlogHeader.vue","webpack://xingyunchaju/./src/components/BlogHeader.vue?c7b7","webpack://xingyunchaju/./src/components/BlogFooter.vue","webpack://xingyunchaju/./src/components/BlogFooter.vue?a69b","webpack://xingyunchaju/./src/App.vue?7ccd","webpack://xingyunchaju/./src/views/Home.vue","webpack://xingyunchaju/./src/components/BlogPost.vue","webpack://xingyunchaju/./src/components/BlogPost.vue?fb96","webpack://xingyunchaju/./src/views/Home.vue?9051","webpack://xingyunchaju/./src/router/index.js","webpack://xingyunchaju/./src/store/index.js","webpack://xingyunchaju/./src/main.js","webpack://xingyunchaju/./src/posts/images/ sync ^\\.\\/.*$","webpack://xingyunchaju/./src/posts/ sync \\.md$","webpack://xingyunchaju/webpack/bootstrap","webpack://xingyunchaju/webpack/runtime/chunk loaded","webpack://xingyunchaju/webpack/runtime/compat get default export","webpack://xingyunchaju/webpack/runtime/define property getters","webpack://xingyunchaju/webpack/runtime/ensure chunk","webpack://xingyunchaju/webpack/runtime/get javascript chunk filename","webpack://xingyunchaju/webpack/runtime/get mini-css chunk filename","webpack://xingyunchaju/webpack/runtime/global","webpack://xingyunchaju/webpack/runtime/hasOwnProperty shorthand","webpack://xingyunchaju/webpack/runtime/load script","webpack://xingyunchaju/webpack/runtime/make namespace object","webpack://xingyunchaju/webpack/runtime/publicPath","webpack://xingyunchaju/webpack/runtime/css loading","webpack://xingyunchaju/webpack/runtime/jsonp chunk loading","webpack://xingyunchaju/webpack/startup"],"sourcesContent":["\nmodule.exports = { \n      attributes: {\"title\":\"亚马逊评论文本简要的分析\",\"date\":\"2024-11-17T00:00:00.000Z\",\"summary\":\"这是数据分析部分的代码的描述和一些注释\",\"coverImage\":\"11-19-4.jpg\",\"pinned\":false},\n    \n      html: \"<p>我做的数据分析主要分为两个部分，其实这个第一个部分是后面补充的。</p>\\n<h1>自己简单爬取数据然后自己分析</h1>\\n<p>这是油猴脚本写的js脚本，直接丢进油猴里边就完事，代码编写耗时可能20分钟以内</p>\\n<pre><code class=\\\"language-javascript\\\">// ==UserScript==\\n// @name         amazon-scraper1\\n// @namespace    http://tampermonkey.net/\\n// @version      2024-11-06\\n// @description  try to take over the world!\\n// @author       suxing\\n// @match        https://www.amazon.com/*\\n// @icon         https://www.google.com/s2/favicons?sz=64&amp;domain=amazon.com\\n// @grant        none\\n// ==/UserScript==\\n\\n\\n\\nfunction main(){\\n    new Promise((resolve)=&gt;{\\n        console.log(&quot;amazonbutton&quot;);\\n        setTimeout(()=&gt;{\\n            resolve();\\n        },2000)\\n    }).then(()=&gt;{\\n        let pageMain = document.querySelector(&quot;.sg-col-inner&quot;);\\n        console.log(pageMain)\\n        if(pageMain){\\n            let button = document.createElement(&quot;button&quot;);\\n            button.className=&quot;button-test&quot;\\n            button.innerHTML = &quot;点击爬取json&quot;;\\n            button.style.padding = &quot;10px 20px&quot;;\\n            button.style.fontSize = &quot;16px&quot;;\\n            button.style.backgroundColor = &quot;#4CAF50&quot;;\\n            button.style.color = &quot;white&quot;;\\n            button.style.border = &quot;none&quot;;\\n            button.style.borderRadius = &quot;5px&quot;;\\n            button.style.cursor = &quot;pointer&quot;;\\n            button.style.boxShadow = &quot;0px 4px 6px rgba(0, 0, 0, 0.1)&quot;;\\n            button.style.transition = &quot;background-color 0.3s&quot;;\\n            button.onmouseover = function() {\\n                button.style.backgroundColor = &quot;#45a049&quot;;\\n            };\\n            button.onmouseout = function() {\\n                button.style.backgroundColor = &quot;#4CAF50&quot;;\\n            };\\n            button.onclick=()=&gt;{scrapefunc();}\\n            var buttonContainer = document.createElement(&quot;div&quot;);\\n            buttonContainer.style.display = &quot;flex&quot;;\\n            buttonContainer.style.justifyContent = &quot;center&quot;;\\n            buttonContainer.style.alignItems = &quot;center&quot;;\\n            buttonContainer.style.height = &quot;100px&quot;; // 调整高度以便更好地居中\\n            buttonContainer.appendChild(button);\\n\\n            // 在 pageMain 元素的上方插入按钮\\n            pageMain.parentNode.insertBefore(buttonContainer, pageMain);\\n        }\\n    })\\n}\\n\\nfunction exportjson(data){\\n    const blob = new Blob([data], { type: 'application/json' });\\n    const url = URL.createObjectURL(blob);\\n    const a = document.createElement('a');\\n    a.href = url;\\n    const today = new Date();\\n    const year = today.getFullYear();\\n    const month = String(today.getMonth() + 1).padStart(2, '0');\\n    const day = String(today.getDate()).padStart(2, '0');\\n    const formattedDate = `${year}-${month}-${day}`;\\n    a.download = `amazon-Products${formattedDate}.json`;\\n    document.body.appendChild(a);\\n    a.click();\\n    document.body.removeChild(a);\\n    URL.revokeObjectURL(url);\\n}\\nfunction scrapefunc(){\\n    new Promise((resolve)=&gt;{\\n        console.log(&quot;amazon-scraper test1&quot;);\\n        setTimeout(()=&gt;{\\n            resolve();\\n        },700)\\n    }).then(()=&gt;{\\n        new Promise((resolve)=&gt;{\\n            window.scrollTo({\\n                top: 1000,\\n                behavior: &quot;smooth&quot;\\n            });\\n            setTimeout(()=&gt;{\\n                resolve();\\n            },1000)\\n        }).then(()=&gt;{\\n            new Promise((resolve)=&gt;{\\n                window.scrollTo({\\n                    top: 4000,\\n                    behavior: &quot;smooth&quot;\\n                });\\n                setTimeout(()=&gt;{\\n                    resolve();\\n                },1000)\\n            }).then(()=&gt;{\\n                new Promise((resolve)=&gt;{\\n                    window.scrollTo({\\n                        top: 8000,\\n                        behavior: &quot;smooth&quot;\\n                    });\\n                    setTimeout(()=&gt;{\\n                        resolve();\\n                    },1000)\\n                }).then(()=&gt;{\\n                    new Promise((resolve)=&gt;{\\n                        window.scrollTo({\\n                            top: document.body.scrollHeight,\\n                            behavior: &quot;smooth&quot;\\n                        });\\n                        setTimeout(()=&gt;{\\n                            resolve();\\n                        },700)\\n                    }).then(()=&gt;{\\n                        let productlist = [];\\n                        document.querySelectorAll('div.a-section.a-spacing-small.puis-padding-left-small.puis-padding-right-small').forEach(container =&gt; {\\n                            let product = {};\\n\\n                            // 标题和URL: 从商品标题容器获取\\n                            try {\\n                                const titleContainer = container.querySelector('[data-cy=&quot;title-recipe&quot;]');\\n                                product.title = titleContainer.querySelector('.a-size-base-plus.a-color-base').textContent.trim();\\n                                product.url = titleContainer.querySelector('a.a-link-normal').getAttribute('href');\\n                            } catch (e) {\\n                                product.title = '';\\n                                product.url = '';\\n                            }\\n\\n                            // 价格: 从价格容器获取\\n                            try {\\n                                const priceContainer = container.querySelector('[data-cy=&quot;price-recipe&quot;]');\\n                                const priceElement = priceContainer.querySelector('.a-price .a-offscreen');\\n                                product.price = priceElement ? priceElement.textContent.trim() : '';\\n                            } catch (e) {\\n                                product.price = '';\\n                            }\\n\\n                            // 评分和评分数: 从评论容器获取\\n                            try {\\n                                const reviewsContainer = container.querySelector('[data-cy=&quot;reviews-block&quot;]');\\n                                const ratingElement = reviewsContainer.querySelector('.a-icon-alt');\\n                                product.rating = ratingElement ? ratingElement.textContent.trim() : '';\\n\\n                                const reviewsElement = reviewsContainer.querySelector('.rush-component .s-underline-text');\\n                                product.ratingnum = reviewsElement ? reviewsElement.textContent.trim() : '';\\n                            } catch (e) {\\n                                product.rating = '';\\n                                product.ratingnum = '';\\n                            }\\n\\n                            if (product.title) {  // 只添加有标题的商品\\n                                productlist.push(product);\\n                            }\\n                        });\\n                        const productListJson = JSON.stringify(productlist, null, 2);\\n                        console.log(productListJson);\\n                        exportjson(productListJson);\\n                        const nexturl=document.querySelector(&quot;.s-pagination-next&quot;).getAttribute(&quot;href&quot;)\\n                        window.scrollTo({\\n                            top: 0,\\n                            behavior: &quot;smooth&quot;\\n                        });\\n                        new Promise((resolve)=&gt;{\\n                            setTimeout(()=&gt;{\\n                                resolve();\\n                            },500)\\n                        }).then(()=&gt;{\\n                            location.href=nexturl\\n                        })\\n\\n                    })\\n                })\\n            })\\n        })\\n    })\\n}\\n\\n\\n\\n\\n\\nwindow.addEventListener(&quot;load&quot;,()=&gt;{\\n    main();\\n\\n},false)\\n</code></pre>\\n<h2>python分析代码</h2>\\n<pre><code class=\\\"language-python\\\"></code></pre>\\n<h1>深度学习模型构建部分</h1>\\n<h2>简要数据分析</h2>\\n<pre><code class=\\\"language-python\\\"># 导入所需库\\nfrom datasets import load_dataset\\nfrom wordcloud import WordCloud\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns\\nfrom sklearn.model_selection import train_test_split\\nimport torch\\nfrom torch import nn\\nfrom torch.utils.data import DataLoader, Dataset\\nfrom transformers import BertTokenizer\\n\\n# 加载数据集，并取前2000条数据\\ndataset = load_dataset(&quot;McAuley-Lab/Amazon-Reviews-2023&quot;, &quot;raw_review_All_Beauty&quot;, trust_remote_code=True)\\ndata = pd.DataFrame(dataset[&quot;full&quot;][:10000])  # 仅取2000条数据\\nprint(data.head())\\n\\n# 1. 词云生成\\nall_text = &quot; &quot;.join(data[&quot;text&quot;].fillna(&quot;&quot;))\\nwordcloud = WordCloud(width=800, height=400, background_color=&quot;white&quot;).generate(all_text)\\n\\nplt.figure(figsize=(10, 5))\\nplt.imshow(wordcloud, interpolation=&quot;bilinear&quot;)\\nplt.axis(&quot;off&quot;)\\nplt.title(&quot;Word Cloud of Amazon Reviews&quot;)\\nplt.show()\\n\\n# 2. 用户画像分析\\n# 评分分布\\nplt.figure(figsize=(8, 5))\\nsns.histplot(data[&quot;rating&quot;], bins=5, kde=True)\\nplt.xlabel(&quot;Rating&quot;)\\nplt.title(&quot;Distribution of Ratings&quot;)\\nplt.show()\\n\\n# 验证购买分析\\nverified_purchase_counts = data[&quot;verified_purchase&quot;].value_counts()\\nplt.figure(figsize=(8, 5))\\nsns.barplot(x=verified_purchase_counts.index, y=verified_purchase_counts.values)\\nplt.xlabel(&quot;Verified Purchase&quot;)\\nplt.ylabel(&quot;Count&quot;)\\nplt.title(&quot;Distribution of Verified Purchases&quot;)\\nplt.show()\\n\\n# 3. 时间序列分析：评论随时间的变化\\ndata[&quot;timestamp&quot;] = pd.to_datetime(data[&quot;timestamp&quot;], unit=&quot;ms&quot;)  # 转换时间戳为日期格式\\ndata.set_index(&quot;timestamp&quot;, inplace=True)\\ndata[&quot;rating&quot;].resample(&quot;M&quot;).mean().plot(figsize=(12, 6))\\nplt.title(&quot;Average Rating Over Time (Monthly)&quot;)\\nplt.xlabel(&quot;Time&quot;)\\nplt.xlim(pd.Timestamp(&quot;2012-01-01&quot;), pd.Timestamp(&quot;2023-12-31&quot;))\\nplt.ylabel(&quot;Average Rating&quot;)\\nplt.show()\\n\\n# 4. 评论字数分析\\ndata[&quot;review_length&quot;] = data[&quot;text&quot;].apply(lambda x: len(str(x).split()))  # 计算每条评论的词数\\ndata[&quot;review_length&quot;].resample(&quot;M&quot;).mean().plot(figsize=(12, 6))\\nplt.title(&quot;Average Review Length Over Time (Monthly)&quot;)\\nplt.xlabel(&quot;Time&quot;)\\nplt.xlim(pd.Timestamp(&quot;2012-01-01&quot;), pd.Timestamp(&quot;2023-12-31&quot;))\\nplt.ylabel(&quot;Average Review Length&quot;)\\nplt.show()\\n\\n\\n\\n\\n\\n</code></pre>\\n\",\n     }","\nmodule.exports = { \n      attributes: {\"title\":\"YOLO计算机视觉&目标检测模型\",\"date\":\"2024-11-01T00:00:00.000Z\",\"summary\":\"在尝试的学习CV技术\",\"coverImage\":\"3.png\",\"pinned\":false},\n    \n      html: \"<h1>开始学点DL技术！</h1>\\n<h2>上点干货的算法</h2>\\n<p>你以为的YOLO ：<strong>you only look once</strong></p>\\n<p>我以为的YOLO： <strong>YOU ONLY LIVE ONCE</strong></p>\\n<p><strong>珍爱生命，远离深度学习啊！！</strong></p>\\n<h2>研究一下YOLO的模型结构</h2>\\n<p>以YOLOv3为例</p>\\n<ol>\\n<li>\\n<p>输入:  模型的输入是一张图片。</p>\\n</li>\\n<li>\\n<p>骨干网络 (Backbone Network):  用于提取图像特征。YOLOv3 使用 Darknet-53 作为骨干网络，它是一个 53 层的卷积神经网络，具有残差连接，可以有效地提取图像特征。</p>\\n</li>\\n<li>\\n<p>特征金字塔网络 (Feature Pyramid Network, FPN):  用于在不同尺度上检测目标。FPN 将骨干网络提取的不同层级的特征图进行融合，生成多个尺度的特征图，从而可以检测不同大小的目标。</p>\\n</li>\\n<li>\\n<p>检测头 (Detection Head):  用于预测目标的类别和位置。YOLOv3 的检测头包含三个分支，分别对应三个不同的尺度。每个分支都包含一系列卷积层，最终输出一个三维张量，其中包含每个网格单元的预测信息。</p>\\n</li>\\n</ol>\\n<p>将输入图像分成 S x S 个网格单元。\\n每个网格单元负责预测 B 个边界框和 C 个类别概率。\\n每个边界框包含 5 个预测值：x，y，w，h 和置信度。\\n(x, y) 是边界框中心相对于网格单元的坐标。\\n(w, h) 是边界框的宽度和高度相对于整张图片的比例。\\n置信度表示边界框包含目标的概率以及边界框的准确度。\\n每个网格单元还会预测 C 个类别概率，表示该网格单元包含某个类别的目标的概率。</p>\\n\",\n     }","\nmodule.exports = { \n      attributes: {\"title\":\"用亚马逊评论数据，玩一下生成式模型\",\"date\":\"2024-11-01T00:00:00.000Z\",\"summary\":\"学习一下生成式模型\",\"coverImage\":\"11-19-2.jpg\",\"pinned\":false},\n    \n      html: \"<h1>T5预训练模型上做微调</h1>\\n<pre><code class=\\\"language-python\\\"># 导入所需库\\nfrom datasets import load_dataset\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nimport torch\\nimport torch.nn as nn\\nfrom transformers import (\\n    T5ForConditionalGeneration, T5Tokenizer,\\n    get_linear_schedule_with_warmup\\n)\\nimport gc\\nfrom torch.utils.data import DataLoader, Dataset\\nimport matplotlib.pyplot as plt\\nfrom tqdm import tqdm\\nimport pandas as pd\\nimport copy\\nimport os\\nimport random\\nfrom torch.nn.utils.rnn import pad_sequence\\nimport nltk\\nfrom nltk.tokenize import word_tokenize\\nfrom collections import Counter\\nimport re\\n\\n# 下载必要的NLTK数据\\nnltk.download('punkt')\\nnltk.download('wordnet')\\nfrom nltk.corpus import wordnet\\n\\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n\\ndef set_seed(seed=42):\\n    random.seed(seed)\\n    np.random.seed(seed)\\n    torch.manual_seed(seed)\\n    if torch.cuda.is_available():\\n        torch.cuda.manual_seed_all(seed)\\n\\nset_seed()\\n# 数据增强方法\\nclass TextAugmenter:\\n    @staticmethod\\n    def synonym_replacement(text, n=1):\\n        words = word_tokenize(text)\\n        new_words = words.copy()\\n        random_word_list = list(set([word for word in words if word.isalnum()]))\\n        n = min(n, len(random_word_list))\\n        \\n        for _ in range(n):\\n            random_word = random.choice(random_word_list)\\n            synonyms = []\\n            for syn in wordnet.synsets(random_word):\\n                for lemma in syn.lemmas():\\n                    synonyms.append(lemma.name())\\n            if len(synonyms) &gt; 0:\\n                synonym = random.choice(list(set(synonyms)))\\n                random_idx = random.randint(0, len(words) - 1)\\n                new_words[random_idx] = synonym\\n        \\n        return ' '.join(new_words)\\n\\n    @staticmethod\\n    def random_deletion(text, p=0.1):\\n        words = word_tokenize(text)\\n        if len(words) == 1:\\n            return text\\n        \\n        new_words = []\\n        for word in words:\\n            if random.random() &gt; p:\\n                new_words.append(word)\\n        \\n        if len(new_words) == 0:\\n            rand_int = random.randint(0, len(words)-1)\\n            new_words.append(words[rand_int])\\n            \\n        return ' '.join(new_words)\\n\\n    @staticmethod\\n    def random_swap(text, n=1):\\n        words = word_tokenize(text)\\n        new_words = words.copy()\\n        for _ in range(n):\\n            if len(new_words) &gt;= 2:\\n                idx1, idx2 = random.sample(range(len(new_words)), 2)\\n                new_words[idx1], new_words[idx2] = new_words[idx2], new_words[idx1]\\n        return ' '.join(new_words)\\n\\nclass ReviewGenerationDataset(Dataset):\\n    def __init__(self, texts, ratings, tokenizer, max_len=128, augment=False):\\n        # 将Series转换为list以避免索引问题\\n        self.texts = texts.tolist()\\n        self.ratings = ratings.tolist()\\n        self.tokenizer = tokenizer\\n        self.max_len = max_len\\n        self.augment = augment\\n        self.augmenter = TextAugmenter()\\n\\n    def __len__(self):\\n        return len(self.texts)\\n\\n    def augment_text(self, text):\\n        augmentation_ops = [\\n            (self.augmenter.synonym_replacement, {'n': 1}),\\n            (self.augmenter.random_deletion, {'p': 0.1}),\\n            (self.augmenter.random_swap, {'n': 1})\\n        ]\\n        op, params = random.choice(augmentation_ops)\\n        return op(text, **params)\\n\\n    def __getitem__(self, idx):\\n        text = str(self.texts[idx])\\n        rating = self.ratings[idx]\\n        \\n        if self.augment and random.random() &lt; 0.3:\\n            text = self.augment_text(text)\\n        \\n        prompt = f&quot;Generate a {rating}-star review:&quot;\\n        \\n        prompt_encoding = self.tokenizer(\\n            prompt,\\n            max_length=32,\\n            padding='max_length',\\n            truncation=True,\\n            return_tensors='pt'\\n        )\\n        \\n        target_encoding = self.tokenizer(\\n            text,\\n            max_length=self.max_len,\\n            padding='max_length',\\n            truncation=True,\\n            return_tensors='pt'\\n        )\\n\\n        return {\\n            'input_ids': prompt_encoding['input_ids'].squeeze(),\\n            'attention_mask': prompt_encoding['attention_mask'].squeeze(),\\n            'labels': target_encoding['input_ids'].squeeze(),\\n            'decoder_attention_mask': target_encoding['attention_mask'].squeeze()\\n        }\\n\\n\\nclass ReviewGenerator(nn.Module):\\n    def __init__(self, model_name=&quot;t5-base&quot;):\\n        super().__init__()\\n        self.model = T5ForConditionalGeneration.from_pretrained(model_name)\\n        # 启用梯度检查点以减少内存使用\\n        self.model.gradient_checkpointing_enable()\\n        \\n    def forward(self, input_ids, attention_mask, labels=None, decoder_attention_mask=None):\\n        outputs = self.model(\\n            input_ids=input_ids,\\n            attention_mask=attention_mask,\\n            labels=labels,\\n            decoder_attention_mask=decoder_attention_mask\\n        )\\n        return outputs\\n\\n\\ndef prepare_data(batch_size=8):  # 减小batch size以降低内存使用\\n    # 加载数据集\\n    dataset = load_dataset(&quot;McAuley-Lab/Amazon-Reviews-2023&quot;, &quot;raw_review_All_Beauty&quot;, trust_remote_code=True)\\n    data = pd.DataFrame(dataset[&quot;full&quot;][:200000])\\n    \\n    # 数据清洗\\n    data['text'] = data['text'].fillna(&quot;&quot;).astype(str)\\n    data = data[data['text'].str.len() &gt; 10]\\n    data = data.reset_index(drop=True)\\n    \\n    # 划分训练集和验证集\\n    train_texts, val_texts, train_ratings, val_ratings = train_test_split(\\n        data['text'], data['rating'],\\n        test_size=0.1,\\n        random_state=42\\n    )\\n    \\n    tokenizer = T5Tokenizer.from_pretrained('t5-base', model_max_length=512)  # 减小max_length\\n    \\n    train_dataset = ReviewGenerationDataset(train_texts, train_ratings, tokenizer, augment=True)\\n    val_dataset = ReviewGenerationDataset(val_texts, val_ratings, tokenizer, augment=False)\\n    \\n    train_loader = DataLoader(\\n        train_dataset, \\n        batch_size=batch_size, \\n        shuffle=True,\\n        drop_last=True,\\n        pin_memory=True  # 启用pin_memory加速数据传输\\n    )\\n    val_loader = DataLoader(\\n        val_dataset, \\n        batch_size=batch_size,\\n        drop_last=True,\\n        pin_memory=True\\n    )\\n    \\n    return train_loader, val_loader, tokenizer\\n\\n\\ndef train_generator(model, train_loader, val_loader, epochs=5, save_dir=&quot;generator_checkpoints&quot;, \\n                   gradient_accumulation_steps=4):\\n    # 创建输出目录\\n    os.makedirs(save_dir, exist_ok=True)\\n    os.makedirs(&quot;generative-output&quot;, exist_ok=True)\\n    \\n    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\\n    num_training_steps = (len(train_loader) // gradient_accumulation_steps) * epochs\\n    num_warmup_steps = num_training_steps // 10\\n    scheduler = get_linear_schedule_with_warmup(\\n        optimizer,\\n        num_warmup_steps=num_warmup_steps,\\n        num_training_steps=num_training_steps\\n    )\\n    \\n    best_val_loss = float('inf')\\n    train_losses = []\\n    val_losses = []\\n    \\n    for epoch in range(epochs):\\n        model.train()\\n        total_train_loss = 0\\n        optimizer.zero_grad()\\n        \\n        with tqdm(total=len(train_loader), desc=f&quot;Epoch {epoch+1}/{epochs}&quot;) as pbar:\\n            for batch_idx, batch in enumerate(train_loader):\\n                # 将数据移动到GPU\\n                input_ids = batch['input_ids'].to(device)\\n                attention_mask = batch['attention_mask'].to(device)\\n                labels = batch['labels'].to(device)\\n                decoder_attention_mask = batch['decoder_attention_mask'].to(device)\\n                \\n                outputs = model(\\n                    input_ids=input_ids,\\n                    attention_mask=attention_mask,\\n                    labels=labels,\\n                    decoder_attention_mask=decoder_attention_mask\\n                )\\n                \\n                loss = outputs.loss / gradient_accumulation_steps\\n                total_train_loss += loss.item() * gradient_accumulation_steps\\n                \\n                loss.backward()\\n                \\n                if (batch_idx + 1) % gradient_accumulation_steps == 0:\\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\\n                    optimizer.step()\\n                    scheduler.step()\\n                    optimizer.zero_grad()\\n                    \\n                    # 清理缓存\\n                    if torch.cuda.is_available():\\n                        torch.cuda.empty_cache()\\n                \\n                pbar.update(1)\\n                pbar.set_postfix({\\n                    'train_loss': f'{loss.item() * gradient_accumulation_steps:.4f}'\\n                })\\n        \\n        # 处理最后一个不完整的累积步\\n        if len(train_loader) % gradient_accumulation_steps != 0:\\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\\n            optimizer.step()\\n            scheduler.step()\\n            optimizer.zero_grad()\\n        \\n        # 评估阶段\\n        model.eval()\\n        total_val_loss = 0\\n        \\n        with torch.no_grad():\\n            for batch in val_loader:\\n                input_ids = batch['input_ids'].to(device)\\n                attention_mask = batch['attention_mask'].to(device)\\n                labels = batch['labels'].to(device)\\n                decoder_attention_mask = batch['decoder_attention_mask'].to(device)\\n                \\n                outputs = model(\\n                    input_ids=input_ids,\\n                    attention_mask=attention_mask,\\n                    labels=labels,\\n                    decoder_attention_mask=decoder_attention_mask\\n                )\\n                \\n                total_val_loss += outputs.loss.item()\\n        \\n        avg_train_loss = total_train_loss / len(train_loader)\\n        avg_val_loss = total_val_loss / len(val_loader)\\n        \\n        train_losses.append(avg_train_loss)\\n        val_losses.append(avg_val_loss)\\n        \\n        print(f&quot;\\\\nEpoch {epoch+1}&quot;)\\n        print(f&quot;Average training loss: {avg_train_loss:.4f}&quot;)\\n        print(f&quot;Average validation loss: {avg_val_loss:.4f}&quot;)\\n        \\n        if avg_val_loss &lt; best_val_loss:\\n            best_val_loss = avg_val_loss\\n            torch.save(model.state_dict(), f&quot;{save_dir}/best_model.pth&quot;)\\n            print(&quot;Saved new best model!&quot;)\\n        \\n        # 绘制并保存loss曲线\\n        plt.figure(figsize=(10, 6))\\n        plt.plot(range(1, epoch + 2), train_losses, label='Training Loss')\\n        plt.plot(range(1, epoch + 2), val_losses, label='Validation Loss')\\n        plt.xlabel('Epoch')\\n        plt.ylabel('Loss')\\n        plt.title('Training and Validation Loss')\\n        plt.legend()\\n        plt.grid(True)\\n        plt.savefig('generative-output/loss_curve.png')\\n        plt.close()\\n        \\n        # 强制进行垃圾回收\\n        gc.collect()\\n        if torch.cuda.is_available():\\n            torch.cuda.empty_cache()\\n\\n\\ndef generate_review(model, tokenizer, rating, max_length=150):\\n    model.eval()\\n    prompt = f&quot;Generate a {rating}-star review:&quot;\\n    \\n    inputs = tokenizer(\\n        prompt,\\n        return_tensors=&quot;pt&quot;,\\n        max_length=32,\\n        padding=True,\\n        truncation=True\\n    ).to(device)\\n    \\n    with torch.no_grad():\\n        outputs = model.model.generate(\\n            input_ids=inputs[&quot;input_ids&quot;],\\n            attention_mask=inputs[&quot;attention_mask&quot;],\\n            max_length=max_length,\\n            num_beams=5,\\n            no_repeat_ngram_size=2,\\n            top_k=50,\\n            top_p=0.95,\\n            temperature=0.7,\\n            do_sample=True\\n        )\\n    \\n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\\n    return generated_text\\n\\n\\ndef main():\\n    # 清理GPU内存\\n    if torch.cuda.is_available():\\n        torch.cuda.empty_cache()\\n        \\n    train_loader, val_loader, tokenizer = prepare_data()\\n    model = ReviewGenerator().to(device)\\n    train_generator(model, train_loader, val_loader)\\n    \\n    # 生成示例评论\\n    model.load_state_dict(torch.load(&quot;generator_checkpoints/best_model.pth&quot;))\\n    \\n    for rating in [1, 3, 5]:\\n        print(f&quot;\\\\nGenerated {rating}-star review:&quot;)\\n        review = generate_review(model, tokenizer, rating)\\n        print(review)\\n\\nif __name__ == &quot;__main__&quot;:\\n    main()\\n</code></pre>\\n\",\n     }","\nmodule.exports = { \n      attributes: {\"title\":\"亚马逊评论数据做文本情感分类模型\",\"date\":\"2024-11-18T00:00:00.000Z\",\"summary\":\"在尝试的学习NLP技术\",\"coverImage\":\"11-19-3.jpg\",\"pinned\":true},\n    \n      html: \"<p>模型大致分为</p>\\n<p>LSTM模型</p>\\n<p>LSTM带注意力机制</p>\\n<p>微调BERT预训练模型，写在另外一篇文章了</p>\\n<p>微调T5生成式模型（补充），这个也写在另外一篇文章了</p>\\n<h1>LSTM模型</h1>\\n<h2>模型1</h2>\\n<p>模型结构可以概括为以下几个步骤：</p>\\n<p>BERT词嵌入: 使用预训练的BERT模型对文本进行编码，将每个词转换为一个高维向量表示。BERT能够捕捉词语的上下文信息，从而生成更准确的词嵌入。</p>\\n<p>LSTM层: 将BERT词嵌入序列输入到LSTM层中。LSTM能够捕捉序列数据中的长期依赖关系，从而更好地理解评论的整体情感。</p>\\n<p>全连接层: LSTM层的输出经过一个全连接层，将高维的隐藏状态映射到一个数值。</p>\\n<p>Tanh激活函数: 全连接层的输出经过Tanh激活函数，将预测评分限制在-1到1之间。</p>\\n<pre><code class=\\\"language-python\\\"># 导入所需库\\nfrom datasets import load_dataset #datasets用于导入huggingface上的数据集\\nfrom wordcloud import WordCloud #这是一个词云库\\nimport matplotlib.pyplot as plt #画图库\\nimport pandas as pd\\nimport seaborn as sns\\nfrom sklearn.model_selection import train_test_split #用于划分数据集\\nimport torch \\nfrom torch import nn\\nfrom torch.utils.data import DataLoader, Dataset\\nfrom transformers import BertTokenizer 使用Bert 分词器\\n\\n\\n# 导入所需库\\nfrom datasets import load_dataset  # datasets用于导入huggingface上的数据集\\nfrom wordcloud import WordCloud  # 这是一个词云库\\nimport matplotlib.pyplot as plt  # 画图库\\nimport pandas as pd\\nimport seaborn as sns\\nfrom sklearn.model_selection import train_test_split  # 用于划分数据集\\nimport torch\\nfrom torch import nn\\nfrom torch.utils.data import DataLoader, Dataset\\nfrom transformers import BertTokenizer  # 使用Bert 分词器\\n\\n\\n# 加载数据集，并取前10000条数据\\ndataset = load_dataset(&quot;McAuley-Lab/Amazon-Reviews-2023&quot;, &quot;raw_review_All_Beauty&quot;, trust_remote_code=True)\\ndata = pd.DataFrame(dataset[&quot;full&quot;][:10000])  # 仅取10000条数据\\nprint(data.head())\\n\\n# 设置Matplotlib的字体参数\\nplt.rcParams['font.family'] = 'SimHei'  # 替换为你选择的字体\\nplt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\\n\\n# 初始化BertTokenizer\\ntokenizer = BertTokenizer.from_pretrained(&quot;bert-base-uncased&quot;)\\nmax_len = 128  # 设置最大序列长度\\n\\n\\n# 定义数据集类\\nclass ReviewDataset(Dataset):\\n    def __init__(self, texts, ratings):\\n        self.texts = texts\\n        self.ratings = ratings\\n\\n    def __len__(self):\\n        return len(self.texts)\\n\\n    def __getitem__(self, idx):\\n        # 使用BertTokenizer对文本进行编码\\n        encoded = tokenizer.encode_plus(\\n            self.texts[idx],\\n            add_special_tokens=True,  # 添加特殊标记\\n            max_length=max_len,  # 设置最大长度\\n            padding=&quot;max_length&quot;,  # 使用最大长度进行填充\\n            truncation=True,  # 超过最大长度进行截断\\n            return_tensors=&quot;pt&quot;,  # 返回pytorch张量\\n        )\\n        input_ids = encoded[&quot;input_ids&quot;].squeeze()  # 获取input_ids\\n        attention_mask = encoded[&quot;attention_mask&quot;].squeeze()  # 获取attention_mask\\n        rating = torch.tensor(self.ratings[idx], dtype=torch.float)  # 将评分转换为张量\\n        return input_ids, attention_mask, rating\\n\\n\\n# 划分训练集和验证集\\ntrain_texts, val_texts, train_ratings, val_ratings = train_test_split(\\n    data[&quot;text&quot;].fillna(&quot;&quot;), data[&quot;rating&quot;], test_size=0.2, random_state=42\\n)\\n# 创建训练集和验证集\\ntrain_dataset = ReviewDataset(train_texts.tolist(), train_ratings.tolist())\\nval_dataset = ReviewDataset(val_texts.tolist(), val_ratings.tolist())\\n# 创建DataLoader\\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\\nval_loader = DataLoader(val_dataset, batch_size=32)\\n\\n\\n# 定义LSTM模型\\nclass ReviewLSTM(nn.Module):\\n    def __init__(self, embedding_dim=64, hidden_dim=128, output_dim=1):\\n        super(ReviewLSTM, self).__init__()\\n        self.embedding = nn.Embedding(tokenizer.vocab_size, embedding_dim)  # 词嵌入层\\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)  # LSTM层\\n        self.fc = nn.Linear(hidden_dim, output_dim)  # 全连接层\\n        self.tanh = nn.Tanh()  # tanh激活函数\\n\\n    def forward(self, input_ids, attention_mask):\\n        embedded = self.embedding(input_ids)  # 获取词嵌入向量\\n        _, (hidden, _) = self.lstm(embedded)  # 通过LSTM层\\n        output = self.tanh(self.fc(hidden[-1]))  # 通过全连接层并使用tanh激活函数\\n        return output\\n\\n\\n# 初始化模型、损失函数和优化器\\nmodel = ReviewLSTM()\\ncriterion = nn.MSELoss()  # 使用均方误差作为损失函数\\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  # 使用Adam优化器\\n\\n\\n# 定义训练函数\\ndef train_model(model, train_loader, val_loader, criterion, optimizer, epochs=20, patience=3):\\n    train_losses, val_losses = [], []  # 用于存储训练和验证损失\\n    best_val_loss = float(&quot;inf&quot;)  # 初始化最佳验证损失\\n    patience_counter = 0  # 初始化早停计数器\\n\\n    for epoch in range(epochs):\\n        model.train()  # 设置模型为训练模式\\n        running_loss = 0\\n        for input_ids, attention_mask, ratings in train_loader:\\n            optimizer.zero_grad()  # 清空梯度\\n            outputs = model(input_ids, attention_mask).squeeze()  # 获取模型输出\\n            loss = criterion(outputs, ratings)  # 计算损失\\n            loss.backward()  # 反向传播\\n            optimizer.step()  # 更新模型参数\\n            running_loss += loss.item()  # 累加损失\\n\\n        train_loss = running_loss / len(train_loader)  # 计算平均训练损失\\n        train_losses.append(train_loss)  # 存储训练损失\\n\\n        # 验证模型\\n        model.eval()  # 设置模型为评估模式\\n        val_loss = 0\\n        with torch.no_grad():  # 不计算梯度\\n            for input_ids, attention_mask, ratings in val_loader:\\n                outputs = model(input_ids, attention_mask).squeeze()  # 获取模型输出\\n                loss = criterion(outputs, ratings)  # 计算损失\\n                val_loss += loss.item()  # 累加损失\\n\\n        val_loss /= len(val_loader)  # 计算平均验证损失\\n        val_losses.append(val_loss)  # 存储验证损失\\n\\n        print(f&quot;Epoch {epoch+1}/{epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}&quot;)\\n\\n        # 早停机制\\n        if val_loss &lt; best_val_loss:\\n            best_val_loss = val_loss\\n            patience_counter = 0\\n        else:\\n            patience_counter += 1\\n            if patience_counter &gt;= patience:\\n                print(&quot;早停法：验证损失未改善，提前停止训练。&quot;)\\n                break\\n\\n    # 绘制损失曲线\\n    plt.figure(figsize=(10, 5))\\n    plt.plot(train_losses, label=&quot;训练损失&quot;)\\n    plt.plot(val_losses, label=&quot;验证损失&quot;)\\n    plt.xlabel(&quot;轮次&quot;)\\n    plt.ylabel(&quot;损失&quot;)\\n    plt.legend()\\n    plt.show()\\n# 开始训练\\ntrain_model(model, train_loader, val_loader, criterion, optimizer)\\n</code></pre>\\n<h2>模型2</h2>\\n<pre><code class=\\\"language-python\\\">from sklearn.metrics.pairwise import cosine_similarity  # 用于计算余弦相似度\\nfrom transformers import BertModel, BertTokenizer  # 用于加载BERT模型和分词器\\nimport torch\\nfrom torch import nn\\nfrom torch.utils.data import DataLoader, Dataset  # 用于创建数据加载器和数据集\\nfrom sklearn.model_selection import train_test_split  # 用于划分数据集\\nimport matplotlib.pyplot as plt  # 用于绘图\\nimport pandas as pd  # 用于数据处理\\nimport seaborn as sns  # 用于绘制热力图\\nfrom datasets import load_dataset  # 用于加载Hugging Face数据集\\nfrom sklearn.metrics import accuracy_score  # 用于计算准确率\\n\\n# 设置Matplotlib的字体参数\\nplt.rcParams['font.family'] = 'SimHei'  # 替换为你选择的字体\\nplt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\\n\\n# 检查CUDA是否可用\\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\nprint(f&quot;Using device: {device}&quot;)\\n\\n# 加载数据集，并取前10000条数据\\ndataset = load_dataset(&quot;McAuley-Lab/Amazon-Reviews-2023&quot;, &quot;raw_review_All_Beauty&quot;, trust_remote_code=True)\\ndata = pd.DataFrame(dataset[&quot;full&quot;][:10000])  # 仅取10000条数据\\n\\n# 设置BERT的分词器\\ntokenizer = BertTokenizer.from_pretrained(&quot;bert-base-uncased&quot;)\\nmax_len = 128  # 设置最大序列长度\\n\\n# 定义数据集类\\nclass ReviewDataset(Dataset):\\n    def __init__(self, texts, ratings):\\n        self.texts = texts\\n        # 将评分转换为类别索引 (1-5星 -&gt; 0-4)\\n        self.ratings = [int(rating) - 1 for rating in ratings]  \\n\\n    def __len__(self):\\n        return len(self.texts)\\n\\n    def __getitem__(self, idx):\\n        # 使用BertTokenizer对文本进行编码\\n        encoded = tokenizer.encode_plus(\\n            self.texts[idx],\\n            add_special_tokens=True,  # 添加特殊标记\\n            max_length=max_len,  # 设置最大长度\\n            padding=&quot;max_length&quot;,  # 使用最大长度进行填充\\n            truncation=True,  # 超过最大长度进行截断\\n            return_tensors=&quot;pt&quot;,  # 返回pytorch张量\\n        )\\n        input_ids = encoded[&quot;input_ids&quot;].squeeze()  # 获取input_ids\\n        attention_mask = encoded[&quot;attention_mask&quot;].squeeze()  # 获取attention_mask\\n        # 使用long类型以适应分类任务\\n        rating = torch.tensor(self.ratings[idx], dtype=torch.long)  \\n        return input_ids, attention_mask, rating\\n\\n# 划分训练集和验证集\\ntrain_texts, val_texts, train_ratings, val_ratings = train_test_split(\\n    data[&quot;text&quot;].fillna(&quot;&quot;), data[&quot;rating&quot;], test_size=0.2, random_state=42\\n)\\n# 创建训练集和验证集\\ntrain_dataset = ReviewDataset(train_texts.tolist(), train_ratings.tolist())\\nval_dataset = ReviewDataset(val_texts.tolist(), val_ratings.tolist())\\n# 创建DataLoader\\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\\nval_loader = DataLoader(val_dataset, batch_size=32)\\n\\n# 修改模型结构，将LSTM层数调整为两层\\nclass ReviewLSTM(nn.Module):\\n    def __init__(self, embedding_dim=128, hidden_dim=256, output_dim=5, dropout_rate=0.3):  # embedding_dim增至128，hidden_dim增至256\\n        super(ReviewLSTM, self).__init__()\\n        self.embedding = nn.Embedding(tokenizer.vocab_size, embedding_dim)\\n\\n        # 双层LSTM\\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, dropout=dropout_rate, batch_first=True)\\n\\n        # 增加两层全连接层并加入Dropout\\n        self.fc1 = nn.Linear(hidden_dim, 128)\\n        self.fc2 = nn.Linear(128, 64)\\n        self.fc3 = nn.Linear(64, output_dim)\\n\\n        # Dropout层\\n        self.dropout = nn.Dropout(dropout_rate)\\n        self.softmax = nn.Softmax(dim=1)\\n\\n        # 权重初始化\\n        self._init_weights()\\n\\n    def _init_weights(self):\\n        # 初始化模型权重\\n        for m in self.modules():\\n            if isinstance(m, nn.Linear):\\n                nn.init.xavier_uniform_(m.weight)\\n                nn.init.zeros_(m.bias)\\n            elif isinstance(m, nn.LSTM):\\n                for name, param in m.named_parameters():\\n                    if 'weight' in name:\\n                        nn.init.xavier_uniform_(param)\\n                    elif 'bias' in name:\\n                        nn.init.zeros_(param)\\n\\n    def forward(self, input_ids, attention_mask):\\n        embedded = self.embedding(input_ids)  # 获取词嵌入向量\\n        lstm_out, (hidden, _) = self.lstm(embedded)  # 通过LSTM层\\n\\n        # 使用最后一层LSTM的隐藏状态并通过全连接层\\n        hidden = self.dropout(hidden[-1])\\n        x = self.fc1(hidden)\\n        x = self.dropout(nn.ReLU()(x))\\n        x = self.fc2(x)\\n        x = self.dropout(nn.ReLU()(x))\\n        x = self.fc3(x)\\n\\n        return self.softmax(x)  # 返回softmax后的概率分布\\n\\n\\n# 初始化模型、损失函数和优化器\\nmodel = ReviewLSTM().to(device)  # 将模型移动到 CUDA\\ncriterion = nn.CrossEntropyLoss()  # 使用交叉熵损失\\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)  # 使用Adam优化器\\n\\n# 修改训练函数，增加准确度计算\\ndef train_model(model, train_loader, val_loader, criterion, optimizer, epochs=20, patience=3):\\n    train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []  # 用于存储训练和验证损失及准确率\\n    best_val_loss = float(&quot;inf&quot;)  # 初始化最佳验证损失\\n    patience_counter = 0  # 初始化早停计数器\\n\\n    for epoch in range(epochs):\\n        model.train()  # 设置模型为训练模式\\n        running_loss = 0\\n        train_predictions, train_labels = [], []  # 用于存储训练集的预测结果和真实标签\\n\\n        for input_ids, attention_mask, ratings in train_loader:\\n            # 将数据移动到GPU\\n            input_ids, attention_mask, ratings = input_ids.to(device), attention_mask.to(device), ratings.to(device)  \\n            optimizer.zero_grad()  # 清空梯度\\n            outputs = model(input_ids, attention_mask)  # 获取模型输出\\n            loss = criterion(outputs, ratings)  # 计算损失\\n            loss.backward()  # 反向传播\\n            optimizer.step()  # 更新模型参数\\n            running_loss += loss.item()  # 累加损失\\n\\n            # 记录预测结果和真实标签\\n            train_predictions.extend(outputs.argmax(dim=1).cpu().numpy())  \\n            train_labels.extend(ratings.cpu().numpy())  \\n\\n        train_loss = running_loss / len(train_loader)  # 计算平均训练损失\\n        train_accuracy = accuracy_score(train_labels, train_predictions)  # 计算训练准确率\\n        train_losses.append(train_loss)  # 存储训练损失\\n        train_accuracies.append(train_accuracy)  # 存储训练准确率\\n\\n        # 验证模型\\n        model.eval()  # 设置模型为评估模式\\n        val_loss = 0\\n        val_predictions, val_labels = [], []  # 用于存储验证集的预测结果和真实标签\\n\\n        with torch.no_grad():  # 不计算梯度\\n            for input_ids, attention_mask, ratings in val_loader:\\n                # 将数据移动到GPU\\n                input_ids, attention_mask, ratings = input_ids.to(device), attention_mask.to(device), ratings.to(device)  \\n                outputs = model(input_ids, attention_mask)  # 获取模型输出\\n                loss = criterion(outputs, ratings)  # 计算损失\\n                val_loss += loss.item()  # 累加损失\\n\\n                # 记录预测结果和真实标签\\n                val_predictions.extend(outputs.argmax(dim=1).cpu().numpy()) \\n                val_labels.extend(ratings.cpu().numpy()) \\n\\n        val_loss /= len(val_loader)  # 计算平均验证损失\\n        val_accuracy = accuracy_score(val_labels, val_predictions)  # 计算验证准确率\\n        val_losses.append(val_loss)  # 存储验证损失\\n        val_accuracies.append(val_accuracy)  # 存储验证准确率\\n\\n        # 打印训练和验证信息\\n        print(f&quot;Epoch {epoch+1}/{epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, &quot;\\n              f&quot;Training Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}&quot;)\\n\\n        # 早停机制\\n        if val_loss &lt; best_val_loss:\\n            best_val_loss = val_loss\\n            patience_counter = 0\\n        else:\\n            patience_counter += 1\\n            if patience_counter &gt;= patience:\\n                print(&quot;早停法：验证损失未改善，提前停止训练。&quot;)\\n                break\\n\\n    # 绘制损失和准确度曲线\\n    plt.figure(figsize=(12, 5))\\n    plt.subplot(1, 2, 1)\\n    plt.plot(train_losses, label=&quot;训练损失&quot;)\\n    plt.plot(val_losses, label=&quot;验证损失&quot;)\\n    plt.xlabel(&quot;轮次&quot;)\\n    plt.ylabel(&quot;损失&quot;)\\n    plt.legend()\\n\\n    plt.subplot(1, 2, 2)\\n    plt.plot(train_accuracies, label=&quot;训练准确度&quot;)\\n    plt.plot(val_accuracies, label=&quot;验证准确度&quot;)\\n    plt.xlabel(&quot;轮次&quot;)\\n    plt.ylabel(&quot;准确度&quot;)\\n    plt.legend()\\n    plt.show()\\n\\n# 开始训练\\ntrain_model(model, train_loader, val_loader, criterion, optimizer)\\n\\n# 导入混淆矩阵和seaborn库\\nfrom sklearn.metrics import confusion_matrix\\nimport seaborn as sns\\n\\n# 生成混淆矩阵\\ndef plot_confusion_matrix(model, val_loader):\\n    model.eval()  # 设置模型为评估模式\\n    val_predictions, val_labels = [], []  # 用于存储验证集的预测结果和真实标签\\n\\n    with torch.no_grad():  # 不计算梯度\\n        for input_ids, attention_mask, ratings in val_loader:\\n            # 将数据移动到GPU\\n            input_ids, attention_mask, ratings = input_ids.to(device), attention_mask.to(device), ratings.to(device)\\n            outputs = model(input_ids, attention_mask)  # 获取模型输出\\n            predictions = outputs.argmax(dim=1).cpu().numpy()  # 获取预测结果\\n            val_predictions.extend(predictions)  # 存储预测结果\\n            val_labels.extend(ratings.cpu().numpy())  # 存储真实标签\\n\\n    # 计算混淆矩阵\\n    cm = confusion_matrix(val_labels, val_predictions)\\n    plt.figure(figsize=(8, 6))\\n    # 绘制热力图\\n    sns.heatmap(cm, annot=True, fmt='d', cmap=&quot;Blues&quot;, xticklabels=range(1, 6), yticklabels=range(1, 6))  \\n    plt.xlabel(&quot;Predicted Labels&quot;)\\n    plt.ylabel(&quot;True Labels&quot;)\\n    plt.title(&quot;Confusion Matrix&quot;)\\n    plt.show()\\n\\n# 生成并绘制混淆矩阵\\nplot_confusion_matrix(model, val_loader)\\n</code></pre>\\n<p>主要改进：</p>\\n<p>双层LSTM: 使用两层LSTM来提取更深层次的文本特征。\\n更宽的网络: 增加了embedding_dim和hidden_dim的维度，以及两层全连接层，使模型容量更大。\\nDropout: 在LSTM层和全连接层之间加入Dropout，防止过拟合。\\n权重初始化: 使用Xavier均匀分布初始化线性层的权重，用零初始化偏置。\\n交叉熵损失: 使用nn.CrossEntropyLoss()作为损失函数，适用于多分类任务。\\nSoftmax: 使用Softmax将模型输出转换为概率分布，表示每个星级的预测概率。\\n准确率: 在训练过程中计算并输出训练集和验证集的准确率。\\n混淆矩阵: 绘制混淆矩阵，可视化模型在不同类别上的预测效果。\\n模型结构可以概括为以下几个步骤：</p>\\n<p>BERT词嵌入: 使用预训练的BERT模型对文本进行编码，将每个词转换为一个高维向量表示。</p>\\n<p>双层LSTM: 将BERT词嵌入序列输入到两层LSTM中，提取更深层次的文本特征。</p>\\n<p>全连接层: LSTM层的输出经过三层全连接层，将高维的隐藏状态映射到五个类别（对应五种星级）。</p>\\n<p>Softmax: 全连接层的输出经过Softmax激活函数，得到每个类别的预测概率。</p>\\n<h1>带注意力机制的LSTM</h1>\\n<h2>模型1</h2>\\n<pre><code class=\\\"language-python\\\"># 导入所需库\\nfrom datasets import load_dataset  # 用于加载Hugging Face数据集\\nimport matplotlib.pyplot as plt  # 用于绘图\\nimport pandas as pd  # 用于数据处理\\nfrom sklearn.model_selection import train_test_split  # 用于划分数据集\\nimport torch\\nfrom torch import nn\\nfrom torch.utils.data import DataLoader, Dataset  # 用于创建数据加载器和数据集\\nfrom transformers import BertTokenizer  # 用于加载BERT分词器\\nimport numpy as np\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # 用于评估模型性能\\nimport seaborn as sns  # 用于绘制热力图\\n\\n# 检查CUDA是否可用\\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\nprint(f&quot;Using device: {device}&quot;)\\n\\n# 加载数据集，并取前20000条数据\\ndataset = load_dataset(&quot;McAuley-Lab/Amazon-Reviews-2023&quot;, &quot;raw_review_All_Beauty&quot;, trust_remote_code=True)\\ndata = pd.DataFrame(dataset[&quot;full&quot;][:20000])\\nprint(data.head())\\n\\n# 设置Matplotlib的字体参数\\nplt.rcParams['font.family'] = 'SimHei'\\nplt.rcParams['axes.unicode_minus'] = False\\n\\n# 初始化BERT分词器\\ntokenizer = BertTokenizer.from_pretrained(&quot;bert-base-uncased&quot;)\\nmax_len = 128  # 设置最大序列长度\\n\\n# 定义数据集类\\nclass ReviewDataset(Dataset):\\n    def __init__(self, texts, ratings):\\n        self.texts = texts\\n        self.ratings = ratings\\n\\n    def __len__(self):\\n        return len(self.texts)\\n\\n    def __getitem__(self, idx):\\n        # 使用BertTokenizer对文本进行编码\\n        encoded = tokenizer.encode_plus(\\n            self.texts[idx],\\n            add_special_tokens=True,  # 添加特殊标记\\n            max_length=max_len,  # 设置最大长度\\n            padding=&quot;max_length&quot;,  # 使用最大长度进行填充\\n            truncation=True,  # 超过最大长度进行截断\\n            return_tensors=&quot;pt&quot;,  # 返回pytorch张量\\n        )\\n        input_ids = encoded[&quot;input_ids&quot;].squeeze()  # 获取input_ids\\n        attention_mask = encoded[&quot;attention_mask&quot;].squeeze()  # 获取attention_mask\\n        # 将评分转换为类别索引（1-5 → 0-4）\\n        rating = torch.tensor(int(self.ratings[idx]) - 1, dtype=torch.long)  \\n        return input_ids, attention_mask, rating\\n\\n# 增强版LSTM分类模型\\nclass EnhancedReviewClassifier(nn.Module):\\n    def __init__(self, embedding_dim=256, hidden_dim=256, num_layers=2, dropout=0.3, bidirectional=True, num_classes=5):\\n        super(EnhancedReviewClassifier, self).__init__()\\n\\n        self.embedding = nn.Embedding(tokenizer.vocab_size, embedding_dim)  # 词嵌入层\\n        self.dropout = nn.Dropout(dropout)  # Dropout层\\n\\n        # 双向LSTM\\n        self.lstm = nn.LSTM(\\n            embedding_dim,\\n            hidden_dim,\\n            num_layers=num_layers,  # LSTM层数\\n            batch_first=True,\\n            bidirectional=bidirectional,  # 是否双向\\n            dropout=dropout if num_layers &gt; 1 else 0  # LSTM层之间添加Dropout\\n        )\\n\\n        # 注意力机制\\n        self.attention = nn.Sequential(\\n            nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, hidden_dim),  # 全连接层\\n            nn.Tanh(),  # Tanh激活函数\\n            nn.Linear(hidden_dim, 1),  # 全连接层\\n            nn.Softmax(dim=1)  # Softmax激活函数，计算注意力权重\\n        )\\n\\n        # 全连接层\\n        fc_input_dim = hidden_dim * 2 if bidirectional else hidden_dim  # 根据LSTM是否双向确定输入维度\\n        self.fc1 = nn.Linear(fc_input_dim, hidden_dim)\\n        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\\n        self.fc3 = nn.Linear(hidden_dim // 2, num_classes)  # 输出改为5个类别\\n\\n        self.relu = nn.ReLU()  # ReLU激活函数\\n        self.softmax = nn.Softmax(dim=1)  # 添加softmax层，用于输出概率分布\\n\\n    def forward(self, input_ids, attention_mask):\\n        # 词嵌入\\n        embedded = self.embedding(input_ids)\\n        embedded = self.dropout(embedded)\\n\\n        # LSTM层\\n        lstm_out, (hidden, cell) = self.lstm(embedded)\\n\\n        # 注意力机制\\n        attention_weights = self.attention(lstm_out)  # 计算注意力权重\\n        attention_output = torch.sum(attention_weights * lstm_out, dim=1)  # 对LSTM输出进行加权求和\\n\\n        # 全连接层\\n        x = self.dropout(attention_output)\\n        x = self.relu(self.fc1(x))\\n        x = self.dropout(x)\\n        x = self.relu(self.fc2(x))\\n        x = self.dropout(x)\\n        x = self.fc3(x)  # 不在这里应用softmax，因为CrossEntropyLoss已包含\\n\\n        return x\\n\\n# 数据预处理和加载\\ntrain_texts, val_texts, train_ratings, val_ratings = train_test_split(\\n    data[&quot;text&quot;].fillna(&quot;&quot;), data[&quot;rating&quot;], test_size=0.2, random_state=42\\n)\\n\\ntrain_dataset = ReviewDataset(train_texts.tolist(), train_ratings.tolist())\\nval_dataset = ReviewDataset(val_texts.tolist(), val_ratings.tolist())\\n\\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\\nval_loader = DataLoader(val_dataset, batch_size=32)\\n\\n# 初始化模型、损失函数和优化器\\nmodel = EnhancedReviewClassifier().to(device)\\ncriterion = nn.CrossEntropyLoss()  # 改用CrossEntropyLoss，适用于多分类任务\\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=0.01)  # 使用AdamW优化器\\n# 使用ReduceLROnPlateau学习率调度器，当验证损失停止下降时降低学习率\\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)  \\n\\n# 绘制混淆矩阵\\ndef plot_confusion_matrix(y_true, y_pred):\\n    cm = confusion_matrix(y_true, y_pred)\\n    plt.figure(figsize=(10, 8))\\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')  # 绘制热力图\\n    plt.title('混淆矩阵')\\n    plt.xlabel('预测类别')\\n    plt.ylabel('真实类别')\\n    plt.show()\\n\\n# 训练模型\\ndef train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=20, patience=5):\\n    train_losses, val_losses = [], []  # 用于存储训练和验证损失\\n    train_accs, val_accs = [], []  # 用于存储训练和验证准确率\\n    best_val_loss = float(&quot;inf&quot;)  # 初始化最佳验证损失\\n    patience_counter = 0  # 初始化早停计数器\\n\\n    for epoch in range(epochs):\\n        # 训练阶段\\n        model.train()  # 设置模型为训练模式\\n        running_loss = 0\\n        train_preds = []  # 用于存储训练集的预测结果\\n        train_true = []  # 用于存储训练集的真实标签\\n\\n        for input_ids, attention_mask, ratings in train_loader:\\n            input_ids = input_ids.to(device)  # 将数据移动到GPU\\n            attention_mask = attention_mask.to(device)  # 将数据移动到GPU\\n            ratings = ratings.to(device)  # 将数据移动到GPU\\n\\n            optimizer.zero_grad()  # 清空梯度\\n            outputs = model(input_ids, attention_mask)  # 获取模型输出\\n            loss = criterion(outputs, ratings)  # 计算损失\\n            loss.backward()  # 反向传播\\n\\n            # 梯度裁剪，防止梯度爆炸\\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  \\n\\n            optimizer.step()  # 更新模型参数\\n            running_loss += loss.item()  # 累加损失\\n\\n            # 收集预测结果\\n            _, predicted = torch.max(outputs.data, 1)  # 获取预测类别\\n            train_preds.extend(predicted.cpu().numpy())  # 存储预测结果\\n            train_true.extend(ratings.cpu().numpy())  # 存储真实标签\\n\\n        train_loss = running_loss / len(train_loader)  # 计算平均训练损失\\n        train_acc = accuracy_score(train_true, train_preds)  # 计算训练准确率\\n        train_losses.append(train_loss)  # 存储训练损失\\n        train_accs.append(train_acc)  # 存储训练准确率\\n\\n        # 验证阶段\\n        model.eval()  # 设置模型为评估模式\\n        val_loss = 0\\n        val_preds = []  # 用于存储验证集的预测结果\\n        val_true = []  # 用于存储验证集的真实标签\\n\\n        with torch.no_grad():  # 不计算梯度\\n            for input_ids, attention_mask, ratings in val_loader:\\n                input_ids = input_ids.to(device)  # 将数据移动到GPU\\n                attention_mask = attention_mask.to(device)  # 将数据移动到GPU\\n                ratings = ratings.to(device)  # 将数据移动到GPU\\n\\n                outputs = model(input_ids, attention_mask)  # 获取模型输出\\n                loss = criterion(outputs, ratings)  # 计算损失\\n                val_loss += loss.item()  # 累加损失\\n\\n                # 收集预测结果\\n                _, predicted = torch.max(outputs.data, 1)  # 获取预测类别\\n                val_preds.extend(predicted.cpu().numpy())  # 存储预测结果\\n                val_true.extend(ratings.cpu().numpy())  # 存储真实标签\\n\\n        val_loss /= len(val_loader)  # 计算平均验证损失\\n        val_acc = accuracy_score(val_true, val_preds)  # 计算验证准确率\\n        val_losses.append(val_loss)  # 存储验证损失\\n        val_accs.append(val_acc)  # 存储验证准确率\\n\\n        # 打印训练和验证信息\\n        print(f&quot;Epoch {epoch+1}/{epochs}&quot;)\\n        print(f&quot;Training Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}&quot;)\\n        print(f&quot;Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}&quot;)\\n\\n        # 每个epoch结束时打印详细的分类报告\\n        if epoch % 5 == 0:  # 每5个epoch打印一次详细报告\\n            print(&quot;\\\\nClassification Report:&quot;)\\n            print(classification_report(val_true, val_preds,\\n                                        target_names=['1 星', '2 星', '3 星', '4 星', '5 星']))  # 打印分类报告\\n            plot_confusion_matrix(val_true, val_preds)  # 绘制混淆矩阵\\n\\n        print(&quot;-&quot; * 50)\\n\\n        # 学习率调整\\n        scheduler.step(val_loss)  # 根据验证损失调整学习率\\n\\n        # 早停机制\\n        if val_loss &lt; best_val_loss:\\n            best_val_loss = val_loss\\n            patience_counter = 0\\n            # 保存最佳模型\\n            torch.save({\\n                'epoch': epoch,\\n                'model_state_dict': model.state_dict(),  # 保存模型参数\\n                'optimizer_state_dict': optimizer.state_dict(),  # 保存优化器参数\\n                'val_loss': val_loss,  # 保存最佳验证损失\\n                'val_acc': val_acc  # 保存最佳验证准确率\\n            }, 'best_model.pth')  # 保存模型到文件\\n        else:\\n            patience_counter += 1\\n            if patience_counter &gt;= patience:\\n                print(&quot;Early stopping triggered&quot;)  # 触发早停\\n                break\\n\\n    # 绘制训练曲线\\n    plt.figure(figsize=(12, 4))\\n\\n    plt.subplot(1, 2, 1)\\n    plt.plot(train_losses, label=&quot;训练损失&quot;)\\n    plt.plot(val_losses, label=&quot;验证损失&quot;)\\n    plt.xlabel(&quot;轮次&quot;)\\n    plt.ylabel(&quot;损失&quot;)\\n    plt.legend()\\n\\n    plt.subplot(1, 2, 2)\\n    plt.plot(train_accs, label=&quot;训练准确率&quot;)\\n    plt.plot(val_accs, label=&quot;验证准确率&quot;)\\n    plt.xlabel(&quot;轮次&quot;)\\n    plt.ylabel(&quot;准确率&quot;)\\n    plt.legend()\\n\\n    plt.tight_layout()\\n    plt.show()\\n\\n    return train_losses, val_losses, train_accs, val_accs\\n\\n# 开始训练\\ntrain_losses, val_losses, train_accs, val_accs = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler)\\n</code></pre>\\n<p>主要改进：</p>\\n<p>双向LSTM: 使用双向LSTM捕捉文本序列的双向信息。\\n注意力机制: 引入注意力机制，使模型能够关注更重要的词语信息。\\n更深的网络: 使用更多的LSTM层和全连接层，增加模型的复杂度和表达能力。\\nDropout: 在多个层之间加入Dropout，防止过拟合。\\n梯度裁剪: 使用梯度裁剪防止梯度爆炸，提高训练稳定性。\\nAdamW优化器: 使用AdamW优化器，可以更好地处理权重衰减。\\nReduceLROnPlateau学习率调度器: 当验证损失停止下降时降低学习率，帮助模型找到更好的最优解。\\n更详细的评估: 使用classification_report和confusion_matrix对模型进行更详细的评估。\\n模型结构可以概括为以下几个步骤：</p>\\n<p>BERT词嵌入: 使用预训练的BERT模型对文本进行编码，将每个词转换为一个高维向量表示。</p>\\n<p>双向LSTM: 将BERT词嵌入序列输入到双向LSTM中，提取更丰富的文本特征。</p>\\n<p>注意力机制:  使用注意力机制对LSTM的输出进行加权求和，突出重要的词语信息。</p>\\n<p>全连接层: 注意力机制的输出经过三层全连接层，将高维特征映射到五个类别（对应五种星级）。</p>\\n<p>Softmax: 全连接层的输出经过Softmax激活函数，得到每个类别的预测概率。</p>\\n<h2>模型2</h2>\\n<pre><code class=\\\"language-python\\\"># 导入所需库\\nfrom datasets import load_dataset  # 用于加载Hugging Face数据集\\nimport matplotlib.pyplot as plt  # 用于绘图\\nimport pandas as pd  # 用于数据处理\\nfrom sklearn.model_selection import train_test_split  # 用于划分数据集\\nimport torch\\nfrom torch import nn\\nfrom torch.utils.data import DataLoader, Dataset  # 用于创建数据加载器和数据集\\nfrom transformers import BertTokenizer  # 用于加载BERT分词器\\nimport numpy as np\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # 用于评估模型性能\\nimport seaborn as sns  # 用于绘制热力图\\n\\n# 检查CUDA是否可用\\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\nprint(f&quot;Using device: {device}&quot;)\\n\\n# 加载数据集，并取前20000条数据\\ndataset = load_dataset(&quot;McAuley-Lab/Amazon-Reviews-2023&quot;, &quot;raw_review_All_Beauty&quot;, trust_remote_code=True)\\ndata = pd.DataFrame(dataset[&quot;full&quot;][:20000])\\nprint(data.head())\\n\\n# 设置Matplotlib的字体参数\\nplt.rcParams['font.family'] = 'SimHei'\\nplt.rcParams['axes.unicode_minus'] = False\\n\\n# 初始化BERT分词器\\ntokenizer = BertTokenizer.from_pretrained(&quot;bert-base-uncased&quot;)\\nmax_len = 128  # 设置最大序列长度\\n\\n\\n# ReviewDataset 类修改，合并标签\\nclass ReviewDataset(Dataset):\\n    def __init__(self, texts, ratings):\\n        self.texts = texts\\n        self.ratings = ratings\\n\\n    def __len__(self):\\n        return len(self.texts)\\n\\n    def __getitem__(self, idx):\\n        # 使用BertTokenizer对文本进行编码\\n        encoded = tokenizer.encode_plus(\\n            self.texts[idx],\\n            add_special_tokens=True,  # 添加特殊标记\\n            max_length=max_len,  # 设置最大长度\\n            padding=&quot;max_length&quot;,  # 使用最大长度进行填充\\n            truncation=True,  # 超过最大长度进行截断\\n            return_tensors=&quot;pt&quot;,  # 返回pytorch张量\\n        )\\n        input_ids = encoded[&quot;input_ids&quot;].squeeze()  # 获取input_ids\\n        attention_mask = encoded[&quot;attention_mask&quot;].squeeze()  # 获取attention_mask\\n\\n        # 合并标签：将 5 个星级评分合并为 3 个类别\\n        original_rating = int(self.ratings[idx])\\n        if original_rating &lt;= 2:\\n            rating = 0  # 1-2 星合并为 0 类\\n        elif original_rating &lt;= 4:\\n            rating = 1  # 3-4 星合并为 1 类\\n        else:\\n            rating = 2  # 5 星为 2 类\\n\\n        return input_ids, attention_mask, torch.tensor(rating, dtype=torch.long)  # 返回输入ID、注意力掩码和合并后的标签\\n\\n\\n# 增强版LSTM分类模型\\nclass EnhancedReviewClassifier(nn.Module):\\n    def __init__(self, embedding_dim=256, hidden_dim=256, num_layers=2, dropout=0.3, bidirectional=True, num_classes=3):\\n        super(EnhancedReviewClassifier, self).__init__()\\n\\n        self.embedding = nn.Embedding(tokenizer.vocab_size, embedding_dim)  # 词嵌入层\\n        self.dropout = nn.Dropout(dropout)  # Dropout层\\n\\n        # 双向LSTM\\n        self.lstm = nn.LSTM(\\n            embedding_dim,\\n            hidden_dim,\\n            num_layers=num_layers,  # LSTM层数\\n            batch_first=True,\\n            bidirectional=bidirectional,  # 是否双向\\n            dropout=dropout if num_layers &gt; 1 else 0  # LSTM层之间添加Dropout\\n        )\\n\\n        # 注意力机制\\n        self.attention = nn.Sequential(\\n            nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, hidden_dim),  # 全连接层\\n            nn.Tanh(),  # Tanh激活函数\\n            nn.Linear(hidden_dim, 1),  # 全连接层\\n            nn.Softmax(dim=1)  # Softmax激活函数，计算注意力权重\\n        )\\n\\n        # 全连接层\\n        fc_input_dim = hidden_dim * 2 if bidirectional else hidden_dim  # 根据LSTM是否双向确定输入维度\\n        self.fc1 = nn.Linear(fc_input_dim, hidden_dim)\\n        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\\n        self.fc3 = nn.Linear(hidden_dim // 2, num_classes)  # 输出改为3个类别\\n\\n        self.relu = nn.ReLU()  # ReLU激活函数\\n        self.softmax = nn.Softmax(dim=1)  # 添加softmax层，用于输出概率分布\\n\\n    def forward(self, input_ids, attention_mask):\\n        # 词嵌入\\n        embedded = self.embedding(input_ids)\\n        embedded = self.dropout(embedded)\\n\\n        # LSTM层\\n        lstm_out, (hidden, cell) = self.lstm(embedded)\\n\\n        # 注意力机制\\n        attention_weights = self.attention(lstm_out)  # 计算注意力权重\\n        attention_output = torch.sum(attention_weights * lstm_out, dim=1)  # 对LSTM输出进行加权求和\\n\\n        # 全连接层\\n        x = self.dropout(attention_output)\\n        x = self.relu(self.fc1(x))\\n        x = self.dropout(x)\\n        x = self.relu(self.fc2(x))\\n        x = self.dropout(x)\\n        x = self.fc3(x)  # 不在这里应用softmax，因为CrossEntropyLoss已包含\\n\\n        return x\\n\\n# 数据预处理和加载\\ntrain_texts, val_texts, train_ratings, val_ratings = train_test_split(\\n    data[&quot;text&quot;].fillna(&quot;&quot;), data[&quot;rating&quot;], test_size=0.2, random_state=42\\n)\\n\\ntrain_dataset = ReviewDataset(train_texts.tolist(), train_ratings.tolist())\\nval_dataset = ReviewDataset(val_texts.tolist(), val_ratings.tolist())\\n\\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\\nval_loader = DataLoader(val_dataset, batch_size=32)\\n\\n# 初始化模型、损失函数和优化器\\nmodel = EnhancedReviewClassifier().to(device)\\ncriterion = nn.CrossEntropyLoss()  # 改用CrossEntropyLoss，适用于多分类任务\\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=0.01)  # 使用AdamW优化器\\n# 使用ReduceLROnPlateau学习率调度器，当验证损失停止下降时降低学习率\\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)  \\n\\n# 绘制混淆矩阵\\ndef plot_confusion_matrix(y_true, y_pred):\\n    cm = confusion_matrix(y_true, y_pred)\\n    plt.figure(figsize=(10, 8))\\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')  # 绘制热力图\\n    plt.title('混淆矩阵')\\n    plt.xlabel('预测类别')\\n    plt.ylabel('真实类别')\\n    plt.show()\\n\\n# 训练模型\\ndef train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=20, patience=5):\\n    train_losses, val_losses = [], []  # 用于存储训练和验证损失\\n    train_accs, val_accs = [], []  # 用于存储训练和验证准确率\\n    best_val_loss = float(&quot;inf&quot;)  # 初始化最佳验证损失\\n    patience_counter = 0  # 初始化早停计数器\\n\\n    for epoch in range(epochs):\\n        # 训练阶段\\n        model.train()  # 设置模型为训练模式\\n        running_loss = 0\\n        train_preds = []  # 用于存储训练集的预测结果\\n        train_true = []  # 用于存储训练集的真实标签\\n\\n        for input_ids, attention_mask, ratings in train_loader:\\n            input_ids = input_ids.to(device)  # 将数据移动到GPU\\n            attention_mask = attention_mask.to(device)  # 将数据移动到GPU\\n            ratings = ratings.to(device)  # 将数据移动到GPU\\n\\n            optimizer.zero_grad()  # 清空梯度\\n            outputs = model(input_ids, attention_mask)  # 获取模型输出\\n            loss = criterion(outputs, ratings)  # 计算损失\\n            loss.backward()  # 反向传播\\n\\n            # 梯度裁剪，防止梯度爆炸\\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  \\n\\n            optimizer.step()  # 更新模型参数\\n            running_loss += loss.item()  # 累加损失\\n\\n            # 收集预测结果\\n            _, predicted = torch.max(outputs.data, 1)  # 获取预测类别\\n            train_preds.extend(predicted.cpu().numpy())  # 存储预测结果\\n            train_true.extend(ratings.cpu().numpy())  # 存储真实标签\\n\\n        train_loss = running_loss / len(train_loader)  # 计算平均训练损失\\n        train_acc = accuracy_score(train_true, train_preds)  # 计算训练准确率\\n        train_losses.append(train_loss)  # 存储训练损失\\n        train_accs.append(train_acc)  # 存储训练准确率\\n\\n        # 验证阶段\\n        model.eval()  # 设置模型为评估模式\\n        val_loss = 0\\n        val_preds = []  # 用于存储验证集的预测结果\\n        val_true = []  # 用于存储验证集的真实标签\\n\\n        with torch.no_grad():  # 不计算梯度\\n            for input_ids, attention_mask, ratings in val_loader:\\n                input_ids = input_ids.to(device)  # 将数据移动到GPU\\n                attention_mask = attention_mask.to(device)  # 将数据移动到GPU\\n                ratings = ratings.to(device)  # 将数据移动到GPU\\n\\n                outputs = model(input_ids, attention_mask)  # 获取模型输出\\n                loss = criterion(outputs, ratings)  # 计算损失\\n                val_loss += loss.item()  # 累加损失\\n\\n                # 收集预测结果\\n                _, predicted = torch.max(outputs.data, 1)  # 获取预测类别\\n                val_preds.extend(predicted.cpu().numpy())  # 存储预测结果\\n                val_true.extend(ratings.cpu().numpy())  # 存储真实标签\\n\\n        val_loss /= len(val_loader)  # 计算平均验证损失\\n        val_acc = accuracy_score(val_true, val_preds)  # 计算验证准确率\\n        val_losses.append(val_loss)  # 存储验证损失\\n        val_accs.append(val_acc)  # 存储验证准确率\\n\\n        # 打印训练和验证信息\\n        print(f&quot;Epoch {epoch+1}/{epochs}&quot;)\\n        print(f&quot;Training Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}&quot;)\\n        print(f&quot;Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}&quot;)\\n\\n        # 每个epoch结束时打印详细的分类报告\\n        if epoch % 5 == 0:  # 每5个epoch打印一次详细报告\\n            print(&quot;\\\\nClassification Report:&quot;)\\n            # 打印分类报告，注意目标类别名称已更改\\n            print(classification_report(val_true, val_preds, \\n                                        target_names=['1 ~2星', '3 ~4星', '5 星']))  \\n            plot_confusion_matrix(val_true, val_preds)  # 绘制混淆矩阵\\n\\n        print(&quot;-&quot; * 50)\\n\\n        # 学习率调整\\n        scheduler.step(val_loss)  # 根据验证损失调整学习率\\n\\n        # 早停机制\\n        if val_loss &lt; best_val_loss:\\n            best_val_loss = val_loss\\n            patience_counter = 0\\n            # 保存最佳模型\\n            torch.save({\\n                'epoch': epoch,\\n                'model_state_dict': model.state_dict(),  # 保存模型参数\\n                'optimizer_state_dict': optimizer.state_dict(),  # 保存优化器参数\\n                'val_loss': val_loss,  # 保存最佳验证损失\\n                'val_acc': val_acc  # 保存最佳验证准确率\\n            }, 'best_model.pth')  # 保存模型到文件\\n        else:\\n            patience_counter += 1\\n            if patience_counter &gt;= patience:\\n                print(&quot;Early stopping triggered&quot;)  # 触发早停\\n                break\\n\\n    # 绘制训练曲线\\n    plt.figure(figsize=(12, 4))\\n\\n    plt.subplot(1, 2, 1)\\n    plt.plot(train_losses, label=&quot;训练损失&quot;)\\n    plt.plot(val_losses, label=&quot;验证损失&quot;)\\n    plt.xlabel(&quot;轮次&quot;)\\n    plt.ylabel(&quot;损失&quot;)\\n    plt.legend()\\n\\n    plt.subplot(1, 2, 2)\\n    plt.plot(train_accs, label=&quot;训练准确率&quot;)\\n    plt.plot(val_accs, label=&quot;验证准确率&quot;)\\n    plt.xlabel(&quot;轮次&quot;)\\n    plt.ylabel(&quot;准确率&quot;)\\n    plt.legend()\\n\\n    plt.tight_layout()\\n    plt.show()\\n\\n    return train_losses, val_losses, train_accs, val_accs\\n\\n# 开始训练\\ntrain_losses, val_losses, train_accs, val_accs = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler)\\n</code></pre>\\n<p>模型结构可以概括为以下几个步骤：</p>\\n<p>BERT词嵌入: 使用预训练的BERT模型对文本进行编码，将每个词转换为一个高维向量表示。</p>\\n<p>双向LSTM: 将BERT词嵌入序列输入到双向LSTM中，提取更丰富的文本特征。</p>\\n<p>注意力机制:  使用注意力机制对LSTM的输出进行加权求和，突出重要的词语信息。</p>\\n<p>全连接层: 注意力机制的输出经过三层全连接层，将高维特征映射到三个类别。</p>\\n<p>Softmax: 全连接层的输出经过Softmax激活函数，得到每个类别的预测概率。</p>\\n<p>合并标签的主要目的：</p>\\n<p>减少类别数量: 简化分类任务，使模型更容易学习。\\n解决类别不平衡: 原始数据集中，5 星评论的数量可能远多于其他星级，合并标签可以缓解类别不平衡问题。</p>\\n\",\n     }","\nmodule.exports = { \n      attributes: {\"title\":\"亚马逊评论数据做文本情感分类模型补充\",\"date\":\"2024-11-18T00:00:00.000Z\",\"summary\":\"在尝试的学习NLP技术\",\"coverImage\":\"11-19-9.jpg\",\"pinned\":true},\n    \n      html: \"<h1>在bert上做微调模型</h1>\\n<p>模型改动太多了，干脆直接发个最终模型得了。</p>\\n<pre><code class=\\\"language-python\\\"># 导入所需库\\nfrom datasets import load_dataset\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nimport torch\\nfrom torch import nn\\nfrom torch.utils.data import DataLoader, Dataset\\nfrom transformers import BertTokenizer, BertModel\\nimport numpy as np\\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\nimport seaborn as sns\\n\\n# 检查CUDA是否可用\\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\nprint(f&quot;Using device: {device}&quot;)\\n\\n# 加载数据集，并取前20000条数据\\ndataset = load_dataset(&quot;McAuley-Lab/Amazon-Reviews-2023&quot;, &quot;raw_review_All_Beauty&quot;, trust_remote_code=True)\\ndata = pd.DataFrame(dataset[&quot;full&quot;][:200000])\\nprint(data.head())\\n\\n# 设置Matplotlib的字体参数\\nplt.rcParams['font.family'] = 'SimHei'\\nplt.rcParams['axes.unicode_minus'] = False\\n\\n# 使用BERT tokenizer\\ntokenizer = BertTokenizer.from_pretrained(&quot;bert-base-uncased&quot;)\\nmax_len = 128\\n\\nclass ReviewDataset(Dataset):\\n    def __init__(self, texts, ratings):\\n        self.texts = texts\\n        self.ratings = ratings\\n\\n    def __len__(self):\\n        return len(self.texts)\\n\\n    def __getitem__(self, idx):\\n        encoded = tokenizer.encode_plus(\\n            self.texts[idx],\\n            add_special_tokens=True,\\n            max_length=max_len,\\n            padding='max_length',\\n            truncation=True,\\n            return_tensors='pt'\\n        )\\n        \\n        input_ids = encoded['input_ids'].squeeze()\\n        attention_mask = encoded['attention_mask'].squeeze()\\n        \\n        # 合并标签\\n        original_rating = int(self.ratings[idx])\\n        if original_rating &lt;= 2:\\n            rating = 0  # 1-2 星合并为 0 类\\n        elif original_rating &lt;= 4:\\n            rating = 1  # 3-4 星合并为 1 类\\n        else:\\n            rating = 2  # 5 星为 2 类\\n        return input_ids, attention_mask, torch.tensor(rating, dtype=torch.long)\\n\\n# BERT分类器模型\\nclass BERTReviewClassifier(nn.Module):\\n    def __init__(self, dropout=0.3, num_classes=3):\\n        super(BERTReviewClassifier, self).__init__()\\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\\n        \\n        # BERT的隐藏层大小\\n        hidden_size = self.bert.config.hidden_size\\n        \\n        # 分类头\\n        self.classifier = nn.Sequential(\\n            nn.Linear(hidden_size, hidden_size),\\n            nn.ReLU(),\\n            nn.Dropout(dropout),\\n            nn.Linear(hidden_size, hidden_size // 2),\\n            nn.ReLU(),\\n            nn.Dropout(dropout),\\n            nn.Linear(hidden_size // 2, num_classes)\\n        )\\n        \\n    def forward(self, input_ids, attention_mask):\\n        # 获取BERT输出\\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\\n        \\n        # 使用[CLS]标记的输出进行分类\\n        pooled_output = outputs.pooler_output\\n        \\n        # 通过分类头\\n        logits = self.classifier(pooled_output)\\n        \\n        return logits\\n\\n# 数据预处理和加载\\ntrain_texts, val_texts, train_ratings, val_ratings = train_test_split(\\n    data[&quot;text&quot;].fillna(&quot;&quot;), data[&quot;rating&quot;], test_size=0.2, random_state=42\\n)\\n\\ntrain_dataset = ReviewDataset(train_texts.tolist(), train_ratings.tolist())\\nval_dataset = ReviewDataset(val_texts.tolist(), val_ratings.tolist())\\n\\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)  # 减小batch size\\nval_loader = DataLoader(val_dataset, batch_size=16)\\n\\n# 初始化模型、损失函数和优化器\\nmodel = BERTReviewClassifier().to(device)\\ncriterion = nn.CrossEntropyLoss()\\n\\n# 设置不同的学习率\\nno_decay = ['bias', 'LayerNorm.weight']\\noptimizer_grouped_parameters = [\\n    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\\n     'weight_decay': 0.01},\\n    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\\n     'weight_decay': 0.0}\\n]\\noptimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=2e-5)\\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\\n\\ndef plot_confusion_matrix(y_true, y_pred,epoch):\\n    cm = confusion_matrix(y_true, y_pred)\\n    plt.figure(figsize=(10, 8))\\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\\n    plt.title('混淆矩阵')\\n    plt.xlabel('预测类别')\\n    plt.ylabel('真实类别')\\n    import os\\n    # 确保保存目录存在\\n    if not os.path.exists(&quot;figures&quot;):\\n        os.makedirs(&quot;figures&quot;)\\n\\n    # 保存图像而不是显示\\n    plt.savefig(&quot;figures/epoch%s-matrix.png&quot;%epoch)\\n    plt.close()\\n\\ndef train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=10, patience=3):\\n    train_losses, val_losses = [], []\\n    train_accs, val_accs = [], []\\n    best_val_loss = float(&quot;inf&quot;)\\n    patience_counter = 0\\n\\n    for epoch in range(epochs):\\n        # 训练阶段\\n        model.train()\\n        running_loss = 0\\n        train_preds = []\\n        train_true = []\\n        \\n        for input_ids, attention_mask, ratings in train_loader:\\n            input_ids = input_ids.to(device)\\n            attention_mask = attention_mask.to(device)\\n            ratings = ratings.to(device)\\n            \\n            optimizer.zero_grad()\\n            outputs = model(input_ids, attention_mask)\\n            loss = criterion(outputs, ratings)\\n            loss.backward()\\n            \\n            # 梯度裁剪\\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\\n            \\n            optimizer.step()\\n            running_loss += loss.item()\\n            \\n            # 收集预测结果\\n            _, predicted = torch.max(outputs.data, 1)\\n            train_preds.extend(predicted.cpu().numpy())\\n            train_true.extend(ratings.cpu().numpy())\\n        \\n        train_loss = running_loss / len(train_loader)\\n        train_acc = accuracy_score(train_true, train_preds)\\n        train_losses.append(train_loss)\\n        train_accs.append(train_acc)\\n\\n        # 验证阶段\\n        model.eval()\\n        val_loss = 0\\n        val_preds = []\\n        val_true = []\\n        \\n        with torch.no_grad():\\n            for input_ids, attention_mask, ratings in val_loader:\\n                input_ids = input_ids.to(device)\\n                attention_mask = attention_mask.to(device)\\n                ratings = ratings.to(device)\\n                \\n                outputs = model(input_ids, attention_mask)\\n                loss = criterion(outputs, ratings)\\n                val_loss += loss.item()\\n                \\n                _, predicted = torch.max(outputs.data, 1)\\n                val_preds.extend(predicted.cpu().numpy())\\n                val_true.extend(ratings.cpu().numpy())\\n        \\n        val_loss /= len(val_loader)\\n        val_acc = accuracy_score(val_true, val_preds)\\n        val_losses.append(val_loss)\\n        val_accs.append(val_acc)\\n        \\n        print(f&quot;Epoch {epoch+1}/{epochs}&quot;)\\n        print(f&quot;Training Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}&quot;)\\n        print(f&quot;Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}&quot;)\\n        \\n        # 每个epoch结束时打印详细的分类报告\\n        if epoch % 2 == 0:  # 每2个epoch打印一次详细报告\\n            print(&quot;\\\\nClassification Report:&quot;)\\n            print(classification_report(val_true, val_preds, \\n                                     target_names=['1-2星', '3-4星', '5星']))\\n            plot_confusion_matrix(val_true, val_preds,epoch)\\n            \\n        print(&quot;-&quot; * 50)\\n\\n        # 学习率调整\\n        scheduler.step(val_loss)\\n\\n        # 早停机制\\n        if val_loss &lt; best_val_loss:\\n            best_val_loss = val_loss\\n            patience_counter = 0\\n            # 保存最佳模型\\n            torch.save({\\n                'epoch': epoch,\\n                'model_state_dict': model.state_dict(),\\n                'optimizer_state_dict': optimizer.state_dict(),\\n                'val_loss': val_loss,\\n                'val_acc': val_acc\\n            }, 'best_model.pth')\\n        else:\\n            patience_counter += 1\\n            if patience_counter &gt;= patience:\\n                print(&quot;Early stopping triggered&quot;)\\n                break\\n\\n    # 绘制训练曲线\\n    plt.figure(figsize=(12, 4))\\n    \\n    plt.subplot(1, 2, 1)\\n    plt.plot(train_losses, label=&quot;训练损失&quot;)\\n    plt.plot(val_losses, label=&quot;验证损失&quot;)\\n    plt.xlabel(&quot;轮次&quot;)\\n    plt.ylabel(&quot;损失&quot;)\\n    plt.legend()\\n    \\n    plt.subplot(1, 2, 2)\\n    plt.plot(train_accs, label=&quot;训练准确率&quot;)\\n    plt.plot(val_accs, label=&quot;验证准确率&quot;)\\n    plt.xlabel(&quot;轮次&quot;)\\n    plt.ylabel(&quot;准确率&quot;)\\n    plt.legend()\\n    \\n    plt.tight_layout()\\n    import os\\n    # 确保保存目录存在\\n    if not os.path.exists(&quot;figures&quot;):\\n        os.makedirs(&quot;figures&quot;)\\n\\n    # 保存图像而不是显示\\n    plt.savefig(&quot;figures/loss_curve.png&quot;)\\n    plt.close()\\n\\n    return train_losses, val_losses, train_accs, val_accs\\n\\n# 开始训练\\ntrain_losses, val_losses, train_accs, val_accs = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler)\\n</code></pre>\\n<pre><code class=\\\"language-python\\\">\\n</code></pre>\\n<pre><code></code></pre>\\n\",\n     }","\nmodule.exports = { \n      attributes: {\"title\":\"记录一下写过的爬虫脚本\",\"date\":\"2024-11-16T00:00:00.000Z\",\"summary\":\"写的都是js脚本\",\"coverImage\":\"11-19-8.jpg\",\"pinned\":false},\n    \n      html: \"<p><s>不会有人还在写python脚本吧？</s>  <br>\\n无论是什么语言写的脚本，都必须要操作DOM  <br>\\n既然都操作都操作DOM了，我何不用JS来写呢？ \\\\</p>\\n<p>下文记录一下自己写过的爬虫脚本，数据整理代码写在另一篇了。</p>\\n<h1>pipiads的爬虫脚本</h1>\\n<p>pipiads上面主要有tiktok小店的数据，和一些广告的数据。</p>\\n<h2>主要是爬取商品数据的信息</h2>\\n<pre><code class=\\\"language-javascript\\\">\\n// ==UserScript==\\n// @name         皮皮一键爬取\\n// @namespace    http://tampermonkey.net/\\n// @version      2024-09-14\\n// @description  try to take over the world!\\n// @author       suxing\\n// @match        https://www.pipiads.com/*\\n// @icon         https://www.google.com/s2/favicons?sz=64&amp;domain=pipiads.com\\n// @grant        none\\n// ==/UserScript==\\n\\n\\nfunction main(){\\n    new Promise((resolve)=&gt;{\\n        console.log(&quot;pipiads-button1&quot;);\\n        setTimeout(()=&gt;{\\n            resolve();\\n        },4000)\\n    }).then(()=&gt;{\\n        let pageMain = document.querySelector(&quot;.main-container&quot;);\\n        console.log(pageMain)\\n        if(pageMain){\\n            const task1Button = document.createElement(&quot;button&quot;);\\n            task1Button.className = &quot;button-test&quot;;\\n            task1Button.innerHTML = &quot;任务1 小店爬取&quot;;\\n            styleButton(task1Button);\\n            task1Button.onclick=()=&gt;{task1();}\\n\\n            const task2Button = document.createElement(&quot;button&quot;);\\n            task2Button.className = &quot;button-test&quot;;\\n            task2Button.innerHTML = &quot;任务2 产品爬取&quot;;\\n            styleButton(task2Button);\\n            task2Button.onclick=()=&gt;{task2();}\\n            \\n\\n            var buttonContainer = document.createElement(&quot;div&quot;);\\n            buttonContainer.style.display = &quot;flex&quot;;\\n            buttonContainer.style.justifyContent = &quot;center&quot;;\\n            buttonContainer.style.alignItems = &quot;center&quot;;\\n            buttonContainer.style.height = &quot;100px&quot;;\\n            buttonContainer.appendChild(task1Button);\\n            buttonContainer.appendChild(task2Button);\\n            pageMain.parentNode.insertBefore(buttonContainer, pageMain);\\n\\n\\n        }\\n    })\\n}\\n\\nfunction exportjson(data,taskname){\\n    const blob = new Blob([data], { type: 'application/json' });\\n    const url = URL.createObjectURL(blob);\\n    const a = document.createElement('a');\\n    a.href = url;\\n    const today = new Date();\\n    const year = today.getFullYear();\\n    const month = String(today.getMonth() + 1).padStart(2, '0');\\n    const day = String(today.getDate()).padStart(2, '0');\\n    const formattedDate = `${year}-${month}-${day}`;\\n    a.download = `${taskname}-${formattedDate}.json`;\\n    document.body.appendChild(a);\\n    a.click();\\n    document.body.removeChild(a);\\n    URL.revokeObjectURL(url);\\n}\\nfunction task2(){\\n    new Promise((resolve)=&gt;{\\n        console.log(&quot;pipiads-scraper test1&quot;);\\n        setTimeout(()=&gt;{\\n            resolve();\\n        },700)\\n    }).then(()=&gt;{\\n        new Promise((resolve)=&gt;{\\n            window.scrollTo({\\n                top: 7000,\\n                behavior: &quot;smooth&quot;\\n            });\\n            setTimeout(()=&gt;{\\n                resolve();\\n            },1000)\\n        }).then(()=&gt;{\\n            new Promise((resolve)=&gt;{\\n                window.scrollTo({\\n                    top: 14000,\\n                    behavior: &quot;smooth&quot;\\n                });\\n                setTimeout(()=&gt;{\\n                    resolve();\\n                },1000)\\n            }).then(()=&gt;{\\n                new Promise((resolve)=&gt;{\\n                    window.scrollTo({\\n                        top: 21000,\\n                        behavior: &quot;smooth&quot;\\n                    });\\n                    setTimeout(()=&gt;{\\n                        resolve();\\n                    },1000)\\n                }).then(()=&gt;{\\n                    new Promise((resolve)=&gt;{\\n                        window.scrollTo({\\n                            top: document.body.scrollHeight,\\n                            behavior: &quot;smooth&quot;\\n                        });\\n                        setTimeout(()=&gt;{\\n                            resolve();\\n                        },700)\\n                    }).then(()=&gt;{\\n                        let productlist=[];\\n                        document.querySelectorAll(&quot;ul.wt-block-grid&gt;li.wt-block-grid__item&quot;).forEach(li=&gt;{\\n                            let title=li.querySelector(&quot;a.title.a-link&quot;).innerText;\\n                            let url=li.querySelector(&quot;a.title.a-link&quot;).getAttribute(&quot;href&quot;);\\n                            let price=&quot;&quot;\\n                            try{\\n                                price=li.querySelector(&quot;.price-box&quot;).innerText.replace(/[()]/g, &quot;&quot;);\\n                            }catch{\\n                                price=&quot;&quot;;\\n                            }\\n                            let datablock=li.querySelector(&quot;.data-count&quot;);\\n                            var i=0;\\n                            let temp=[];\\n                            datablock.querySelectorAll(&quot;.item&quot;).forEach(item=&gt;{\\n                                if(i==0){let thumb=item.querySelector(&quot;.value&quot;).innerText;temp.push(thumb)}\\n                                if(i==1){let ads=item.querySelector(&quot;.value&quot;).innerText;temp.push(ads)}\\n                                if(i==2){let increase=item.querySelector(&quot;.value&quot;).innerText;temp.push(increase)}\\n                                i++;\\n                            })\\n                            let products={\\n                                &quot;title&quot;:title,\\n                                &quot;url&quot;:url,\\n                                &quot;price&quot;:price,\\n                                &quot;thumb&quot;:temp[0],\\n                                &quot;ads&quot;:temp[1],\\n                                &quot;increase&quot;:temp[2],\\n                            }\\n                            productlist.push(products);\\n\\n                        })\\n                        const productListJson = JSON.stringify(productlist, null, 2);\\n                        console.log(productListJson);\\n                        exportjson(productListJson,&quot;task2&quot;);\\n                        window.scrollTo({\\n                            top: 0,\\n                            behavior: &quot;smooth&quot;\\n                        });\\n                    })\\n                })\\n            })\\n        })\\n    })\\n}\\n\\nfunction task1(){\\n    new Promise((resolve)=&gt;{\\n        console.log(&quot;pipiads-scraper test1&quot;);\\n        setTimeout(()=&gt;{\\n            resolve();\\n        },700)\\n    }).then(()=&gt;{\\n        new Promise((resolve)=&gt;{\\n            window.scrollTo({\\n                top: 7000,\\n                behavior: &quot;smooth&quot;\\n            });\\n            setTimeout(()=&gt;{\\n                resolve();\\n            },1000)\\n        }).then(()=&gt;{\\n            new Promise((resolve)=&gt;{\\n                window.scrollTo({\\n                    top: 14000,\\n                    behavior: &quot;smooth&quot;\\n                });\\n                setTimeout(()=&gt;{\\n                    resolve();\\n                },1000)\\n            }).then(()=&gt;{\\n                new Promise((resolve)=&gt;{\\n                    window.scrollTo({\\n                        top: 21000,\\n                        behavior: &quot;smooth&quot;\\n                    });\\n                    setTimeout(()=&gt;{\\n                        resolve();\\n                    },1000)\\n                }).then(()=&gt;{\\n                    new Promise((resolve)=&gt;{\\n                        window.scrollTo({\\n                            top: document.body.scrollHeight,\\n                            behavior: &quot;smooth&quot;\\n                        });\\n                        setTimeout(()=&gt;{\\n                            resolve();\\n                        },700)\\n                    }).then(()=&gt;{\\n                        let productlist=[];\\n                        document.querySelectorAll(&quot;ul.wt-block-grid&gt;li.wt-block-grid__item&quot;).forEach(li=&gt;{\\n                            let title=li.querySelector(&quot;a.title.a-link&quot;).innerText;\\n                            let url=li.querySelector(&quot;a.title.a-link&quot;).getAttribute(&quot;href&quot;);\\n                            let price=&quot;&quot;\\n                            try{\\n                                price=li.querySelector(&quot;span.usdPrice&quot;).innerText.replace(/[()]/g, &quot;&quot;);\\n                            }catch{\\n                                price=li.querySelector(&quot;strong.price&quot;).innerText;\\n                            }\\n                            let quantity=li.querySelector(&quot;.sales-value&quot;).innerText;\\n                            let datablock=li.querySelector(&quot;.data-count&quot;);\\n                            let adsblock=li.querySelector(&quot;.time-data-box&quot;);\\n                            var i=0;\\n                            let temp=[];\\n                            datablock.querySelectorAll(&quot;.item&quot;).forEach(item=&gt;{\\n                                if(i==0){let ads=item.querySelector(&quot;.value&quot;).innerText;temp.push(ads)}\\n                                if(i==1){let thumb=item.querySelector(&quot;.value&quot;).innerText;temp.push(thumb)}\\n                                if(i==2){let thumbrate=item.querySelector(&quot;.value&quot;).innerText;temp.push(thumbrate)}\\n                                i++;\\n                            })\\n                            let temp1=[]\\n                            var i1=0\\n                            adsblock.querySelectorAll(&quot;.time-item&quot;).forEach(item=&gt;{\\n                                if(i1==0){let starttime=item.querySelector(&quot;._value&quot;).innerText;temp1.push(starttime)}\\n                                if(i1==1){let endtime=item.querySelector(&quot;._value&quot;).innerText;temp1.push(endtime)}\\n                                if(i1==2){let nums=item.querySelector(&quot;._value&quot;).innerText;temp1.push(nums)}\\n                                i1++;\\n\\n                            })\\n                            let products={\\n                                &quot;title&quot;:title,\\n                                &quot;url&quot;:url,\\n                                &quot;price&quot;:price,\\n                                &quot;quantity&quot;:quantity,\\n                                &quot;ads&quot;:temp[0],\\n                                &quot;thumb&quot;:temp[1],\\n                                &quot;thumbrate&quot;:temp[2],\\n                                &quot;starttime&quot;:temp1[0],\\n                                &quot;endtime&quot;:temp1[1],\\n                                &quot;adsnums&quot;:temp1[2]\\n                            }\\n                            productlist.push(products);\\n\\n                        })\\n                        const productListJson = JSON.stringify(productlist, null, 2);\\n                        console.log(productListJson);\\n                        exportjson(productListJson,&quot;task1&quot;);\\n                        window.scrollTo({\\n                            top: 0,\\n                            behavior: &quot;smooth&quot;\\n                        });\\n                    })\\n                })\\n            })\\n        })\\n    })\\n}\\nfunction styleButton(button) {\\n    button.style.padding = &quot;7px 15px&quot;;\\n    button.style.margin = &quot;5px&quot;;\\n    button.style.fontSize = &quot;16px&quot;;\\n    button.style.backgroundColor = &quot;#4CAF50&quot;;\\n    button.style.color = &quot;white&quot;;\\n    button.style.border = &quot;none&quot;;\\n    button.style.borderRadius = &quot;5px&quot;;\\n    button.style.cursor = &quot;pointer&quot;;\\n    button.style.boxShadow = &quot;0px 4px 6px rgba(0, 0, 0, 0.1)&quot;;\\n    button.style.transition = &quot;background-color 0.3s&quot;;\\n    button.onmouseover = function() {\\n        button.style.backgroundColor = &quot;#45a049&quot;;\\n    };\\n    button.onmouseout = function() {\\n        button.style.backgroundColor = &quot;#4CAF50&quot;;\\n    };\\n}\\n\\n\\n\\n\\nwindow.addEventListener(&quot;load&quot;,()=&gt;{\\n    main();\\n},false)\\n</code></pre>\\n<h1>sellercenter爬虫</h1>\\n<p>当时随便找到的网站，上面不少数据是可以免费查看的，很爽。\\n随手就搞了一个爬虫，虽然没怎么用。</p>\\n<pre><code class=\\\"language-javascript\\\">// ==UserScript==\\n// @name         ebayscraper1\\n// @namespace    http://tampermonkey.net/\\n// @version      2024-10-14\\n// @description  try to take over the world!\\n// @author       suxing\\n// @match        https://sellercenter.io/*\\n// @icon         https://www.google.com/s2/favicons?sz=64&amp;domain=ebay.com\\n// @grant        none\\n// ==/UserScript==\\n\\n\\nfunction main(){\\n    new Promise((resolve)=&gt;{\\n        console.log(&quot;sc-test!&quot;);\\n        setTimeout(()=&gt;{\\n            resolve();\\n        },2000)\\n    }).then(()=&gt;{\\n        let pageMain = document.querySelector(&quot;.el-table__header-wrapper&quot;);\\n        console.log(pageMain)\\n        if(pageMain){\\n            let button = document.createElement(&quot;button&quot;);\\n            button.className=&quot;button-test&quot;\\n            button.innerHTML = &quot;点击爬取json&quot;;\\n            button.style.padding = &quot;10px 20px&quot;;\\n            button.style.fontSize = &quot;16px&quot;;\\n            button.style.backgroundColor = &quot;#4CAF50&quot;;\\n            button.style.color = &quot;white&quot;;\\n            button.style.border = &quot;none&quot;;\\n            button.style.borderRadius = &quot;5px&quot;;\\n            button.style.cursor = &quot;pointer&quot;;\\n            button.style.boxShadow = &quot;0px 4px 6px rgba(0, 0, 0, 0.1)&quot;;\\n            button.style.transition = &quot;background-color 0.3s&quot;;\\n            button.onmouseover = function() {\\n                button.style.backgroundColor = &quot;#45a049&quot;;\\n            };\\n            button.onmouseout = function() {\\n                button.style.backgroundColor = &quot;#4CAF50&quot;;\\n            };\\n            button.onclick=()=&gt;{scrapefunc();}\\n            var buttonContainer = document.createElement(&quot;div&quot;);\\n            buttonContainer.style.display = &quot;flex&quot;;\\n            buttonContainer.style.justifyContent = &quot;center&quot;;\\n            buttonContainer.style.alignItems = &quot;center&quot;;\\n            buttonContainer.style.height = &quot;100px&quot;; // 调整高度以便更好地居中\\n            buttonContainer.appendChild(button);\\n\\n            // 在 pageMain 元素的上方插入按钮\\n            pageMain.parentNode.insertBefore(buttonContainer, pageMain);\\n        }\\n    })\\n}\\n\\nfunction exportjson(data){\\n    const blob = new Blob([data], { type: 'application/json' });\\n    const url = URL.createObjectURL(blob);\\n    const a = document.createElement('a');\\n    a.href = url;\\n    const today = new Date();\\n    const year = today.getFullYear();\\n    const month = String(today.getMonth() + 1).padStart(2, '0');  \\n    const day = String(today.getDate()).padStart(2, '0');  \\n    const formattedDate = `${year}-${month}-${day}`;\\n    a.download = `ebay${formattedDate}.json`;\\n    document.body.appendChild(a);\\n    a.click();\\n    document.body.removeChild(a);\\n    URL.revokeObjectURL(url);\\n}\\nfunction scrapefunc(){\\n    new Promise((resolve)=&gt;{\\n        console.log(&quot;ebay-scraper test1&quot;);\\n        setTimeout(()=&gt;{\\n            resolve();\\n        },1000)\\n    }).then(()=&gt;{\\n        new Promise((resolve)=&gt;{\\n            window.scrollTo({\\n                top: 2000,\\n                behavior: &quot;smooth&quot;\\n            });\\n            setTimeout(()=&gt;{\\n                resolve();\\n            },1000)\\n        }).then(()=&gt;{\\n            let productlist=[];\\n            document.querySelectorAll(&quot;.el-table__row &quot;).forEach(li=&gt;{\\n                let title=li.querySelector(&quot;.productNameNew&quot;).innerText;\\n                \\n                let price=li.querySelector(&quot;.priceShow&quot;).innerText  \\n                let cate=li.querySelector(&quot;.el-tooltip__trigger&quot;).innerText\\n                let quantity=&quot;&quot;   \\n                try{\\n                    quantity=li.querySelector(&quot;.cell&gt;span&quot;).innerText;\\n                }catch{\\n                    quantity=&quot;不显示&quot;\\n                }                   \\n                let info =&quot;&quot;\\n                try{\\n                    info=li.querySelector(&quot;.viewLabel&quot;).innerText; \\n        \\n                }\\n                catch{\\n                    shipping=&quot;不显示&quot;\\n                }\\n\\n                \\n                let products={\\n                    &quot;title&quot;:title,\\n                    &quot;cate&quot;:cate,\\n                    &quot;price&quot;:price,\\n                    &quot;quantity&quot;:quantity,\\n                    &quot;info&quot;:info,\\n\\n                }                                                                      \\n                productlist.push(products);\\n                })\\n                const productListJson = JSON.stringify(productlist, null, 2);\\n                console.log(productListJson);\\n                exportjson(productListJson);\\n                window.scrollTo({\\n                    top: 0,\\n                    behavior: &quot;smooth&quot;\\n                });\\n            })        \\n\\n        })\\n}\\n\\n\\n\\n\\n\\nwindow.addEventListener(&quot;load&quot;,()=&gt;{ \\n    main();\\n\\n},false)\\n</code></pre>\\n<h1>ebay爬虫</h1>\\n<p>当时做客户需求搞的脚本，爬了二手服务器，内存条，硬盘数据</p>\\n<pre><code class=\\\"language-javascipt\\\">// ==UserScript==\\n// @name         ebayscraper1\\n// @namespace    http://tampermonkey.net/\\n// @version      2024-10-14\\n// @description  try to take over the world!\\n// @author       suxing\\n// @match        https://www.ebay.com/*\\n// @icon         https://www.google.com/s2/favicons?sz=64&amp;domain=ebay.com\\n// @grant        none\\n// ==/UserScript==\\n\\n\\nfunction main(){\\n    new Promise((resolve)=&gt;{\\n        console.log(&quot;pipiads-button1&quot;);\\n        setTimeout(()=&gt;{\\n            resolve();\\n        },2000)\\n    }).then(()=&gt;{\\n        let pageMain = document.querySelector(&quot;.s-answer-region&quot;);\\n        console.log(pageMain)\\n        if(pageMain){\\n            let button = document.createElement(&quot;button&quot;);\\n            button.className=&quot;button-test&quot;\\n            button.innerHTML = &quot;点击爬取json&quot;;\\n            button.style.padding = &quot;10px 20px&quot;;\\n            button.style.fontSize = &quot;16px&quot;;\\n            button.style.backgroundColor = &quot;#4CAF50&quot;;\\n            button.style.color = &quot;white&quot;;\\n            button.style.border = &quot;none&quot;;\\n            button.style.borderRadius = &quot;5px&quot;;\\n            button.style.cursor = &quot;pointer&quot;;\\n            button.style.boxShadow = &quot;0px 4px 6px rgba(0, 0, 0, 0.1)&quot;;\\n            button.style.transition = &quot;background-color 0.3s&quot;;\\n            button.onmouseover = function() {\\n                button.style.backgroundColor = &quot;#45a049&quot;;\\n            };\\n            button.onmouseout = function() {\\n                button.style.backgroundColor = &quot;#4CAF50&quot;;\\n            };\\n            button.onclick=()=&gt;{scrapefunc();}\\n            var buttonContainer = document.createElement(&quot;div&quot;);\\n            buttonContainer.style.display = &quot;flex&quot;;\\n            buttonContainer.style.justifyContent = &quot;center&quot;;\\n            buttonContainer.style.alignItems = &quot;center&quot;;\\n            buttonContainer.style.height = &quot;100px&quot;; // 调整高度以便更好地居中\\n            buttonContainer.appendChild(button);\\n\\n            // 在 pageMain 元素的上方插入按钮\\n            pageMain.parentNode.insertBefore(buttonContainer, pageMain);\\n        }\\n    })\\n}\\n\\nfunction exportjson(data){\\n    const blob = new Blob([data], { type: 'application/json' });\\n    const url = URL.createObjectURL(blob);\\n    const a = document.createElement('a');\\n    a.href = url;\\n    const today = new Date();\\n    const year = today.getFullYear();\\n    const month = String(today.getMonth() + 1).padStart(2, '0');  \\n    const day = String(today.getDate()).padStart(2, '0');  \\n    const formattedDate = `${year}-${month}-${day}`;\\n    a.download = `ebay${formattedDate}.json`;\\n    document.body.appendChild(a);\\n    a.click();\\n    document.body.removeChild(a);\\n    URL.revokeObjectURL(url);\\n}\\nfunction scrapefunc(){\\n    new Promise((resolve)=&gt;{\\n        console.log(&quot;ebay-scraper test1&quot;);\\n        setTimeout(()=&gt;{\\n            resolve();\\n        },1000)\\n    }).then(()=&gt;{\\n        new Promise((resolve)=&gt;{\\n            window.scrollTo({\\n                top: 2000,\\n                behavior: &quot;smooth&quot;\\n            });\\n            setTimeout(()=&gt;{\\n                resolve();\\n            },1000)\\n        }).then(()=&gt;{\\n            new Promise((resolve)=&gt;{\\n                window.scrollTo({\\n                    top: 5000,\\n                    behavior: &quot;smooth&quot;\\n                });\\n                setTimeout(()=&gt;{\\n                    resolve();\\n                },1000)\\n            }).then(()=&gt;{\\n                new Promise((resolve)=&gt;{\\n                    window.scrollTo({\\n                        top: 8000,\\n                        behavior: &quot;smooth&quot;\\n                    });\\n                    setTimeout(()=&gt;{\\n                        resolve();\\n                    },1000)\\n                }).then(()=&gt;{\\n                    new Promise((resolve)=&gt;{\\n                        window.scrollTo({\\n                            top: 12000,\\n                            behavior: &quot;smooth&quot;\\n                        });\\n                        setTimeout(()=&gt;{\\n                            resolve();\\n                        },700)\\n                    }).then(()=&gt;{    \\n                        new Promise((resolve)=&gt;{\\n                            window.scrollTo({\\n                                top: 14000,\\n                                behavior: &quot;smooth&quot;\\n                            });\\n                            setTimeout(()=&gt;{\\n                                resolve();\\n                            },700)\\n    \\n                        }).then(()=&gt;{\\n                            let productlist=[];\\n                            document.querySelectorAll(&quot;.s-item__info &quot;).forEach(li=&gt;{\\n                                let title=li.querySelector(&quot;.s-item__title&gt;span&quot;).innerText;\\n                                let secondtitle=&quot;&quot;\\n                                try{\\n                                    secondtitle=li.querySelector(&quot;.s-item__subtitle&gt;span&quot;).innerText;\\n\\n                                }\\n                                catch{\\n                                    secondtitle=&quot;不显示&quot;\\n\\n                                }\\n                                \\n                                let price=li.querySelector(&quot;span.s-item__price&quot;).innerText    \\n                                let quantity=&quot;&quot;   \\n                                try{\\n                                    quantity=li.querySelector(&quot;span.s-item__quantitySold&quot;).innerText;\\n                                }catch{\\n                                    quantity=&quot;不显示&quot;\\n                                }                   \\n                                let loc=&quot;&quot;\\n                                try{\\n                                    loc=li.querySelector(&quot;span.s-item__location&quot;).innerText;\\n\\n                                }\\n                                catch{\\n                                    loc=&quot;不显示&quot;\\n                                }\\n                                let shipping =&quot;&quot;\\n                                try{\\n                                    shipping=li.querySelector(&quot;span.s-item__shipping&quot;).innerText; \\n                      \\n                                }\\n                                catch{\\n                                    shipping=&quot;不显示&quot;\\n                                }\\n    \\n                                \\n                                let products={\\n                                    &quot;title&quot;:title,\\n                                    &quot;secondtitle&quot;:secondtitle,\\n                                    &quot;location&quot;:loc,\\n                                    &quot;price&quot;:price,\\n                                    &quot;quantity&quot;:quantity,\\n                                    &quot;shipping&quot;:shipping,\\n    \\n                                }\\n                                if (products.title!=&quot;Shop on eBay&quot;){\\n                                    productlist.push(products);\\n\\n                                }\\n                                \\n                \\n                            })\\n                            const productListJson = JSON.stringify(productlist, null, 2);\\n                            console.log(productListJson);\\n                            exportjson(productListJson);\\n                            let nextpage=document.querySelector(&quot;.pagination__next&quot;).href\\n                            window.scrollTo({\\n                                top: 0,\\n                                behavior: &quot;smooth&quot;\\n                            });\\n                            location.href=nextpage\\n                        })                              \\n    \\n                           \\n                        \\n                    })\\n                })        \\n\\n            })\\n               \\n        })\\n    })\\n}\\n\\n\\n\\n\\n\\nwindow.addEventListener(&quot;load&quot;,()=&gt;{ \\n    main();\\n\\n},false)\\n</code></pre>\\n<h1>tiktok爬虫</h1>\\n<p>这个没什么卵用的脚本，做到一半我差不多就弃掉了。</p>\\n<p>主要出发点就是，自己手点太慢了想搞个脚本一键保存tiktok后台数据不多好。</p>\\n<p>结果发现还不如手点。。。所以全自动脚本等于全自己手动脚本。</p>\\n<pre><code class=\\\"language-javascript\\\">// ==UserScript==\\n// @name         tkshop test\\n// @namespace    http://tampermonkey.net/\\n// @version      2024-10-28\\n// @description  字节跳动被我踩在脚下。\\n// @author       suxing\\n// @match        https://seller.tiktokglobalshop.com/*\\n// @icon         https://www.google.com/s2/favicons?sz=64&amp;domain=tiktokglobalshop.com\\n// @grant        none\\n// ==/UserScript==\\n\\nfunction simulateClick(selector) {\\n    const element = document.querySelector(selector);\\n    \\n    if (element) {\\n        const rect = element.getBoundingClientRect();\\n        const centerX = rect.left + rect.width / 2;\\n        const centerY = rect.top + rect.height / 2;\\n\\n        // 创建鼠标移动事件\\n        const mouseMoveEvent = new MouseEvent('mousemove', {\\n            bubbles: true,\\n            cancelable: true,\\n            view: window,\\n            clientX: centerX,\\n            clientY: centerY\\n        });\\n\\n        // 创建点击事件\\n        const mouseDownEvent = new MouseEvent('mousedown', {\\n            bubbles: true,\\n            cancelable: true,\\n            view: window,\\n            clientX: centerX,\\n            clientY: centerY\\n        });\\n\\n        const mouseUpEvent = new MouseEvent('mouseup', {\\n            bubbles: true,\\n            cancelable: true,\\n            view: window,\\n            clientX: centerX,\\n            clientY: centerY\\n        });\\n\\n        const clickEvent = new MouseEvent('click', {\\n            bubbles: true,\\n            cancelable: true,\\n            view: window,\\n            clientX: centerX,\\n            clientY: centerY\\n        });\\n\\n        // 模拟鼠标移动\\n        document.dispatchEvent(mouseMoveEvent);\\n        // 模拟鼠标按下和松开\\n        element.dispatchEvent(mouseDownEvent);\\n        element.dispatchEvent(mouseUpEvent);\\n        // 模拟点击\\n        element.dispatchEvent(clickEvent);\\n    } else {\\n        console.error('Element not found for selector:', selector);\\n    }\\n}\\n\\nfunction delay(ms) {\\n    return new Promise(resolve =&gt; setTimeout(resolve, ms));\\n}\\n\\nasync function waitForModalToClose() {\\n    // 等待打开的框消失\\n    while (document.querySelector('div[role=&quot;dialog&quot;]')) {\\n        await delay(500); // 每500毫秒检查一次\\n    }\\n}\\n\\nfunction main() {\\n    new Promise((resolve) =&gt; {\\n        console.log(&quot;tktest&quot;);\\n        setTimeout(() =&gt; {\\n            resolve();\\n        }, 10000); // 等待 10 秒\\n    }).then(() =&gt; {\\n        const pageMain = document.querySelector(&quot;#compass-header&quot;);\\n        console.log(pageMain);\\n        if (pageMain) {\\n            // 创建第一个按钮，用于第一个任务\\n            const task1Button = document.createElement(&quot;button&quot;);\\n            task1Button.className = &quot;button-test&quot;;\\n            task1Button.innerHTML = &quot;任务 1 总览数据导出）&quot;;\\n            styleButton(task1Button);\\n            task1Button.onclick = async () =&gt; {\\n                task1Button.disabled = true; // 禁用按钮以防重复点击\\n                console.log(&quot;任务 1: 点击按钮&quot;);\\n                // 执行任务 1 的操作\\n                await simulateClick('button[data-tid=&quot;m4b_button&quot;]'); // 假设是导出按钮\\n                task1Button.disabled = false; // 点击完成后启用按钮\\n            };\\n\\n            // 创建第二个按钮，用于第二个任务\\n            const task2Button = document.createElement(&quot;button&quot;);\\n            task2Button.className = &quot;button-test&quot;;\\n            task2Button.innerHTML = &quot;任务 2: 商品数据导出）&quot;;\\n            styleButton(task2Button);\\n            task2Button.onclick = async () =&gt; {\\n                task2Button.disabled = true; // 禁用按钮以防重复点击\\n                console.log(&quot;任务 2: 商品数据导出&quot;);\\n\\n                // 点击配置指标按钮\\n                const configButtonSelector = 'div.mx-12 button';\\n                simulateClick(configButtonSelector);\\n\\n                // 等待框关闭\\n                await waitForModalToClose();\\n\\n                // 点击导出按钮\\n                const exportButtonSelector = 'div.flex.gap-8 button';\\n                simulateClick(exportButtonSelector);\\n\\n                task2Button.disabled = false; // 点击完成后启用按钮\\n            };\\n\\n            // 创建按钮容器并插入按钮\\n            const buttonContainer = document.createElement(&quot;div&quot;);\\n            buttonContainer.style.display = &quot;flex&quot;;\\n            buttonContainer.style.justifyContent = &quot;center&quot;;\\n            buttonContainer.style.alignItems = &quot;center&quot;;\\n            buttonContainer.style.height = &quot;50px&quot;; // 调整高度以便更好地居中\\n            buttonContainer.appendChild(task1Button);\\n            buttonContainer.appendChild(task2Button);\\n\\n            // 在 pageMain 元素的上方插入按钮容器\\n            pageMain.parentNode.insertBefore(buttonContainer, pageMain);\\n        }\\n    });\\n}\\n\\nfunction styleButton(button) {\\n    button.style.padding = &quot;10px 20px&quot;;\\n    button.style.margin = &quot;5px&quot;;\\n    button.style.fontSize = &quot;16px&quot;;\\n    button.style.backgroundColor = &quot;#4CAF50&quot;;\\n    button.style.color = &quot;white&quot;;\\n    button.style.border = &quot;none&quot;;\\n    button.style.borderRadius = &quot;5px&quot;;\\n    button.style.cursor = &quot;pointer&quot;;\\n    button.style.boxShadow = &quot;0px 4px 6px rgba(0, 0, 0, 0.1)&quot;;\\n    button.style.transition = &quot;background-color 0.3s&quot;;\\n    button.onmouseover = function() {\\n        button.style.backgroundColor = &quot;#45a049&quot;;\\n    };\\n    button.onmouseout = function() {\\n        button.style.backgroundColor = &quot;#4CAF50&quot;;\\n    };\\n}\\n\\n// 调用 main 函数以执行代码\\nmain();\\n\\n</code></pre>\\n\",\n     }","\nmodule.exports = { \n      attributes: {\"title\":\"从CNN循环神经网络到Transformer模型\",\"date\":\"2024-11-01T00:00:00.000Z\",\"summary\":\"在尝试的学习CV技术\",\"coverImage\":\"11-19-7.jpg\",\"pinned\":false},\n    \n      html: \"<p>CNN最初就是从线性层变过来的一个模型结构，只是多加了一个隐藏变量。</p>\\n<h2>RNN模型</h2>\\n<p>$$\\nh_t = \\\\sigma_h(W_{xh} x_t + W_{hh} h_{t-1} + b_h)\\n$$</p>\\n<p>$$\\ny_t=\\\\sigma_y(W _{hy}h_t+b _y)\\n$$</p>\\n<p>$$\\nf_t=\\\\sigma(W_f⋅concat[h _{t−1},x _t]+b _f)\\n$$</p>\\n<p>当前层的输出会</p>\\n\",\n     }","\nmodule.exports = { \n      attributes: {\"title\":\"文本情感分析模型\",\"date\":\"2024-11-21T00:00:00.000Z\",\"summary\":\"这是整理代码的文章\",\"coverImage\":\"11-19-6.jpg\",\"pinned\":true},\n    \n      html: \"<h1>这是一个置顶文章测试</h1>\\n\",\n     }","\nmodule.exports = { \n      attributes: {\"title\":\"测试文章\",\"date\":\"2024-11-1\",\"summary\":\"这是我的第一篇博客文章\",\"coverImage\":\"post1/2.png\",\"pinned\":false},\n    \n      html: \"<h1>欢迎来到我的博客</h1>\\n<p>这是一篇测试博客，如果它能正常显示成功就代表它运行正常了。</p>\\n<h2>数学公式示例</h2>\\n<p>$\\nE = mc^2\\n$</p>\\n<h2>代码块示例</h2>\\n<pre><code class=\\\"language-python\\\">def hello_world():\\n    print(&quot;Hello, World!&quot;)\\n</code></pre>\\n<h2>图片示例</h2>\\n<p><img src=\\\"posts/images/1.png\\\" alt=\\\"本地图片\\\"></p>\\n\",\n     }","<!-- src/App.vue -->\n<template>\n  <div class=\"app\">\n    <blog-header />\n    <router-view />\n    <blog-footer />\n  </div>\n</template>\n\n<script>\nimport BlogHeader from '@/components/BlogHeader.vue'\nimport BlogFooter from '@/components/BlogFooter.vue'\n\nexport default {\n  name: 'App',\n  components: {\n    BlogHeader,\n    BlogFooter\n  }\n}\n</script>\n","<!-- BlogHeader.vue -->\n<template>\n  <header class=\"header\" :class=\"{ 'header-scrolled': isScrolled }\">\n    <div class=\"header-content\">\n      <div class=\"header-main\">\n        <h1 class=\"site-title\">星云茶聚</h1>\n        <nav class=\"site-nav\">\n          <router-link to=\"/\" class=\"nav-link\">首页</router-link>\n          <router-link to=\"/archive\" class=\"nav-link\">归档</router-link>\n          <router-link to=\"/about\" class=\"nav-link\">关于</router-link>\n        </nav>\n      </div>\n    </div>\n  </header>\n</template>\n\n<script>\n\nexport default {\n  name: 'BlogHeader',\n  data() {\n    return {\n      isScrolled: false,\n      lastScrollTop: 0,\n      headerHeight: 0,\n      scrollThreshold: 50, // 添加滚动阈值\n      scrollTimer: null\n    }\n  },\n  mounted() {\n    this.headerHeight = this.$el.offsetHeight\n    window.addEventListener('scroll', this.handleScroll, { passive: true })\n    document.body.style.paddingTop = `${this.headerHeight + 40}px`\n  },\n  beforeUnmount() {\n    window.removeEventListener('scroll', this.handleScroll)\n    document.body.style.paddingTop = '0'\n    if (this.scrollTimer) {\n      clearTimeout(this.scrollTimer)\n    }\n  },\n  methods: {\n    handleScroll() {\n      // 使用 requestAnimationFrame 优化性能\n      if (this.scrollTimer) {\n        cancelAnimationFrame(this.scrollTimer)\n      }\n      \n      this.scrollTimer = requestAnimationFrame(() => {\n        const st = window.scrollY // 替换废弃的 pageYOffset\n        \n        // 在顶部或接近顶部时始终显示\n        if (st <= this.scrollThreshold) {\n          this.isScrolled = false\n          return\n        }\n\n        // 计算滚动距离和方向\n        const scrollDelta = st - this.lastScrollTop\n        \n        // 只有当滚动距离超过阈值时才触发变化\n        if (Math.abs(scrollDelta) > this.scrollThreshold) {\n          if (scrollDelta > 0) {\n            // 向下滚动\n            this.isScrolled = false\n          } else {\n            // 向上滚动\n            this.isScrolled = true\n          }\n          this.lastScrollTop = st\n        }\n      })\n    }\n  }\n}\n</script>\n\n<style scoped>\n\n.header-scrolled {\n  top: 0;\n}\n\n.header {\n  background: rgba(255, 255, 255, 0.65); /* 降低不透明度 */\n  backdrop-filter: blur(0.5px); /* 添加模糊效果增加可读性 */\n  border-bottom: 1px solid #eef2f7;\n  max-width: 900px;\n  margin: auto;\n  padding: 0.5rem 0;\n  position: sticky;\n  top: 0;\n  z-index: 100;\n  box-shadow: 0 1px 2px rgba(0, 0, 0, 0.03);\n}\n\n.header-content {\n  max-width: 1200px;\n  margin: 0 auto;\n  padding: 0 1rem;\n}\n\n.header-main {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  gap: 0.05rem;\n}\n\n.site-title {\n  font-size: 1.5rem;\n  font-weight: 700;\n  color: #2c3e50;\n  margin: 0;\n  background: linear-gradient(120deg, #42b883 0%, #3aa876 100%);\n  -webkit-background-clip: text;\n  -webkit-text-fill-color: transparent;\n}\n\n.site-nav {\n  display: flex;\n  gap: 2rem; /* 增加导航项间距 */\n}\n\n.nav-link {\n  color: #4a5568;\n  text-decoration: none;\n  font-weight: 500;\n  font-size: 0.9375rem;\n  padding: 0.5rem 0.75rem; /* 增加可点击区域 */\n  position: relative;\n  transition: color 0.2s ease;\n}\n.nav-link:hover {\n  color: #42b883;\n}\n\n.nav-link::after {\n  content: '';\n  position: absolute;\n  bottom: -2px;\n  left: 0;\n  width: 100%;\n  height: 2px;\n  background: #42b883;\n  transform: scaleX(0);\n  transition: transform 0.2s ease;\n}\n\n.nav-link:hover::after,\n.router-link-active::after {\n  transform: scaleX(1);\n}\n\n@media (max-width: 768px) {\n  .header-content {\n    padding: 0 1rem;\n  }\n  \n  .header-main {\n    flex-direction: column;\n    gap: 0.5rem;\n  }\n\n  .site-nav {\n    gap: 1.5rem;\n  }\n}\n</style>","import { render } from \"./BlogHeader.vue?vue&type=template&id=1e9d4ba0&scoped=true\"\nimport script from \"./BlogHeader.vue?vue&type=script&lang=js\"\nexport * from \"./BlogHeader.vue?vue&type=script&lang=js\"\n\nimport \"./BlogHeader.vue?vue&type=style&index=0&id=1e9d4ba0&scoped=true&lang=css\"\n\nimport exportComponent from \"../../node_modules/vue-loader/dist/exportHelper.js\"\nconst __exports__ = /*#__PURE__*/exportComponent(script, [['render',render],['__scopeId',\"data-v-1e9d4ba0\"]])\n\nexport default __exports__","<!-- src/components/BlogFooter.vue -->\n<template>\n    <footer class=\"footer\">\n      <p>© {{ currentYear }} 星云茶聚. All rights reserved.</p>\n      <div class=\"social-links\">\n        <a href=\"#\">微博</a> |\n        <a href=\"https://github.com/SUXUING-star/SUXUING-star.github.io\">GitHub</a> |\n        <a href=\"#\">LinkedIn</a>\n      </div>\n    </footer>\n  </template>\n  \n  <script>\n  export default {\n    name: 'BlogFooter',\n    computed: {\n      currentYear() {\n        return new Date().getFullYear()\n      }\n    }\n  }\n  </script>","import { render } from \"./BlogFooter.vue?vue&type=template&id=47c3d96c\"\nimport script from \"./BlogFooter.vue?vue&type=script&lang=js\"\nexport * from \"./BlogFooter.vue?vue&type=script&lang=js\"\n\nimport exportComponent from \"../../node_modules/vue-loader/dist/exportHelper.js\"\nconst __exports__ = /*#__PURE__*/exportComponent(script, [['render',render]])\n\nexport default __exports__","import { render } from \"./App.vue?vue&type=template&id=7dda88b9\"\nimport script from \"./App.vue?vue&type=script&lang=js\"\nexport * from \"./App.vue?vue&type=script&lang=js\"\n\nimport exportComponent from \"../node_modules/vue-loader/dist/exportHelper.js\"\nconst __exports__ = /*#__PURE__*/exportComponent(script, [['render',render]])\n\nexport default __exports__","<!-- Home.vue -->\n<template>\n  <div class=\"home-page\">\n    <section class=\"banner\">\n      <div class=\"banner-content\">\n        <h2>欢迎来到这个神奇的地方！</h2>\n        <p>记录成长，探索未知的世界。</p>\n      </div>\n    </section>\n\n\n    <!-- 置顶文章区域 -->\n    <section v-if=\"pinnedPosts.length\" class=\"pinned-posts\">\n      <h3 class=\"section-title\">📌 置顶文章</h3>\n      <div class=\"posts-grid\">\n        <blog-post\n          v-for=\"post in pinnedPosts\"\n          :key=\"post.id\"\n          :post=\"post\"\n          @click=\"viewPost(post.id)\"\n        />\n      </div>\n    </section>\n    \n    <!-- 普通文章区域 -->\n    <section class=\"regular-posts\">\n      <h3 v-if=\"pinnedPosts.length\" class=\"section-title\">最新文章</h3>\n      <div class=\"posts-grid\">\n        <blog-post\n          v-for=\"post in paginatedRegularPosts\"\n          :key=\"post.id\"\n          :post=\"post\"\n          @click=\"viewPost(post.id)\"\n        />\n      </div>\n    </section>\n\n    <!-- 分页控件 -->\n    <div v-if=\"totalPages > 1\" class=\"pagination\">\n      <button \n        class=\"pagination-btn\" \n        :disabled=\"currentPage === 1\"\n        @click=\"changePage(currentPage - 1)\"\n      >\n        ← 上一页\n      </button>\n      \n      <div class=\"pagination-numbers\">\n        <button \n          v-for=\"page in displayedPages\" \n          :key=\"page\"\n          class=\"page-number\"\n          :class=\"{ active: page === currentPage }\"\n          @click=\"changePage(page)\"\n        >\n          {{ page }}\n        </button>\n      </div>\n\n      <button \n        class=\"pagination-btn\"\n        :disabled=\"currentPage === totalPages\"\n        @click=\"changePage(currentPage + 1)\"\n      >\n        下一页 →\n      </button>\n    </div>\n  </div>\n</template>\n  \n<script>\nimport { useStore } from 'vuex'\nimport { computed, ref } from 'vue'\nimport { useRouter } from 'vue-router'\nimport BlogPost from '@/components/BlogPost.vue'\n\nexport default {\n  name: 'HomePage',\n  components: {\n    BlogPost\n  },\n  setup() {\n    const store = useStore()\n    const router = useRouter()\n    \n    const postsPerPage = 6\n    const currentPage = ref(1)\n    \n    const posts = computed(() => {\n      console.log('Posts:', store.state.posts)\n      return store.state.posts\n    })\n    \n    // 统一使用 pinned\n    const pinnedPosts = computed(() =>\n      posts.value.filter(post => \n        post.frontmatter?.pinned === true || \n        post.pinned === true\n      )\n    )\n    const regularPosts = computed(() =>\n      posts.value.filter(post => post.pinned !== true)\n    );\n    \n    // 计算总页数（只考虑非置顶文章）\n    const totalPages = computed(() => \n      Math.ceil(regularPosts.value.length / postsPerPage)\n    )\n    \n    // 当前页的普通文章\n    const paginatedRegularPosts = computed(() => {\n      const start = (currentPage.value - 1) * postsPerPage\n      const end = start + postsPerPage\n      return regularPosts.value.slice(start, end)\n    })\n    \n    // 计算要显示的页码（最多显示5个页码）\n    const displayedPages = computed(() => {\n      const total = totalPages.value\n      const current = currentPage.value\n      const pages = []\n      \n      if (total <= 5) {\n        for (let i = 1; i <= total; i++) {\n          pages.push(i)\n        }\n      } else {\n        if (current <= 3) {\n          for (let i = 1; i <= 5; i++) {\n            pages.push(i)\n          }\n        } else if (current >= total - 2) {\n          for (let i = total - 4; i <= total; i++) {\n            pages.push(i)\n          }\n        } else {\n          for (let i = current - 2; i <= current + 2; i++) {\n            pages.push(i)\n          }\n        }\n      }\n      \n      return pages\n    })\n    \n    const changePage = (page) => {\n      currentPage.value = page\n      window.scrollTo({\n        top: 0,\n        behavior: 'smooth'\n      })\n    }\n    \n    const viewPost = (id) => {\n      router.push(`/post/${id}`)\n    }\n    \n    return {\n      pinnedPosts,\n      paginatedRegularPosts,\n      currentPage,\n      totalPages,\n      displayedPages,\n      changePage,\n      viewPost\n    }\n  }\n}\n</script>\n\n<style scoped>\n.home-page {\n  max-width: 1600px;\n  margin: 0 auto;\n  padding: 1rem;\n}\n\n.section-title {\n  font-size: 1.5rem;\n  color: #2c3e50;\n  margin: 2rem 0 1rem;\n  padding-left: 0.5rem;\n  max-width: 1000px;\n  margin-left: auto;\n  margin-right: auto;\n}\n\n.pinned-posts {\n  margin-bottom: 2rem;\n}\n\n.posts-grid {\n  display: grid;\n  grid-template-columns: repeat(auto-fill, minmax(280px, 1fr));\n  gap: 1.5rem;\n  padding: 0.5rem 0;\n  max-width: 1000px;\n  margin: 0 auto;\n}\n\n.pagination {\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  margin: 2rem 0;\n  gap: 1rem;\n}\n\n.pagination-numbers {\n  display: flex;\n  gap: 0.5rem;\n}\n\n.pagination-btn, .page-number {\n  padding: 0.5rem 1rem;\n  border: 1px solid #e2e8f0;\n  border-radius: 6px;\n  background-color: #ffffff;\n  color: #4a5568;\n  cursor: pointer;\n  transition: all 0.2s ease;\n}\n\n.pagination-btn:disabled {\n  opacity: 0.5;\n  cursor: not-allowed;\n}\n\n.pagination-btn:not(:disabled):hover,\n.page-number:hover {\n  background-color: #f7fafc;\n  border-color: #cbd5e0;\n}\n\n.page-number.active {\n  background-color: #42b883;\n  color: white;\n  border-color: #42b883;\n}\n\n@media (max-width: 768px) {\n  .banner {\n    padding: 1.5rem 1rem;\n  }\n\n  .banner h2 {\n    font-size: 1.5rem;\n  }\n\n  .banner p {\n    font-size: 1rem;\n  }\n\n  .posts-grid {\n    grid-template-columns: 1fr;\n    gap: 1.25rem;\n  }\n\n  .pagination {\n    flex-wrap: wrap;\n  }\n\n  .section-title {\n    font-size: 1.25rem;\n    margin: 1.5rem 0 0.75rem;\n  }\n}\n</style>","<!-- BlogPost.vue -->\n<template>\n  <article class=\"blog-post-card\" :class=\"{ 'blog-post-pinned': post.pinned }\" @click=\"$emit('click')\">\n    <!-- 添加置顶标识 -->\n    <div class=\"pin-badge\" v-if=\"post.pinned\">\n      <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" fill=\"none\" \n           stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n        <line x1=\"12\" y1=\"17\" x2=\"12\" y2=\"22\"/>\n        <path d=\"M5 17h14v-1.76a2 2 0 0 0-1.11-1.79l-1.78-.9A2 2 0 0 1 15 10.76V6h1a2 2 0 0 0 0-4H8a2 2 0 0 0 0 4h1v4.76a2 2 0 0 1-1.11 1.79l-1.78.9A2 2 0 0 0 5 15.24Z\"/>\n      </svg>\n      <span>置顶</span>\n    </div>\n    \n    <div class=\"post-image\" >\n      <img \n        v-if=\"post.coverImage\"\n        :src=\"post.coverImage\" \n        :alt=\"post.title\"\n        @error=\"handleImageError\"\n        loading=\"lazy\"\n      >\n      <img \n        v-else \n        src=\"/placeholder-image.gif\" \n        alt=\"Placeholder Image\" \n        loading=\"lazy\"\n      >\n    </div>\n    <div class=\"post-content\">\n      <h2 class=\"post-title\">{{ post.title }}</h2>\n      <div class=\"post-meta\">\n        <span class=\"post-date\">{{ post.date }}</span>\n      </div>\n      <p class=\"post-summary\">{{ post.summary }}</p>\n      <div class=\"post-footer\">\n        <span class=\"read-more\">阅读全文 →</span>\n      </div>\n    </div>\n  </article>\n</template>\n\n<script>\nexport default {\n  name: 'BlogPostItem',\n  props: {\n    post: {\n      type: Object,\n      required: true,\n      default: () => ({\n\n        coverImage: '',\n        summary: ''\n      }),\n      validator: function(obj) {\n        return obj && \n          // 标题可以是空字符串，但必须是字符串\n          (typeof obj.title === 'string') && \n          // 日期可以是空字符串，但必须是字符串\n          (typeof obj.date === 'string') && \n          // pinned 是可选的，如果存在必须是布尔值\n          (!('pinned' in obj) || typeof obj.pinned === 'boolean') && \n          // coverImage 可以是字符串或 undefined\n          (typeof obj.coverImage === 'string' || obj.coverImage === undefined) && \n          // summary 可以是空字符串，但必须是字符串\n          (typeof obj.summary === 'string')\n      }\n    }\n  },\n  methods: {\n    handleImageError(e) {\n      e.target.src = '/placeholder-image.gif'\n    }\n    \n    \n  }\n}\n</script>\n\n<style scoped>\n/* 修正 - 为 blog-post-card 添加 position: relative */\n.blog-post-card {\n  background: #ffffff;\n  border-radius: 12px;\n  overflow: hidden;\n  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);\n  transition: transform 0.2s ease, box-shadow 0.2s ease;\n  height: 100%;\n  display: flex;\n  flex-direction: column;\n  cursor: pointer;\n  border: 1px solid #eef2f7;\n  position: relative; /* 添加相对定位 */\n}\n\n.blog-post-card:hover {\n  transform: translateY(-4px);\n  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n}\n\n/* 置顶标识样式 */\n.pin-badge {\n  position: absolute;\n  top: 1rem;\n  right: 1rem;\n  background: rgba(66, 184, 131, 0.9);\n  color: white;\n  padding: 0.25rem 0.75rem;\n  border-radius: 20px;\n  display: flex;\n  align-items: center;\n  gap: 0.25rem;\n  font-size: 0.875rem;\n  font-weight: 500;\n  z-index: 1;\n  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n}\n\n\n.pin-badge svg {\n  width: 14px;\n  height: 14px;\n}\n\n.blog-post-card {\n  background: #ffffff;\n  border-radius: 12px;\n  overflow: hidden;\n  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);\n  transition: transform 0.2s ease, box-shadow 0.2s ease;\n  height: 100%;\n  display: flex;\n  flex-direction: column;\n  cursor: pointer;\n  border: 1px solid #eef2f7;\n}\n\n.blog-post-card:hover {\n  transform: translateY(-4px);\n  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n}\n\n.post-image {\n  width: 100%;\n  height: 180px;\n  overflow: hidden;\n}\n\n.post-image img {\n  width: 100%;\n  height: 100%;\n  object-fit: cover;\n  transition: transform 0.3s ease;\n}\n\n.blog-post-card:hover .post-image img {\n  transform: scale(1.05);\n}\n\n.post-content {\n  padding: 1.25rem;\n  flex: 1;\n  display: flex;\n  flex-direction: column;\n  background: linear-gradient(to bottom, #ffffff 0%, #fafbfc 100%);\n}\n\n.post-title {\n  font-size: 1.125rem;\n  font-weight: 600;\n  color: #2c3e50;\n  margin: 0 0 0.5rem 0;\n  line-height: 1.4;\n}\n\n.post-meta {\n  font-size: 0.875rem;\n  color: #718096;\n  margin-bottom: 0.75rem;\n}\n\n.post-summary {\n  color: #4a5568;\n  line-height: 1.6;\n  margin-bottom: 1rem;\n  flex: 1;\n  font-size: 0.9375rem;\n}\n\n.post-footer {\n  margin-top: auto;\n  padding-top: 0.75rem;\n  border-top: 1px solid #edf2f7;\n}\n\n.read-more {\n  color: #42b883;\n  font-weight: 500;\n  font-size: 0.875rem;\n}\n\n.read-more:hover {\n  color: #3aa876;\n}\n</style>","import { render } from \"./BlogPost.vue?vue&type=template&id=7a8ffa7a&scoped=true\"\nimport script from \"./BlogPost.vue?vue&type=script&lang=js\"\nexport * from \"./BlogPost.vue?vue&type=script&lang=js\"\n\nimport \"./BlogPost.vue?vue&type=style&index=0&id=7a8ffa7a&scoped=true&lang=css\"\n\nimport exportComponent from \"../../node_modules/vue-loader/dist/exportHelper.js\"\nconst __exports__ = /*#__PURE__*/exportComponent(script, [['render',render],['__scopeId',\"data-v-7a8ffa7a\"]])\n\nexport default __exports__","import { render } from \"./Home.vue?vue&type=template&id=6ccd4249&scoped=true\"\nimport script from \"./Home.vue?vue&type=script&lang=js\"\nexport * from \"./Home.vue?vue&type=script&lang=js\"\n\nimport \"./Home.vue?vue&type=style&index=0&id=6ccd4249&scoped=true&lang=css\"\n\nimport exportComponent from \"../../node_modules/vue-loader/dist/exportHelper.js\"\nconst __exports__ = /*#__PURE__*/exportComponent(script, [['render',render],['__scopeId',\"data-v-6ccd4249\"]])\n\nexport default __exports__","import { createRouter, createWebHashHistory } from 'vue-router'\nimport Home from '../views/Home.vue'\n\nconst routes = [\n  {\n    path: '/',\n    name: 'Home',\n    component: Home,\n    // 预加载其他常用组件\n    beforeEnter: (to, from, next) => {\n      const components = [\n        import(/* webpackChunkName: \"about\" */ '../views/About.vue'),\n        import(/* webpackChunkName: \"archive\" */ '../views/Archive.vue')\n      ];\n      Promise.all(components).catch(() => {});\n      next();\n    }\n  },\n  {\n    path: '/about',\n    name: 'About',\n    component: () => import(/* webpackChunkName: \"about\" */ '../views/About.vue'),\n    // 添加 meta 字段用于控制缓存\n    meta: { keepAlive: true }\n  },\n  {\n    path: '/post/:id',\n    name: 'PostDetail',\n    component: () => import(/* webpackChunkName: \"post\" */ '../views/PostDetail.vue'),\n    props: true,\n  },\n  {\n    path: '/archive',\n    name: 'Archive',\n    component: () => import(/* webpackChunkName: \"archive\" */ '../views/Archive.vue'),\n    meta: { keepAlive: true }\n  }\n]\n\nconst router = createRouter({\n  history: createWebHashHistory(),\n  routes,\n  // 滚动行为\n  scrollBehavior(to, from, savedPosition) {\n    if (savedPosition) {\n      return savedPosition;\n    } else {\n      return { top: 0 };\n    }\n  }\n});\n\n// 路由守卫中添加进度条\nrouter.beforeEach((to, from, next) => {\n  // 可以在这里添加 NProgress 等加载进度条\n  next();\n});\n\nexport default router;","import { createStore } from 'vuex'\n\n// 使用 webpack 的 require.context 导入 Markdown 文件\nconst markdownFiles = require.context('../posts/', true, /\\.md$/)\n\n// 日期格式化\nfunction formatDate(dateString) {\n  const date = new Date(dateString)\n  return date.toLocaleDateString('zh-CN', {\n    year: 'numeric',\n    month: 'long',\n    day: 'numeric'\n  })\n}\n\n// 图片路径解析\nfunction getImageUrl(imagePath) {\n  if (!imagePath) return ''\n  if (imagePath.startsWith('http')) {\n    return imagePath\n  }\n\n  try {\n    return require(`../posts/images/${imagePath}`)\n  } catch (e) {\n    console.warn(`Image not found: ${imagePath}`)\n    return ''\n  }\n}\n\n// Markdown 图片路径处理\nfunction processMarkdownImages(content) {\n  return content.replace(\n    /!\\[(.*?)\\]\\((.*?)\\)/g,\n    (match, alt, path) => {\n      if (path.startsWith('http')) {\n        return match\n      }\n      try {\n        const imageUrl = require(`../posts/images/${path}`)\n        return `![${alt}](${imageUrl})`\n      } catch (e) {\n        console.warn(`Image not found in markdown: ${path}`)\n        return match\n      }\n    }\n  )\n}\n\n// Markdown 文件处理\nfunction processMarkdownFiles() {\n  return markdownFiles.keys().map((path, index) => {\n    const slug = path.replace(/^\\.\\//, '').replace(/\\.md$/, '')\n    const { attributes, html } = markdownFiles(path)\n\n    return {\n      id: index + 1,\n      slug,\n      title: attributes.title,\n      date: formatDate(attributes.date),\n      summary: attributes.summary,\n      coverImage: getImageUrl(attributes.coverImage),\n      pinned: attributes.pinned || false,\n      content: processMarkdownImages(html)\n    }\n  })\n}\n\nconst store = createStore({\n  state() {\n    return {\n      posts: processMarkdownFiles()\n    }\n  },\n  getters: {\n    getPostById: (state) => (id) => {\n      return state.posts.find(post => post.id === parseInt(id))\n    },\n    getPostBySlug: (state) => (slug) => {\n      return state.posts.find(post => post.slug === slug)\n    },\n    getAllPosts: (state) => {\n      return state.posts\n    }\n  },\n  mutations: {\n    UPDATE_POST(state, { id, post }) {\n      const index = state.posts.findIndex(p => p.id === id)\n      if (index !== -1) {\n        state.posts[index] = { ...state.posts[index], ...post }\n      }\n    }\n  },\n  actions: {\n    updatePost({ commit }, payload) {\n      commit('UPDATE_POST', payload)\n    }\n  }\n})\n\nexport default store\n","// src/main.js\nimport { createApp } from 'vue'\nimport App from './App.vue'\nimport router from './router'\nimport store from './store'\nimport './assets/styles/main.css'\n\n// 导入 KaTeX CSS\nimport 'katex/dist/katex.min.css'\n// 导入代码高亮样式\nimport 'highlight.js/styles/github.css'\n\n\n\nconst app = createApp(App)\n\napp.use(store)\napp.use(router)\n\napp.mount('#app')","var map = {\n\t\"./11-19-1.jpg\": 5567,\n\t\"./11-19-2.jpg\": 5248,\n\t\"./11-19-3.jpg\": 3341,\n\t\"./11-19-4.jpg\": 646,\n\t\"./11-19-5.jpg\": 5411,\n\t\"./11-19-6.jpg\": 9188,\n\t\"./11-19-7.jpg\": 2785,\n\t\"./11-19-8.jpg\": 6058,\n\t\"./11-19-9.jpg\": 4343,\n\t\"./3.png\": 4415,\n\t\"./post1/2.png\": 380,\n\t\"./post2/post2-1.png\": 9743\n};\n\n\nfunction webpackContext(req) {\n\tvar id = webpackContextResolve(req);\n\treturn __webpack_require__(id);\n}\nfunction webpackContextResolve(req) {\n\tif(!__webpack_require__.o(map, req)) {\n\t\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\t\te.code = 'MODULE_NOT_FOUND';\n\t\tthrow e;\n\t}\n\treturn map[req];\n}\nwebpackContext.keys = function webpackContextKeys() {\n\treturn Object.keys(map);\n};\nwebpackContext.resolve = webpackContextResolve;\nmodule.exports = webpackContext;\nwebpackContext.id = 1751;","var map = {\n\t\"./post2.md\": 3937,\n\t\"./post3.md\": 9317,\n\t\"./post4.md\": 2879,\n\t\"./post5.md\": 3352,\n\t\"./post6.md\": 277,\n\t\"./post7.md\": 8774,\n\t\"./post8.md\": 4307,\n\t\"./post9.md\": 2044,\n\t\"./welcome.md\": 8277\n};\n\n\nfunction webpackContext(req) {\n\tvar id = webpackContextResolve(req);\n\treturn __webpack_require__(id);\n}\nfunction webpackContextResolve(req) {\n\tif(!__webpack_require__.o(map, req)) {\n\t\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\t\te.code = 'MODULE_NOT_FOUND';\n\t\tthrow e;\n\t}\n\treturn map[req];\n}\nwebpackContext.keys = function webpackContextKeys() {\n\treturn Object.keys(map);\n};\nwebpackContext.resolve = webpackContextResolve;\nmodule.exports = webpackContext;\nwebpackContext.id = 5344;","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n// expose the modules object (__webpack_modules__)\n__webpack_require__.m = __webpack_modules__;\n\n","var deferred = [];\n__webpack_require__.O = function(result, chunkIds, fn, priority) {\n\tif(chunkIds) {\n\t\tpriority = priority || 0;\n\t\tfor(var i = deferred.length; i > 0 && deferred[i - 1][2] > priority; i--) deferred[i] = deferred[i - 1];\n\t\tdeferred[i] = [chunkIds, fn, priority];\n\t\treturn;\n\t}\n\tvar notFulfilled = Infinity;\n\tfor (var i = 0; i < deferred.length; i++) {\n\t\tvar chunkIds = deferred[i][0];\n\t\tvar fn = deferred[i][1];\n\t\tvar priority = deferred[i][2];\n\t\tvar fulfilled = true;\n\t\tfor (var j = 0; j < chunkIds.length; j++) {\n\t\t\tif ((priority & 1 === 0 || notFulfilled >= priority) && Object.keys(__webpack_require__.O).every(function(key) { return __webpack_require__.O[key](chunkIds[j]); })) {\n\t\t\t\tchunkIds.splice(j--, 1);\n\t\t\t} else {\n\t\t\t\tfulfilled = false;\n\t\t\t\tif(priority < notFulfilled) notFulfilled = priority;\n\t\t\t}\n\t\t}\n\t\tif(fulfilled) {\n\t\t\tdeferred.splice(i--, 1)\n\t\t\tvar r = fn();\n\t\t\tif (r !== undefined) result = r;\n\t\t}\n\t}\n\treturn result;\n};","// getDefaultExport function for compatibility with non-harmony modules\n__webpack_require__.n = function(module) {\n\tvar getter = module && module.__esModule ?\n\t\tfunction() { return module['default']; } :\n\t\tfunction() { return module; };\n\t__webpack_require__.d(getter, { a: getter });\n\treturn getter;\n};","// define getter functions for harmony exports\n__webpack_require__.d = function(exports, definition) {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.f = {};\n// This file contains only the entry chunk.\n// The chunk loading function for additional chunks\n__webpack_require__.e = function(chunkId) {\n\treturn Promise.all(Object.keys(__webpack_require__.f).reduce(function(promises, key) {\n\t\t__webpack_require__.f[key](chunkId, promises);\n\t\treturn promises;\n\t}, []));\n};","// This function allow to reference async chunks\n__webpack_require__.u = function(chunkId) {\n\t// return url for filenames based on template\n\treturn \"js/\" + ({\"205\":\"post\",\"503\":\"archive\",\"594\":\"about\"}[chunkId] || chunkId) + \".\" + {\"137\":\"5b3b94a8\",\"205\":\"613e6bae\",\"503\":\"29cb7fcf\",\"594\":\"6f7f4a2a\"}[chunkId] + \".js\";\n};","// This function allow to reference async chunks\n__webpack_require__.miniCssF = function(chunkId) {\n\t// return url for filenames based on template\n\treturn \"css/\" + \"post\" + \".\" + \"d68cf366\" + \".css\";\n};","__webpack_require__.g = (function() {\n\tif (typeof globalThis === 'object') return globalThis;\n\ttry {\n\t\treturn this || new Function('return this')();\n\t} catch (e) {\n\t\tif (typeof window === 'object') return window;\n\t}\n})();","__webpack_require__.o = function(obj, prop) { return Object.prototype.hasOwnProperty.call(obj, prop); }","var inProgress = {};\nvar dataWebpackPrefix = \"xingyunchaju:\";\n// loadScript function to load a script via script tag\n__webpack_require__.l = function(url, done, key, chunkId) {\n\tif(inProgress[url]) { inProgress[url].push(done); return; }\n\tvar script, needAttach;\n\tif(key !== undefined) {\n\t\tvar scripts = document.getElementsByTagName(\"script\");\n\t\tfor(var i = 0; i < scripts.length; i++) {\n\t\t\tvar s = scripts[i];\n\t\t\tif(s.getAttribute(\"src\") == url || s.getAttribute(\"data-webpack\") == dataWebpackPrefix + key) { script = s; break; }\n\t\t}\n\t}\n\tif(!script) {\n\t\tneedAttach = true;\n\t\tscript = document.createElement('script');\n\n\t\tscript.charset = 'utf-8';\n\t\tscript.timeout = 120;\n\t\tif (__webpack_require__.nc) {\n\t\t\tscript.setAttribute(\"nonce\", __webpack_require__.nc);\n\t\t}\n\t\tscript.setAttribute(\"data-webpack\", dataWebpackPrefix + key);\n\n\t\tscript.src = url;\n\t}\n\tinProgress[url] = [done];\n\tvar onScriptComplete = function(prev, event) {\n\t\t// avoid mem leaks in IE.\n\t\tscript.onerror = script.onload = null;\n\t\tclearTimeout(timeout);\n\t\tvar doneFns = inProgress[url];\n\t\tdelete inProgress[url];\n\t\tscript.parentNode && script.parentNode.removeChild(script);\n\t\tdoneFns && doneFns.forEach(function(fn) { return fn(event); });\n\t\tif(prev) return prev(event);\n\t}\n\tvar timeout = setTimeout(onScriptComplete.bind(null, undefined, { type: 'timeout', target: script }), 120000);\n\tscript.onerror = onScriptComplete.bind(null, script.onerror);\n\tscript.onload = onScriptComplete.bind(null, script.onload);\n\tneedAttach && document.head.appendChild(script);\n};","// define __esModule on exports\n__webpack_require__.r = function(exports) {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","__webpack_require__.p = \"/SUXUING-star.github.io/\";","if (typeof document === \"undefined\") return;\nvar createStylesheet = function(chunkId, fullhref, oldTag, resolve, reject) {\n\tvar linkTag = document.createElement(\"link\");\n\n\tlinkTag.rel = \"stylesheet\";\n\tlinkTag.type = \"text/css\";\n\tif (__webpack_require__.nc) {\n\t\tlinkTag.nonce = __webpack_require__.nc;\n\t}\n\tvar onLinkComplete = function(event) {\n\t\t// avoid mem leaks.\n\t\tlinkTag.onerror = linkTag.onload = null;\n\t\tif (event.type === 'load') {\n\t\t\tresolve();\n\t\t} else {\n\t\t\tvar errorType = event && event.type;\n\t\t\tvar realHref = event && event.target && event.target.href || fullhref;\n\t\t\tvar err = new Error(\"Loading CSS chunk \" + chunkId + \" failed.\\n(\" + errorType + \": \" + realHref + \")\");\n\t\t\terr.name = \"ChunkLoadError\";\n\t\t\terr.code = \"CSS_CHUNK_LOAD_FAILED\";\n\t\t\terr.type = errorType;\n\t\t\terr.request = realHref;\n\t\t\tif (linkTag.parentNode) linkTag.parentNode.removeChild(linkTag)\n\t\t\treject(err);\n\t\t}\n\t}\n\tlinkTag.onerror = linkTag.onload = onLinkComplete;\n\tlinkTag.href = fullhref;\n\n\n\tif (oldTag) {\n\t\toldTag.parentNode.insertBefore(linkTag, oldTag.nextSibling);\n\t} else {\n\t\tdocument.head.appendChild(linkTag);\n\t}\n\treturn linkTag;\n};\nvar findStylesheet = function(href, fullhref) {\n\tvar existingLinkTags = document.getElementsByTagName(\"link\");\n\tfor(var i = 0; i < existingLinkTags.length; i++) {\n\t\tvar tag = existingLinkTags[i];\n\t\tvar dataHref = tag.getAttribute(\"data-href\") || tag.getAttribute(\"href\");\n\t\tif(tag.rel === \"stylesheet\" && (dataHref === href || dataHref === fullhref)) return tag;\n\t}\n\tvar existingStyleTags = document.getElementsByTagName(\"style\");\n\tfor(var i = 0; i < existingStyleTags.length; i++) {\n\t\tvar tag = existingStyleTags[i];\n\t\tvar dataHref = tag.getAttribute(\"data-href\");\n\t\tif(dataHref === href || dataHref === fullhref) return tag;\n\t}\n};\nvar loadStylesheet = function(chunkId) {\n\treturn new Promise(function(resolve, reject) {\n\t\tvar href = __webpack_require__.miniCssF(chunkId);\n\t\tvar fullhref = __webpack_require__.p + href;\n\t\tif(findStylesheet(href, fullhref)) return resolve();\n\t\tcreateStylesheet(chunkId, fullhref, null, resolve, reject);\n\t});\n}\n// object to store loaded CSS chunks\nvar installedCssChunks = {\n\t524: 0\n};\n\n__webpack_require__.f.miniCss = function(chunkId, promises) {\n\tvar cssChunks = {\"205\":1};\n\tif(installedCssChunks[chunkId]) promises.push(installedCssChunks[chunkId]);\n\telse if(installedCssChunks[chunkId] !== 0 && cssChunks[chunkId]) {\n\t\tpromises.push(installedCssChunks[chunkId] = loadStylesheet(chunkId).then(function() {\n\t\t\tinstalledCssChunks[chunkId] = 0;\n\t\t}, function(e) {\n\t\t\tdelete installedCssChunks[chunkId];\n\t\t\tthrow e;\n\t\t}));\n\t}\n};\n\n// no hmr\n\n// no prefetching\n\n// no preloaded","// no baseURI\n\n// object to store loaded and loading chunks\n// undefined = chunk not loaded, null = chunk preloaded/prefetched\n// [resolve, reject, Promise] = chunk loading, 0 = chunk loaded\nvar installedChunks = {\n\t524: 0\n};\n\n__webpack_require__.f.j = function(chunkId, promises) {\n\t\t// JSONP chunk loading for javascript\n\t\tvar installedChunkData = __webpack_require__.o(installedChunks, chunkId) ? installedChunks[chunkId] : undefined;\n\t\tif(installedChunkData !== 0) { // 0 means \"already installed\".\n\n\t\t\t// a Promise means \"currently loading\".\n\t\t\tif(installedChunkData) {\n\t\t\t\tpromises.push(installedChunkData[2]);\n\t\t\t} else {\n\t\t\t\tif(true) { // all chunks have JS\n\t\t\t\t\t// setup Promise in chunk cache\n\t\t\t\t\tvar promise = new Promise(function(resolve, reject) { installedChunkData = installedChunks[chunkId] = [resolve, reject]; });\n\t\t\t\t\tpromises.push(installedChunkData[2] = promise);\n\n\t\t\t\t\t// start chunk loading\n\t\t\t\t\tvar url = __webpack_require__.p + __webpack_require__.u(chunkId);\n\t\t\t\t\t// create error before stack unwound to get useful stacktrace later\n\t\t\t\t\tvar error = new Error();\n\t\t\t\t\tvar loadingEnded = function(event) {\n\t\t\t\t\t\tif(__webpack_require__.o(installedChunks, chunkId)) {\n\t\t\t\t\t\t\tinstalledChunkData = installedChunks[chunkId];\n\t\t\t\t\t\t\tif(installedChunkData !== 0) installedChunks[chunkId] = undefined;\n\t\t\t\t\t\t\tif(installedChunkData) {\n\t\t\t\t\t\t\t\tvar errorType = event && (event.type === 'load' ? 'missing' : event.type);\n\t\t\t\t\t\t\t\tvar realSrc = event && event.target && event.target.src;\n\t\t\t\t\t\t\t\terror.message = 'Loading chunk ' + chunkId + ' failed.\\n(' + errorType + ': ' + realSrc + ')';\n\t\t\t\t\t\t\t\terror.name = 'ChunkLoadError';\n\t\t\t\t\t\t\t\terror.type = errorType;\n\t\t\t\t\t\t\t\terror.request = realSrc;\n\t\t\t\t\t\t\t\tinstalledChunkData[1](error);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t};\n\t\t\t\t\t__webpack_require__.l(url, loadingEnded, \"chunk-\" + chunkId, chunkId);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n};\n\n// no prefetching\n\n// no preloaded\n\n// no HMR\n\n// no HMR manifest\n\n__webpack_require__.O.j = function(chunkId) { return installedChunks[chunkId] === 0; };\n\n// install a JSONP callback for chunk loading\nvar webpackJsonpCallback = function(parentChunkLoadingFunction, data) {\n\tvar chunkIds = data[0];\n\tvar moreModules = data[1];\n\tvar runtime = data[2];\n\t// add \"moreModules\" to the modules object,\n\t// then flag all \"chunkIds\" as loaded and fire callback\n\tvar moduleId, chunkId, i = 0;\n\tif(chunkIds.some(function(id) { return installedChunks[id] !== 0; })) {\n\t\tfor(moduleId in moreModules) {\n\t\t\tif(__webpack_require__.o(moreModules, moduleId)) {\n\t\t\t\t__webpack_require__.m[moduleId] = moreModules[moduleId];\n\t\t\t}\n\t\t}\n\t\tif(runtime) var result = runtime(__webpack_require__);\n\t}\n\tif(parentChunkLoadingFunction) parentChunkLoadingFunction(data);\n\tfor(;i < chunkIds.length; i++) {\n\t\tchunkId = chunkIds[i];\n\t\tif(__webpack_require__.o(installedChunks, chunkId) && installedChunks[chunkId]) {\n\t\t\tinstalledChunks[chunkId][0]();\n\t\t}\n\t\tinstalledChunks[chunkId] = 0;\n\t}\n\treturn __webpack_require__.O(result);\n}\n\nvar chunkLoadingGlobal = self[\"webpackChunkxingyunchaju\"] = self[\"webpackChunkxingyunchaju\"] || [];\nchunkLoadingGlobal.forEach(webpackJsonpCallback.bind(null, 0));\nchunkLoadingGlobal.push = webpackJsonpCallback.bind(null, chunkLoadingGlobal.push.bind(chunkLoadingGlobal));","// startup\n// Load entry module and return exports\n// This entry module depends on other loaded chunks and execution need to be delayed\nvar __webpack_exports__ = __webpack_require__.O(undefined, [683,501,849,823], function() { return __webpack_require__(8642); })\n__webpack_exports__ = __webpack_require__.O(__webpack_exports__);\n"],"names":["module","exports","attributes","html","class","_createElementBlock","_hoisted_1","_createVNode","_component_blog_header","_component_router_view","_component_blog_footer","_normalizeClass","$data","isScrolled","_createElementVNode","_hoisted_2","_hoisted_3","_component_router_link","to","default","_withCtx","_cache","_createTextVNode","_","name","data","lastScrollTop","headerHeight","scrollThreshold","scrollTimer","mounted","this","$el","offsetHeight","window","addEventListener","handleScroll","passive","document","body","style","paddingTop","beforeUnmount","removeEventListener","clearTimeout","methods","cancelAnimationFrame","requestAnimationFrame","st","scrollY","scrollDelta","Math","abs","__exports__","_toDisplayString","$options","currentYear","href","computed","Date","getFullYear","components","BlogHeader","BlogFooter","render","key","$setup","pinnedPosts","length","_Fragment","_renderList","post","_createBlock","_component_blog_post","id","onClick","$event","viewPost","_createCommentVNode","_hoisted_4","_hoisted_5","_hoisted_6","paginatedRegularPosts","totalPages","_hoisted_7","disabled","currentPage","changePage","_hoisted_8","_hoisted_9","displayedPages","page","active","_hoisted_10","_hoisted_11","src","alt","loading","$props","pinned","_ctx","$emit","xmlns","width","height","viewBox","fill","stroke","x1","y1","x2","y2","d","coverImage","title","onError","args","handleImageError","date","summary","props","type","Object","required","validator","obj","undefined","e","target","BlogPost","setup","store","useStore","router","useRouter","postsPerPage","ref","posts","console","log","state","value","filter","frontmatter","regularPosts","ceil","start","end","slice","total","current","pages","i","push","scrollTo","top","behavior","routes","path","component","Home","beforeEnter","from","next","Promise","all","catch","meta","keepAlive","createRouter","history","createWebHashHistory","scrollBehavior","savedPosition","beforeEach","markdownFiles","require","formatDate","dateString","toLocaleDateString","year","month","day","getImageUrl","imagePath","startsWith","warn","processMarkdownImages","content","replace","match","imageUrl","processMarkdownFiles","keys","map","index","slug","createStore","getters","getPostById","find","parseInt","getPostBySlug","getAllPosts","mutations","UPDATE_POST","findIndex","p","actions","updatePost","commit","payload","app","createApp","App","use","mount","webpackContext","req","webpackContextResolve","__webpack_require__","o","Error","code","resolve","__webpack_module_cache__","moduleId","cachedModule","__webpack_modules__","call","m","deferred","O","result","chunkIds","fn","priority","notFulfilled","Infinity","fulfilled","j","every","splice","r","n","getter","__esModule","a","definition","defineProperty","enumerable","get","f","chunkId","reduce","promises","u","miniCssF","g","globalThis","Function","prop","prototype","hasOwnProperty","inProgress","dataWebpackPrefix","l","url","done","script","needAttach","scripts","getElementsByTagName","s","getAttribute","createElement","charset","timeout","nc","setAttribute","onScriptComplete","prev","event","onerror","onload","doneFns","parentNode","removeChild","forEach","setTimeout","bind","head","appendChild","Symbol","toStringTag","createStylesheet","fullhref","oldTag","reject","linkTag","rel","nonce","onLinkComplete","errorType","realHref","err","request","insertBefore","nextSibling","findStylesheet","existingLinkTags","tag","dataHref","existingStyleTags","loadStylesheet","installedCssChunks","miniCss","cssChunks","then","installedChunks","installedChunkData","promise","error","loadingEnded","realSrc","message","webpackJsonpCallback","parentChunkLoadingFunction","moreModules","runtime","some","chunkLoadingGlobal","self","__webpack_exports__"],"sourceRoot":""}